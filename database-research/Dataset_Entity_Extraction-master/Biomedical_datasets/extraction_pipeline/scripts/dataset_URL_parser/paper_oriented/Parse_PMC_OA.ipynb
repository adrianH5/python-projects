{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e68a69f",
   "metadata": {},
   "source": [
    "## Parse out main text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3c5018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "from lxml import etree\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74711f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/xzuo/Projects/dissertation/dataset_URL_parser/paper_oriented', '/usr/local/anaconda3/lib/python39.zip', '/usr/local/anaconda3/lib/python3.9', '/usr/local/anaconda3/lib/python3.9/lib-dynload', '', '/home/xzuo/.local/lib/python3.9/site-packages', '/usr/local/anaconda3/lib/python3.9/site-packages', '/usr/local/anaconda3/lib/python3.9/site-packages/locket-0.2.1-py3.9.egg', '/usr/local/anaconda3/lib/python3.9/site-packages/IPython/extensions', '/home/xzuo/.ipython', '/data/xzuo/.conda/envs/dissertation/lib/python38.zip', '/data/xzuo/.conda/envs/dissertation/lib/python3.8', '/data/xzuo/.conda/envs/dissertation/lib/python3.8/lib-dynload', '/data/xzuo/.conda/envs/dissertation/lib/python3.8/site-packages']\n"
     ]
    }
   ],
   "source": [
    "# Update env and pkg paths.\n",
    "\n",
    "sys.path.extend(['/data/xzuo/.conda/envs/dissertation/lib/python38.zip', '/data/xzuo/.conda/envs/dissertation/lib/python3.8', '/data/xzuo/.conda/envs/dissertation/lib/python3.8/lib-dynload', '/data/xzuo/.conda/envs/dissertation/lib/python3.8/site-packages'])\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d304da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pubmed_parser as pp\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5d9d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pmid from LitCovid.\n",
    "\n",
    "id_list_path = \"./litcovid_pmid/litcovid_16052022.tsv\"\n",
    "csv_directory_path = \"./litcovid_pmcid_lists\"\n",
    "download_directory_path =\"./litcovid_pmc_fulltext/xml\"\n",
    "\n",
    "current_filelist = os.listdir(download_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcd0c557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove file PMC7594999.xml.\n",
      "Remove file PMC7938886.xml.\n",
      "Remove file PMC8447410.xml.\n",
      "Remove file PMC8262888.xml.\n",
      "Remove file PMC8665857.xml.\n",
      "Remove file PMC8032439.xml.\n",
      "Remove file PMC8423670.xml.\n",
      "There are 1 articles not accessible.\n"
     ]
    }
   ],
   "source": [
    "# Remove inaccessible files.\n",
    "\n",
    "# inaccessible_articles = []\n",
    "\n",
    "for i, xml_name in enumerate(current_filelist):\n",
    "    pmc_xml_path = os.path.join(download_directory_path, xml_name)\n",
    "#     with open(pmc_xml_path, \"r\") as f:\n",
    "#         xml_content = f.read()\n",
    "#     if \"API rate limit exceeded\" in xml_content:\n",
    "#         print(xml_name)\n",
    "#         current_filelist.remove(xml_name)\n",
    "#     else:\n",
    "#         continue\n",
    "    try:\n",
    "        pmc_tree = etree.parse(pmc_xml_path)\n",
    "    # except:\n",
    "    except Exception:\n",
    "        # inaccessible_articles.append(xml_name)\n",
    "        current_filelist.remove(xml_name)\n",
    "        os.remove(pmc_xml_path)\n",
    "        print(\"Remove file %s.\" % xml_name)\n",
    "        \n",
    "\n",
    "for i, xml_name in enumerate(current_filelist):\n",
    "    pmc_xml_path = os.path.join(download_directory_path, xml_name)\n",
    "    pmc_tree = etree.parse(pmc_xml_path)\n",
    "    meta = pmc_tree.find(\".//article-meta\")\n",
    "    if meta is None:\n",
    "        # inaccessible_articles.append(xml_name)\n",
    "        current_filelist.remove(xml_name)\n",
    "        os.remove(pmc_xml_path)\n",
    "#         print(\"File %s is not accessible.\" % xml_name)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# print(\"There are %d articles not accessible.\" % len(inaccessible_articles))\n",
    "\n",
    "# for i, xml_name in enumerate(inaccessible_articles):\n",
    "#     pmc_xml_path = os.path.join(download_directory_path, xml_name)\n",
    "#     if os.path.exists(pmc_xml_path):\n",
    "#         os.remove(pmc_xml_path)\n",
    "#     else:\n",
    "#         print(\"Error: File %s does not exist.\" % xml_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e3cfde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>main text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34776649</td>\n",
       "      <td>8572530</td>\n",
       "      <td>Subjektives Befinden und Arbeitsfähigkeit nach...</td>\n",
       "      <td>Hintergrund  Seit dem 29.01.2021 wurde der C...</td>\n",
       "      <td>Gegen SARS-CoV‑2 wurden Impfstoffe mit völlig ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34098882</td>\n",
       "      <td>8182346</td>\n",
       "      <td>Web-based, rapid and contactless management of...</td>\n",
       "      <td>Background  During the SARS-CoV-2 pandemic a...</td>\n",
       "      <td>From the end of February 2020 onwards, many pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34541298</td>\n",
       "      <td>8441688</td>\n",
       "      <td>Molecular Level Dissection of Critical Spike M...</td>\n",
       "      <td>Abstract  SARS‐CoV‐2 virus during its spread ...</td>\n",
       "      <td>Severe Acute Respiratory Syndrome Corona Virus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32302815</td>\n",
       "      <td>7151272</td>\n",
       "      <td>Psychological status of surgical staff during ...</td>\n",
       "      <td>Highlight     •  The mental health problems o...</td>\n",
       "      <td>Dear editor,\\nIn the outbreak of novel coronav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34295171</td>\n",
       "      <td>8291382</td>\n",
       "      <td>The Immunogenicity of Hyaluronic Fillers and I...</td>\n",
       "      <td>Abstract  Hyaluronic acid (HA) is a glycosami...</td>\n",
       "      <td>Hyaluronic acid (HA) is a glycosaminoglycan, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61889</th>\n",
       "      <td>34115405</td>\n",
       "      <td>8420322</td>\n",
       "      <td>The presence of SARS‐CoV‐2 virus in semen samp...</td>\n",
       "      <td>Abstract  The SARS‐CoV‐2 set off a pandemic i...</td>\n",
       "      <td>Coronavirus (SARS‐CoV‐2) induced a pandemic al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61890</th>\n",
       "      <td>35029196</td>\n",
       "      <td>8757937</td>\n",
       "      <td>Does influenza vaccination help reduce inciden...</td>\n",
       "      <td>Abstract  To facilitate the understanding of ...</td>\n",
       "      <td>Corona virus disease 2019 (COVID-19) was decla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61891</th>\n",
       "      <td>35414326</td>\n",
       "      <td>9115793</td>\n",
       "      <td>Myocarditis following COVID-19 vaccination: in...</td>\n",
       "      <td>ABSTRACT   Introduction  Vaccines have demons...</td>\n",
       "      <td>The concept of introducing substrate resemblin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61892</th>\n",
       "      <td>34655522</td>\n",
       "      <td>8514195</td>\n",
       "      <td>Safety and immunogenicity of CpG 1018 and alum...</td>\n",
       "      <td>Background  MVC-COV1901, a recombinant prote...</td>\n",
       "      <td>\\nEvidence before this study\\nTo understand th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61893</th>\n",
       "      <td>32376573</td>\n",
       "      <td>7167319</td>\n",
       "      <td>COVID-19临床分型与MSCT容积扫描间的相关性</td>\n",
       "      <td>目的  探讨新型冠状病毒肺炎(COVID-19)不同的临床分型与多层螺旋计算机体层摄影术...</td>\n",
       "      <td>\\nEvidence before this study\\nTo understand th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61894 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pmid    pmcid                                              title  \\\n",
       "0      34776649  8572530  Subjektives Befinden und Arbeitsfähigkeit nach...   \n",
       "1      34098882  8182346  Web-based, rapid and contactless management of...   \n",
       "2      34541298  8441688  Molecular Level Dissection of Critical Spike M...   \n",
       "3      32302815  7151272  Psychological status of surgical staff during ...   \n",
       "4      34295171  8291382  The Immunogenicity of Hyaluronic Fillers and I...   \n",
       "...         ...      ...                                                ...   \n",
       "61889  34115405  8420322  The presence of SARS‐CoV‐2 virus in semen samp...   \n",
       "61890  35029196  8757937  Does influenza vaccination help reduce inciden...   \n",
       "61891  35414326  9115793  Myocarditis following COVID-19 vaccination: in...   \n",
       "61892  34655522  8514195  Safety and immunogenicity of CpG 1018 and alum...   \n",
       "61893  32376573  7167319                         COVID-19临床分型与MSCT容积扫描间的相关性   \n",
       "\n",
       "                                                abstract  \\\n",
       "0        Hintergrund  Seit dem 29.01.2021 wurde der C...   \n",
       "1        Background  During the SARS-CoV-2 pandemic a...   \n",
       "2       Abstract  SARS‐CoV‐2 virus during its spread ...   \n",
       "3       Highlight     •  The mental health problems o...   \n",
       "4       Abstract  Hyaluronic acid (HA) is a glycosami...   \n",
       "...                                                  ...   \n",
       "61889   Abstract  The SARS‐CoV‐2 set off a pandemic i...   \n",
       "61890   Abstract  To facilitate the understanding of ...   \n",
       "61891   ABSTRACT   Introduction  Vaccines have demons...   \n",
       "61892    Background  MVC-COV1901, a recombinant prote...   \n",
       "61893    目的  探讨新型冠状病毒肺炎(COVID-19)不同的临床分型与多层螺旋计算机体层摄影术...   \n",
       "\n",
       "                                               main text  \n",
       "0      Gegen SARS-CoV‑2 wurden Impfstoffe mit völlig ...  \n",
       "1      From the end of February 2020 onwards, many pa...  \n",
       "2      Severe Acute Respiratory Syndrome Corona Virus...  \n",
       "3      Dear editor,\\nIn the outbreak of novel coronav...  \n",
       "4      Hyaluronic acid (HA) is a glycosaminoglycan, a...  \n",
       "...                                                  ...  \n",
       "61889  Coronavirus (SARS‐CoV‐2) induced a pandemic al...  \n",
       "61890  Corona virus disease 2019 (COVID-19) was decla...  \n",
       "61891  The concept of introducing substrate resemblin...  \n",
       "61892  \\nEvidence before this study\\nTo understand th...  \n",
       "61893  \\nEvidence before this study\\nTo understand th...  \n",
       "\n",
       "[61894 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse out text.\n",
    "articles = []\n",
    "\n",
    "for i, xml_name in enumerate(current_filelist):\n",
    "    pmc_xml_path = os.path.join(download_directory_path, xml_name)\n",
    "    pmc_tree = etree.parse(pmc_xml_path)\n",
    "    meta = pmc_tree.find(\".//article-meta\")\n",
    "    try:\n",
    "        metadata = pp.parse_pubmed_xml(pmc_xml_path)\n",
    "        full_text = pp.parse_pubmed_paragraph(pmc_xml_path, all_paragraph=True)\n",
    "        paras = []\n",
    "        for para in full_text:\n",
    "            paras.append(para['text'].strip())\n",
    "            main_text = \"\\n\".join(paras)\n",
    "        pmc_article = {\"pmid\": metadata['pmid'], \"pmcid\": metadata['pmc'], \n",
    "                       \"title\": metadata['full_title'], \"abstract\": metadata['abstract'], \n",
    "                       \"main text\": main_text}\n",
    "        articles.append(pmc_article)\n",
    "    except:\n",
    "        os.remove(pmc_xml_path)\n",
    "        print(\"File %s is not accessible. Removed.\" % xml_name)\n",
    "\n",
    "df = pd.DataFrame(articles)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c1d471",
   "metadata": {},
   "source": [
    "## General Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c907fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysbd\n",
    "import unidecode\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750e637e",
   "metadata": {},
   "source": [
    "### Search dataset description sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00b6669d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searched 1000 full-text articles.\n"
     ]
    }
   ],
   "source": [
    "seg = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "pattern = re.compile(r'((?:train|test|validation|testing|trainings?)\\s*(?:set|data))|(benchmarks?)|(data\\s*(?:set|base)s?)|(corpus)|(corpora)|(tree\\s*bank)|(collections?)')\n",
    "\n",
    "for i, article in enumerate(articles):\n",
    "    all_text = article['title'] + \".\\n\" + article['abstract'] + \"\\n\" + article['main text']\n",
    "    article['sentences'] = seg.segment(all_text)\n",
    "    article['has_pattern'] = []\n",
    "    for j, sent in enumerate(article['sentences']):\n",
    "        if pattern.search(sent):\n",
    "            article['has_pattern'].append(sent)\n",
    "    if i != 0 and i % 1000 == 0:\n",
    "        print(\"Searched %d full-text articles.\" % i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14ce9946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>main text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>has_pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34847386</td>\n",
       "      <td>8609674</td>\n",
       "      <td>Uncertainty-aware convolutional neural network...</td>\n",
       "      <td>Deep learning (DL) has shown great success in...</td>\n",
       "      <td>Novel Corona Virus disease 2019 (COVID-19) has...</td>\n",
       "      <td>[Uncertainty-aware convolutional neural networ...</td>\n",
       "      <td>[The proposed method is evaluated on the three...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34976572</td>\n",
       "      <td>8675556</td>\n",
       "      <td>Detecting SARS-CoV-2 From Chest X-Ray Using Ar...</td>\n",
       "      <td>Chest radiographs (X-rays) combined with Deep...</td>\n",
       "      <td>The Severe Acute Respiratory Syndrome Coronavi...</td>\n",
       "      <td>[Detecting SARS-CoV-2 From Chest X-Ray Using A...</td>\n",
       "      <td>[However, questions remain regarding the accur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34352699</td>\n",
       "      <td>8249716</td>\n",
       "      <td>Conventional and microfluidic methods for airb...</td>\n",
       "      <td>Graphical abstract      With the COVID-19 pan...</td>\n",
       "      <td>Throughout history, infectious diseases have p...</td>\n",
       "      <td>[Conventional and microfluidic methods for air...</td>\n",
       "      <td>[Creating targeted and effective interventions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32836689</td>\n",
       "      <td>7236753</td>\n",
       "      <td>Competitive pricing of substitute products und...</td>\n",
       "      <td>There has been an increased interest in optim...</td>\n",
       "      <td>Retailers frequently rely on suppliers that ar...</td>\n",
       "      <td>[Competitive pricing of substitute products un...</td>\n",
       "      <td>[Section 3 is devoted to benchmark modeling of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34070422</td>\n",
       "      <td>8226892</td>\n",
       "      <td>Shall I Work with Them? A Knowledge Graph-Base...</td>\n",
       "      <td>We consider the prediction of future research...</td>\n",
       "      <td>The development of knowledge graph-based appro...</td>\n",
       "      <td>[Shall I Work with Them? , A Knowledge Graph-B...</td>\n",
       "      <td>[We benchmark the proposed approach against cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34139910</td>\n",
       "      <td>8216038</td>\n",
       "      <td>Protecting Privacy and Transforming COVID-19 C...</td>\n",
       "      <td>Objectives  Federal open-data initiatives th...</td>\n",
       "      <td>Federal open-data initiatives that promote inc...</td>\n",
       "      <td>[Protecting Privacy and Transforming COVID-19 ...</td>\n",
       "      <td>[We describe how CDC designed and produces 2 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33935584</td>\n",
       "      <td>8068562</td>\n",
       "      <td>A Novel Ensemble-based Classifier for Detectin...</td>\n",
       "      <td>The recently discovered coronavirus, SARS-CoV...</td>\n",
       "      <td>The SARS-CoV-2 that causes COVID-19, colloquia...</td>\n",
       "      <td>[A Novel Ensemble-based Classifier for Detecti...</td>\n",
       "      <td>[In this paper, a synthetic dataset of COVID-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33728416</td>\n",
       "      <td>7953447</td>\n",
       "      <td>VERSO: A comprehensive framework for the infer...</td>\n",
       "      <td>Summary  We introduce VERSO, a two-step frame...</td>\n",
       "      <td>The outbreak of coronavirus disease 2019 (COVI...</td>\n",
       "      <td>[VERSO: A comprehensive framework for the infe...</td>\n",
       "      <td>[The application to large-scale datasets demon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35071990</td>\n",
       "      <td>8767797</td>\n",
       "      <td>Development and implementation of a COVID-19 c...</td>\n",
       "      <td>Introduction  Convalescent Plasma therapy is...</td>\n",
       "      <td>In late 2019, patients presenting an atypical ...</td>\n",
       "      <td>[Development and implementation of a COVID-19 ...</td>\n",
       "      <td>[Methods  A multicentric convalescent plasma c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32898686</td>\n",
       "      <td>7474840</td>\n",
       "      <td>Digital technology, tele-medicine and artifici...</td>\n",
       "      <td>The simultaneous maturation of multiple digit...</td>\n",
       "      <td>2020 marked the synchronous maturation of seve...</td>\n",
       "      <td>[Digital technology, tele-medicine and artific...</td>\n",
       "      <td>[A review of different tele-health models and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>33302292</td>\n",
       "      <td>7799233</td>\n",
       "      <td>iDMer: an integrative and mechanism-driven res...</td>\n",
       "      <td>Abstract  Emerging viral infections seriously...</td>\n",
       "      <td>Emerging viral infections seriously threaten h...</td>\n",
       "      <td>[iDMer: an integrative and mechanism-driven re...</td>\n",
       "      <td>[As a one-stop integrative platform, iDMer inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33052312</td>\n",
       "      <td>7543791</td>\n",
       "      <td>Virus database annotations assist in tracing i...</td>\n",
       "      <td>The global pandemic of SARS-CoV-2 has disrupt...</td>\n",
       "      <td>The coronavirus disease 2019 (COVID-19) pandem...</td>\n",
       "      <td>[Virus database annotations assist in tracing ...</td>\n",
       "      <td>[Virus database annotations assist in tracing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34228637</td>\n",
       "      <td>8312471</td>\n",
       "      <td>Prognostic and immunological value of  ATP6AP1...</td>\n",
       "      <td>Abnormal ATPase H+ Transporting Accessory Pro...</td>\n",
       "      <td>In women, breast cancer (BC) is one of the lea...</td>\n",
       "      <td>[Prognostic and immunological value of  ATP6AP...</td>\n",
       "      <td>[The Oncomine, Gene Expression Profiling Inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>34451100</td>\n",
       "      <td>8402377</td>\n",
       "      <td>Explainable Artificial Intelligence for Bias D...</td>\n",
       "      <td>Problem: An application of Explainable Artifi...</td>\n",
       "      <td>The COVID-19 outbreak has become a central top...</td>\n",
       "      <td>[Explainable Artificial Intelligence for Bias ...</td>\n",
       "      <td>[Motivation: It is possible that classifiers a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>34335121</td>\n",
       "      <td>8317469</td>\n",
       "      <td>A stochastic bi-objective simulation–optimizat...</td>\n",
       "      <td>As of March 24, 2020, the Food and Drug Admin...</td>\n",
       "      <td>Nowadays we are challenging with the daily inc...</td>\n",
       "      <td>[A stochastic bi-objective simulation–optimiza...</td>\n",
       "      <td>[Therefore, a four-echelon supply chain has be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pmid    pmcid                                              title  \\\n",
       "0   34847386  8609674  Uncertainty-aware convolutional neural network...   \n",
       "1   34976572  8675556  Detecting SARS-CoV-2 From Chest X-Ray Using Ar...   \n",
       "2   34352699  8249716  Conventional and microfluidic methods for airb...   \n",
       "3   32836689  7236753  Competitive pricing of substitute products und...   \n",
       "4   34070422  8226892  Shall I Work with Them? A Knowledge Graph-Base...   \n",
       "5   34139910  8216038  Protecting Privacy and Transforming COVID-19 C...   \n",
       "6   33935584  8068562  A Novel Ensemble-based Classifier for Detectin...   \n",
       "7   33728416  7953447  VERSO: A comprehensive framework for the infer...   \n",
       "8   35071990  8767797  Development and implementation of a COVID-19 c...   \n",
       "9   32898686  7474840  Digital technology, tele-medicine and artifici...   \n",
       "10  33302292  7799233  iDMer: an integrative and mechanism-driven res...   \n",
       "11  33052312  7543791  Virus database annotations assist in tracing i...   \n",
       "12  34228637  8312471  Prognostic and immunological value of  ATP6AP1...   \n",
       "13  34451100  8402377  Explainable Artificial Intelligence for Bias D...   \n",
       "14  34335121  8317469  A stochastic bi-objective simulation–optimizat...   \n",
       "\n",
       "                                             abstract  \\\n",
       "0    Deep learning (DL) has shown great success in...   \n",
       "1    Chest radiographs (X-rays) combined with Deep...   \n",
       "2    Graphical abstract      With the COVID-19 pan...   \n",
       "3    There has been an increased interest in optim...   \n",
       "4    We consider the prediction of future research...   \n",
       "5     Objectives  Federal open-data initiatives th...   \n",
       "6    The recently discovered coronavirus, SARS-CoV...   \n",
       "7    Summary  We introduce VERSO, a two-step frame...   \n",
       "8     Introduction  Convalescent Plasma therapy is...   \n",
       "9    The simultaneous maturation of multiple digit...   \n",
       "10   Abstract  Emerging viral infections seriously...   \n",
       "11   The global pandemic of SARS-CoV-2 has disrupt...   \n",
       "12   Abnormal ATPase H+ Transporting Accessory Pro...   \n",
       "13   Problem: An application of Explainable Artifi...   \n",
       "14   As of March 24, 2020, the Food and Drug Admin...   \n",
       "\n",
       "                                            main text  \\\n",
       "0   Novel Corona Virus disease 2019 (COVID-19) has...   \n",
       "1   The Severe Acute Respiratory Syndrome Coronavi...   \n",
       "2   Throughout history, infectious diseases have p...   \n",
       "3   Retailers frequently rely on suppliers that ar...   \n",
       "4   The development of knowledge graph-based appro...   \n",
       "5   Federal open-data initiatives that promote inc...   \n",
       "6   The SARS-CoV-2 that causes COVID-19, colloquia...   \n",
       "7   The outbreak of coronavirus disease 2019 (COVI...   \n",
       "8   In late 2019, patients presenting an atypical ...   \n",
       "9   2020 marked the synchronous maturation of seve...   \n",
       "10  Emerging viral infections seriously threaten h...   \n",
       "11  The coronavirus disease 2019 (COVID-19) pandem...   \n",
       "12  In women, breast cancer (BC) is one of the lea...   \n",
       "13  The COVID-19 outbreak has become a central top...   \n",
       "14  Nowadays we are challenging with the daily inc...   \n",
       "\n",
       "                                            sentences  \\\n",
       "0   [Uncertainty-aware convolutional neural networ...   \n",
       "1   [Detecting SARS-CoV-2 From Chest X-Ray Using A...   \n",
       "2   [Conventional and microfluidic methods for air...   \n",
       "3   [Competitive pricing of substitute products un...   \n",
       "4   [Shall I Work with Them? , A Knowledge Graph-B...   \n",
       "5   [Protecting Privacy and Transforming COVID-19 ...   \n",
       "6   [A Novel Ensemble-based Classifier for Detecti...   \n",
       "7   [VERSO: A comprehensive framework for the infe...   \n",
       "8   [Development and implementation of a COVID-19 ...   \n",
       "9   [Digital technology, tele-medicine and artific...   \n",
       "10  [iDMer: an integrative and mechanism-driven re...   \n",
       "11  [Virus database annotations assist in tracing ...   \n",
       "12  [Prognostic and immunological value of  ATP6AP...   \n",
       "13  [Explainable Artificial Intelligence for Bias ...   \n",
       "14  [A stochastic bi-objective simulation–optimiza...   \n",
       "\n",
       "                                          has_pattern  \n",
       "0   [The proposed method is evaluated on the three...  \n",
       "1   [However, questions remain regarding the accur...  \n",
       "2   [Creating targeted and effective interventions...  \n",
       "3   [Section 3 is devoted to benchmark modeling of...  \n",
       "4   [We benchmark the proposed approach against cl...  \n",
       "5   [We describe how CDC designed and produces 2 d...  \n",
       "6   [In this paper, a synthetic dataset of COVID-1...  \n",
       "7   [The application to large-scale datasets demon...  \n",
       "8   [Methods  A multicentric convalescent plasma c...  \n",
       "9   [A review of different tele-health models and ...  \n",
       "10  [As a one-stop integrative platform, iDMer inc...  \n",
       "11  [Virus database annotations assist in tracing ...  \n",
       "12  [The Oncomine, Gene Expression Profiling Inter...  \n",
       "13  [Motivation: It is possible that classifiers a...  \n",
       "14  [Therefore, a four-echelon supply chain has be...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qualified_articles = []\n",
    "for article in articles:\n",
    "    if \"has_pattern\" in article and len(article['has_pattern']) > 20:\n",
    "        qualified_articles.append(article)\n",
    "\n",
    "qualified_df = pd.DataFrame(qualified_articles)\n",
    "display(qualified_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56163009",
   "metadata": {},
   "source": [
    "### Search dataset description sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff0e870c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searched 1000 full-text articles.\n",
      "Searched 2000 full-text articles.\n",
      "Searched 3000 full-text articles.\n",
      "Searched 4000 full-text articles.\n",
      "Searched 5000 full-text articles.\n",
      "Searched 6000 full-text articles.\n",
      "Searched 7000 full-text articles.\n",
      "Searched 8000 full-text articles.\n",
      "Searched 9000 full-text articles.\n",
      "Searched 10000 full-text articles.\n",
      "Searched 11000 full-text articles.\n",
      "Searched 12000 full-text articles.\n",
      "Searched 13000 full-text articles.\n",
      "Searched 14000 full-text articles.\n",
      "Searched 15000 full-text articles.\n",
      "Searched 16000 full-text articles.\n",
      "Searched 17000 full-text articles.\n",
      "Searched 18000 full-text articles.\n",
      "Searched 19000 full-text articles.\n",
      "Searched 20000 full-text articles.\n",
      "Searched 21000 full-text articles.\n",
      "Searched 22000 full-text articles.\n",
      "Searched 23000 full-text articles.\n",
      "Searched 24000 full-text articles.\n",
      "Searched 25000 full-text articles.\n",
      "Searched 26000 full-text articles.\n",
      "Searched 27000 full-text articles.\n",
      "Searched 28000 full-text articles.\n",
      "Searched 29000 full-text articles.\n",
      "Searched 30000 full-text articles.\n",
      "Searched 31000 full-text articles.\n",
      "Searched 32000 full-text articles.\n",
      "Searched 33000 full-text articles.\n",
      "Searched 34000 full-text articles.\n",
      "Searched 35000 full-text articles.\n",
      "Searched 36000 full-text articles.\n",
      "Searched 37000 full-text articles.\n",
      "Searched 38000 full-text articles.\n",
      "Searched 39000 full-text articles.\n",
      "Searched 40000 full-text articles.\n",
      "Searched 41000 full-text articles.\n",
      "Searched 42000 full-text articles.\n",
      "Searched 43000 full-text articles.\n",
      "Searched 44000 full-text articles.\n",
      "Searched 45000 full-text articles.\n",
      "Searched 46000 full-text articles.\n",
      "Searched 47000 full-text articles.\n",
      "Searched 48000 full-text articles.\n",
      "Searched 49000 full-text articles.\n",
      "Searched 50000 full-text articles.\n",
      "Searched 51000 full-text articles.\n",
      "Searched 52000 full-text articles.\n",
      "Searched 53000 full-text articles.\n",
      "Searched 54000 full-text articles.\n",
      "Searched 55000 full-text articles.\n",
      "Searched 56000 full-text articles.\n",
      "Searched 57000 full-text articles.\n",
      "Searched 58000 full-text articles.\n",
      "Searched 59000 full-text articles.\n",
      "Searched 60000 full-text articles.\n",
      "Searched 61000 full-text articles.\n",
      "Search Completed.\n"
     ]
    }
   ],
   "source": [
    "seg = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "pattern = re.compile(r'(N3C)|(National COVID Cohort Collaborative)|(GenBank)|\\\n",
    "                     (GISAID)|(Nextstrain)|(OpenICPSR)|(TCIA)|(GEO)|(Gene Expression Omnibus)\\\n",
    "                     (CORD-19)|(LitCovid)|(NCBI Virus)')\n",
    "\n",
    "for i, article in enumerate(articles):\n",
    "    # all_text = article['title'] + \".\\n\" + article['abstract'] + \"\\n\" + article['main text']\n",
    "    title_abstract_text = article['title'] + \".\\n\" + article['abstract']\n",
    "    article['sentences'] = seg.segment(title_abstract_text)\n",
    "    # article['sentences'] = seg.segment(all_text)\n",
    "    article['has_pattern'] = []\n",
    "    for j, sent in enumerate(article['sentences']):\n",
    "        if pattern.search(sent):\n",
    "            article['has_pattern'].append(sent)\n",
    "    if i != 0 and i % 1000 == 0:\n",
    "        print(\"Searched %d full-text articles.\" % i)\n",
    "        # break\n",
    "\n",
    "print(\"Search Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "032a5511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>main text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>has_pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34765026</td>\n",
       "      <td>8576622</td>\n",
       "      <td>Testicular injury during SARS-CoV-2 infection ...</td>\n",
       "      <td>Coronavirus disease 2019 (COVID-19), caused b...</td>\n",
       "      <td>Coronavirus disease 2019 (COVID-19), caused by...</td>\n",
       "      <td>[Testicular injury during SARS-CoV-2 infection...</td>\n",
       "      <td>[For this, the ACE2-expressing cell compositio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35422859</td>\n",
       "      <td>9002903</td>\n",
       "      <td>Combination of Enrichment Using Gene Ontology ...</td>\n",
       "      <td>Introduction  The severity of coronavirus di...</td>\n",
       "      <td>A coronavirus is a group of viruses from the s...</td>\n",
       "      <td>[Combination of Enrichment Using Gene Ontology...</td>\n",
       "      <td>[We collected the transcriptomics data from GE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33166392</td>\n",
       "      <td>7778958</td>\n",
       "      <td>LitCovid: an open database of COVID-19 literature</td>\n",
       "      <td>Abstract  Since the outbreak of the current p...</td>\n",
       "      <td>Since the outbreak of the COVID-19 pandemic, r...</td>\n",
       "      <td>[LitCovid: an open database of COVID-19 litera...</td>\n",
       "      <td>[LitCovid: an open database of COVID-19 litera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34821594</td>\n",
       "      <td>8625834</td>\n",
       "      <td>Characterization and Pathogenic Speculation of...</td>\n",
       "      <td>Patients with coronavirus disease 2019 (COVID...</td>\n",
       "      <td>Infection with severe acute respiratory syndro...</td>\n",
       "      <td>[Characterization and Pathogenic Speculation o...</td>\n",
       "      <td>[Scientific articles were retrieved by searchi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32022275</td>\n",
       "      <td>7166327</td>\n",
       "      <td>The first two cases of 2019‐nCoV in Italy: Whe...</td>\n",
       "      <td>Abstract  A novel Coronavirus , 2019‐nCoV, ha...</td>\n",
       "      <td>An ongoing epidemic by a new Coronavirus, name...</td>\n",
       "      <td>[The first two cases of 2019‐nCoV in Italy: Wh...</td>\n",
       "      <td>[A maximum clade credibility tree has been bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>35005058</td>\n",
       "      <td>8734487</td>\n",
       "      <td>Evaluation of multiple open-source deep learni...</td>\n",
       "      <td>Abstract.  Purpose : Chest x-rays are complex...</td>\n",
       "      <td>The early radiological features of viral pneum...</td>\n",
       "      <td>[Evaluation of multiple open-source deep learn...</td>\n",
       "      <td>[Approach : We tested three open-source deep l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>34675627</td>\n",
       "      <td>8520483</td>\n",
       "      <td>Construction and Investigation of Competing En...</td>\n",
       "      <td>Introduction  The current COVID-19 pandemic ...</td>\n",
       "      <td>The Coronaviruses (CoVs) are a varied group of...</td>\n",
       "      <td>[Construction and Investigation of Competing E...</td>\n",
       "      <td>[Methods  The RNA sequencing data of SARS-CoV-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>32773643</td>\n",
       "      <td>7493783</td>\n",
       "      <td>Genomic variance of Open Reading Frames (ORFs)...</td>\n",
       "      <td>Background:  The outbreak of severe acute res...</td>\n",
       "      <td>The outbreak of severe acute respiratory syndr...</td>\n",
       "      <td>[Genomic variance of Open Reading Frames (ORFs...</td>\n",
       "      <td>[Methods:  We apply genomic alignment analysis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>34019643</td>\n",
       "      <td>8218201</td>\n",
       "      <td>eVITTA: a web-based visualization and inferenc...</td>\n",
       "      <td>Abstract  Transcriptome profiling is essentia...</td>\n",
       "      <td>Transcriptome profiling is an essential techni...</td>\n",
       "      <td>[eVITTA: a web-based visualization and inferen...</td>\n",
       "      <td>[Additionally, there is no systematic way to e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>32946531</td>\n",
       "      <td>7500631</td>\n",
       "      <td>The association between ABO blood group and SA...</td>\n",
       "      <td>At present, existing evidence about the assoc...</td>\n",
       "      <td>Since the first outbreak of COVID-19 in Wuhan,...</td>\n",
       "      <td>[The association between ABO blood group and S...</td>\n",
       "      <td>[We performed a systematic search on MEDLINE a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pmid    pmcid                                              title  \\\n",
       "0   34765026  8576622  Testicular injury during SARS-CoV-2 infection ...   \n",
       "1   35422859  9002903  Combination of Enrichment Using Gene Ontology ...   \n",
       "2   33166392  7778958  LitCovid: an open database of COVID-19 literature   \n",
       "3   34821594  8625834  Characterization and Pathogenic Speculation of...   \n",
       "4   32022275  7166327  The first two cases of 2019‐nCoV in Italy: Whe...   \n",
       "..       ...      ...                                                ...   \n",
       "69  35005058  8734487  Evaluation of multiple open-source deep learni...   \n",
       "70  34675627  8520483  Construction and Investigation of Competing En...   \n",
       "71  32773643  7493783  Genomic variance of Open Reading Frames (ORFs)...   \n",
       "72  34019643  8218201  eVITTA: a web-based visualization and inferenc...   \n",
       "73  32946531  7500631  The association between ABO blood group and SA...   \n",
       "\n",
       "                                             abstract  \\\n",
       "0    Coronavirus disease 2019 (COVID-19), caused b...   \n",
       "1     Introduction  The severity of coronavirus di...   \n",
       "2    Abstract  Since the outbreak of the current p...   \n",
       "3    Patients with coronavirus disease 2019 (COVID...   \n",
       "4    Abstract  A novel Coronavirus , 2019‐nCoV, ha...   \n",
       "..                                                ...   \n",
       "69   Abstract.  Purpose : Chest x-rays are complex...   \n",
       "70    Introduction  The current COVID-19 pandemic ...   \n",
       "71   Background:  The outbreak of severe acute res...   \n",
       "72   Abstract  Transcriptome profiling is essentia...   \n",
       "73   At present, existing evidence about the assoc...   \n",
       "\n",
       "                                            main text  \\\n",
       "0   Coronavirus disease 2019 (COVID-19), caused by...   \n",
       "1   A coronavirus is a group of viruses from the s...   \n",
       "2   Since the outbreak of the COVID-19 pandemic, r...   \n",
       "3   Infection with severe acute respiratory syndro...   \n",
       "4   An ongoing epidemic by a new Coronavirus, name...   \n",
       "..                                                ...   \n",
       "69  The early radiological features of viral pneum...   \n",
       "70  The Coronaviruses (CoVs) are a varied group of...   \n",
       "71  The outbreak of severe acute respiratory syndr...   \n",
       "72  Transcriptome profiling is an essential techni...   \n",
       "73  Since the first outbreak of COVID-19 in Wuhan,...   \n",
       "\n",
       "                                            sentences  \\\n",
       "0   [Testicular injury during SARS-CoV-2 infection...   \n",
       "1   [Combination of Enrichment Using Gene Ontology...   \n",
       "2   [LitCovid: an open database of COVID-19 litera...   \n",
       "3   [Characterization and Pathogenic Speculation o...   \n",
       "4   [The first two cases of 2019‐nCoV in Italy: Wh...   \n",
       "..                                                ...   \n",
       "69  [Evaluation of multiple open-source deep learn...   \n",
       "70  [Construction and Investigation of Competing E...   \n",
       "71  [Genomic variance of Open Reading Frames (ORFs...   \n",
       "72  [eVITTA: a web-based visualization and inferen...   \n",
       "73  [The association between ABO blood group and S...   \n",
       "\n",
       "                                          has_pattern  \n",
       "0   [For this, the ACE2-expressing cell compositio...  \n",
       "1   [We collected the transcriptomics data from GE...  \n",
       "2   [LitCovid: an open database of COVID-19 litera...  \n",
       "3   [Scientific articles were retrieved by searchi...  \n",
       "4   [A maximum clade credibility tree has been bui...  \n",
       "..                                                ...  \n",
       "69  [Approach : We tested three open-source deep l...  \n",
       "70  [Methods  The RNA sequencing data of SARS-CoV-...  \n",
       "71  [Methods:  We apply genomic alignment analysis...  \n",
       "72  [Additionally, there is no systematic way to e...  \n",
       "73  [We performed a systematic search on MEDLINE a...  \n",
       "\n",
       "[74 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qualified_articles = []\n",
    "for article in articles:\n",
    "    if \"has_pattern\" in article and len(article['has_pattern']) > 0:\n",
    "        qualified_articles.append(article)\n",
    "\n",
    "qualified_df = pd.DataFrame(qualified_articles)\n",
    "display(qualified_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6954fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_directory = \"./fulltext_txt_nih/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c71e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_batch = [\"PMC8178310.xml\", \"PMC7245624.xml\", \"PMC8353192.xml\", \"PMC8174030.xml\", \"PMC8201431.xml\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ac3ed10",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_78585/2842238824.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marticle_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# print(article['pmcid'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mall_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abstract'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'main text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Format lines.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mraw_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# parser = CoreNLPParser(url='http://localhost:9000')\n",
    "\n",
    "for article in article_batch:\n",
    "    # print(article['pmcid'])\n",
    "    all_text = article['title'] + \".\\n\" + article['abstract'] + \"\\n\" + article['main text'].strip()\n",
    "    # Format lines.\n",
    "    raw_lines = all_text.splitlines()\n",
    "    # lines = [line.strip() for line in raw_lines if len(word_tokenize(line)) > 10]\n",
    "    lines = []\n",
    "    for line in raw_lines:\n",
    "        line_decode = unidecode.unidecode(line)\n",
    "        if len(word_tokenize(line_decode)) > 10:\n",
    "            lines.append(line.strip())\n",
    "        else:\n",
    "            continue\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        if not new_lines or not(line.startswith((\")\", \"-\", \",\"))):\n",
    "            new_lines.append(line)\n",
    "        else:\n",
    "            new_lines[-1] += line\n",
    "    new_text_per_article = \"\\n\\n\".join(new_lines)\n",
    "    txt_name = \"PMC{}.txt\".format(article['pmcid'])\n",
    "    output_path = os.path.join(txt_directory, txt_name)\n",
    "    with open(output_path, \"w\", encoding='utf-8') as output_file:\n",
    "        output_file.write(new_text_per_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26696693",
   "metadata": {},
   "source": [
    "## Detailed search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bb4d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "159bfba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PMC8675677.xml', 'PMC7989622.xml', 'PMC8180385.xml', 'PMC8336924.xml', 'PMC8653328.xml', 'PMC8362655.xml', 'PMC8216038.xml', 'PMC8319175.xml', 'PMC7823180.xml', 'PMC8468495.xml']\n"
     ]
    }
   ],
   "source": [
    "pmcs_has_pattern = top20_df['pmcid'].to_list()\n",
    "pmcpath_has_pattern = [\"PMC\" + pmcid + \".xml\" for pmcid in pmcs_has_pattern]\n",
    "print(pmcpath_has_pattern[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66528997",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "count_all = 0\n",
    "dataset_sents = []\n",
    "\n",
    "for xml_name in pmcpath_has_pattern[:10]:\n",
    "    xml_path = os.path.join(download_directory_path, xml_name)\n",
    "    metadata = pp.parse_pubmed_xml(xml_path)\n",
    "    full_text = pp.parse_pubmed_paragraph(xml_path, all_paragraph=True)\n",
    "    for para in full_text:\n",
    "        sents = sent_tokenize(para['text'])\n",
    "        for sent in sents:\n",
    "            count_all += 1\n",
    "            if re.search(pattern, sent):\n",
    "                count += 1\n",
    "                sentence = {\"pmid\": metadata['pmid'], \"pmcid\": metadata['pmc'], \"sentence\": sent}\n",
    "                dataset_sents.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "228bad23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34914688</td>\n",
       "      <td>8675677</td>\n",
       "      <td>Using this graphical model called the Stochast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34914688</td>\n",
       "      <td>8675677</td>\n",
       "      <td>To this end, we first analyzed a large dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34914688</td>\n",
       "      <td>8675677</td>\n",
       "      <td>We then analyzed other datasets to determine w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34914688</td>\n",
       "      <td>8675677</td>\n",
       "      <td>Early in the pandemic, we implemented the Stoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34914688</td>\n",
       "      <td>8675677</td>\n",
       "      <td>We chose to first perform the same analysis ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>34573790</td>\n",
       "      <td>8468495</td>\n",
       "      <td>For our analysis, we used the synthetic and re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>34573790</td>\n",
       "      <td>8468495</td>\n",
       "      <td>Additional synthetic and real datasets exist b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>34573790</td>\n",
       "      <td>8468495</td>\n",
       "      <td>The synthetic datasets for the three different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>34573790</td>\n",
       "      <td>8468495</td>\n",
       "      <td>The synthetic versions of some datasets and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>34573790</td>\n",
       "      <td>8468495</td>\n",
       "      <td>The real MIMIC and ASD datasets are only acces...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>856 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pmid    pmcid                                           sentence\n",
       "0    34914688  8675677  Using this graphical model called the Stochast...\n",
       "1    34914688  8675677  To this end, we first analyzed a large dataset...\n",
       "2    34914688  8675677  We then analyzed other datasets to determine w...\n",
       "3    34914688  8675677  Early in the pandemic, we implemented the Stoc...\n",
       "4    34914688  8675677  We chose to first perform the same analysis ov...\n",
       "..        ...      ...                                                ...\n",
       "851  34573790  8468495  For our analysis, we used the synthetic and re...\n",
       "852  34573790  8468495  Additional synthetic and real datasets exist b...\n",
       "853  34573790  8468495  The synthetic datasets for the three different...\n",
       "854  34573790  8468495  The synthetic versions of some datasets and th...\n",
       "855  34573790  8468495  The real MIMIC and ASD datasets are only acces...\n",
       "\n",
       "[856 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_df = pd.DataFrame(dataset_sents)\n",
    "display(sent_df)\n",
    "sent_df.to_csv('./top10_sents.tsv', sep='\\t', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acc143e",
   "metadata": {},
   "source": [
    "## Parse full-text with section headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cc8d5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PMC8475511.xml', 'PMC8609674.xml', 'PMC8675556.xml', 'PMC7236753.xml', 'PMC8216038.xml', 'PMC8767797.xml', 'PMC7474840.xml', 'PMC7799233.xml', 'PMC7543791.xml', 'PMC8312471.xml']\n"
     ]
    }
   ],
   "source": [
    "# Generate PMC article file names.\n",
    "\n",
    "# pmc_to_extract = df_rand_100['pmcid'].to_list()\n",
    "pmc_to_extract = remain_articles\n",
    "pmc_to_extract_filenames = [\"PMC\" + pmcid + \".xml\" for pmcid in pmc_to_extract]\n",
    "print(pmc_to_extract_filenames[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ede0e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_directory = \"./fulltext_txt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b18d2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text files for annotation.\n",
    "\n",
    "for i, xml_name in enumerate(article_batch):\n",
    "    xml_path = os.path.join(download_directory_path, xml_name)\n",
    "    metadata = pp.parse_pubmed_xml(xml_path)\n",
    "    full_text = pp.parse_pubmed_paragraph(xml_path, all_paragraph=True)\n",
    "    \n",
    "    paras = []\n",
    "    for para in full_text:\n",
    "        paras.append(para['text'].strip())\n",
    "        main_text = \"\\n\".join(paras)\n",
    "        # paras.append(paragraph['all text'])\n",
    "    all_text_per_article = metadata['full_title'] + \".\\n\" + metadata['abstract'] + \"\\n\" + main_text\n",
    "    \n",
    "    # Format lines.\n",
    "    lines = all_text_per_article.splitlines()\n",
    "    lines = [line for line in lines if len(line) > 2]\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        if not new_lines or not(line.startswith((\")\", \"-\", \",\"))):\n",
    "            new_lines.append(line)\n",
    "        else:\n",
    "            new_lines[-1] += line\n",
    "    new_text_per_article = \"\\n\\n\".join(new_lines)\n",
    "    # print(all_text_per_article)\n",
    "    \n",
    "    txt_name = xml_name.replace(\".xml\", \".txt\")\n",
    "    output_path = os.path.join(txt_directory, txt_name)\n",
    "    with open(output_path, \"w\", encoding='utf-8') as output_file:\n",
    "        output_file.write(new_text_per_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783bd46",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
