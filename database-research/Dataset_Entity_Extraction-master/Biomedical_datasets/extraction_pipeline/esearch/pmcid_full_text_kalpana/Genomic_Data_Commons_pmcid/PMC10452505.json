[{"source": "PMC", "date": "20240203", "key": "pmc.key", "infons": {}, "documents": [{"id": "10452505", "infons": {"license": "CC BY"}, "passages": [{"offset": 0, "infons": {"article-id_doi": "10.3390/cancers15164044", "article-id_pmc": "10452505", "article-id_pmid": "37627071", "article-id_publisher-id": "cancers-15-04044", "elocation-id": "4044", "issue": "16", "kwd": "deep learning neural network chemotherapy response occlusion sensitivity analysis Inception V3 convolutional neural network spatialomic spatialomics platinum chemotherapy histopathology ovarian cancer artificial intelligence", "license": "Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).", "name_0": "surname:Liu;given-names:Yuexin", "name_1": "surname:Lawson;given-names:Barrett C.", "name_2": "surname:Huang;given-names:Xuelin", "name_3": "surname:Broom;given-names:Bradley M.", "name_4": "surname:Weinstein;given-names:John N.", "name_5": "surname:Fadare;given-names:Oluwole", "section_type": "TITLE", "type": "front", "volume": "15", "year": "2023"}, "text": "Prediction of Ovarian Cancer Response to Therapy Based on Deep Learning Analysis of Histopathology Images", "sentences": [], "annotations": [], "relations": []}, {"offset": 106, "infons": {"section_type": "ABSTRACT", "type": "abstract_title_1"}, "text": "Simple Summary", "sentences": [], "annotations": [], "relations": []}, {"offset": 121, "infons": {"section_type": "ABSTRACT", "type": "abstract"}, "text": "Ovarian cancer remains the leading cause of mortality from gynecologic cancer. In this study, we present a deep-learning artificial intelligence framework that uses pre-treatment histopathology images of high-grade ovarian cancers to predict the cancer\u2019s sensitivity or resistance to subsequent platinum-based chemotherapy. Analyses of this type could provide fast, inexpensive prediction of response to therapy at the time of initial pathological diagnosis.", "sentences": [], "annotations": [], "relations": []}, {"offset": 582, "infons": {"section_type": "ABSTRACT", "type": "abstract_title_1"}, "text": "Abstract", "sentences": [], "annotations": [], "relations": []}, {"offset": 591, "infons": {"section_type": "ABSTRACT", "type": "abstract"}, "text": "Background: Ovarian cancer remains the leading gynecological cause of cancer mortality. Predicting the sensitivity of ovarian cancer to chemotherapy at the time of pathological diagnosis is a goal of precision medicine research that we have addressed in this study using a novel deep-learning neural network framework to analyze the histopathological images. Methods: We have developed a method based on the Inception V3 deep learning algorithm that complements other methods for predicting response to standard platinum-based therapy of the disease. For the study, we used histopathological H&E images (pre-treatment) of high-grade serous carcinoma from The Cancer Genome Atlas (TCGA) Genomic Data Commons portal to train the Inception V3 convolutional neural network system to predict whether cancers had independently been labeled as sensitive or resistant to subsequent platinum-based chemotherapy. The trained model was then tested using data from patients left out of the training process. We used receiver operating characteristic (ROC) and confusion matrix analyses to evaluate model performance and Kaplan\u2013Meier survival analysis to correlate the predicted probability of resistance with patient outcome. Finally, occlusion sensitivity analysis was piloted as a start toward correlating histopathological features with a response. Results: The study dataset consisted of 248 patients with stage 2 to 4 serous ovarian cancer. For a held-out test set of forty patients, the trained deep learning network model distinguished sensitive from resistant cancers with an area under the curve (AUC) of 0.846 \u00b1 0.009 (SE). The probability of resistance calculated from the deep-learning network was also significantly correlated with patient survival and progression-free survival. In confusion matrix analysis, the network classifier achieved an overall predictive accuracy of 85% with a sensitivity of 73% and specificity of 90% for this cohort based on the Youden-J cut-off. Stage, grade, and patient age were not statistically significant for this cohort size. Occlusion sensitivity analysis suggested histopathological features learned by the network that may be associated with sensitivity or resistance to the chemotherapy, but multiple marker studies will be necessary to follow up on those preliminary results. Conclusions: This type of analysis has the potential, if further developed, to improve the prediction of response to therapy of high-grade serous ovarian cancer and perhaps be useful as a factor in deciding between platinum-based and other therapies. More broadly, it may increase our understanding of the histopathological variables that predict response and may be adaptable to other cancer types and imaging modalities.", "sentences": [], "annotations": [], "relations": []}, {"offset": 3336, "infons": {"section_type": "INTRO", "type": "title_1"}, "text": "1. Introduction", "sentences": [], "annotations": [], "relations": []}, {"offset": 3352, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Ovarian carcinoma (OvCa) remains the leading cause of mortality from gynecologic cancer, with estimated 21,410 new cases and 13,770 deaths in the United States alone in 2021. A standard treatment protocol for advanced-stage epithelial OvCa includes cytoreductive surgery followed by platinum-based combination chemotherapy. However, the majority of patients eventually relapse with a generally incurable disease, mainly due to the emergence of resistance to chemotherapy. Chemotherapy imposes significant toxicity and cost; hence, early identification of patients whose cancers are resistant to chemotherapy is a goal of precision medicine.", "sentences": [], "annotations": [], "relations": []}, {"offset": 3993, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "OvCa patients with BRCA1/2 mutations (germline or somatic) respond better to platinum-based treatment and have substantially longer survival than non-carriers, and additional genomic markers of response have been identified. For example, we previously found that mutations in members of the ADAMTS (a disintegrin and metalloproteinase with thrombospondin motifs) gene family were significantly associated with an improved response to platinum-based chemotherapy and substantially longer survival in OvCa patients, independent of BRCA1/2 mutation. The association of ADAMTS mutations with drug sensitization in ovarian cancer cells was functionally validated using ovarian cancer in vitro and in vivo model systems. However, additional predictors of response would be useful.", "sentences": [], "annotations": [], "relations": []}, {"offset": 4768, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "In addition to genomic aberrations, morphological alterations have long been a hallmark of cancer pathology. Morphologic features can be correlated with cellular functions such as cell growth, apoptosis, differentiation, and migration and are routinely used for cancer diagnosis in clinical practice. Genetic testing for BRCA1/2 mutations is currently performed in clinical practice on ovarian cancer patients to predict drug sensitivity. However, only 15\u201320% of the cancers have a BRCA1/2 mutation (germline or somatic), and therefore response to chemotherapy in the remaining percentage of patients with ovarian cancer is not subject to prediction on the basis of that genomic marker.", "sentences": [], "annotations": [], "relations": []}, {"offset": 5457, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Convolutional neural networks (CNNs) consisting of convolution, activation, and pooling layers represent a specific type of deep learning architecture that is well suited to image analysis tasks. The development of graphics processing units (GPUs), the accessibility of large amounts of data, and the high accuracies achievable have caused a surge in the application of deep learning to image analysis in the last few years. Several CNNs have been successfully designed for automated detection, segmentation, or classification of medical and whole-slide histopathological images for a wide array of cancer types. Computational pathology using deep learning techniques may lead to quick, inexpensive methods for characterizing the tumor microenvironment, distinguishing tumor subtypes, correctly grading tumors, and predicting gene mutations based on histopathology images. Such analysis methods can, in principle, be applied to all types of what we might term \u2018spatialomic\u2019 technologies, including those based on sequencing and multiplexed labeling with antibodies. For ovarian cancers, Wu et al. have used a deep learning model and hematoxylin\u2013eosin (H&E) stained tissue sections to classify ovarian cancer histologic subtypes automatically, and Shin et al. leveraged an image set obtained from The Cancer Image Archive (TCIA) to distinguish malignant tissues from normal background based on a CNN model. Wang et al. developed a weakly supervised deep learning approach to predict the therapeutic response of ovarian cancers to bevacizumab based on histopathology images, and a similar weakly-supervised neural network was proposed to discriminate ovarian cancer patients with extremely different platinum-free intervals. The patient cohort used in that study was relatively small, and a majority of ovarian cancer patients with platinum-free intervals in between the two extremes remained undetermined. Yu et al. employed a series network architecture (VGGNet) with regression output to predict platinum-free intervals of ovarian cancer patients from histopathology images. Thus far, no similar studies have used deep learning network algorithms and histopathology images to classify ovarian cancer patients into resistant or sensitive categories in a large patient population. ", "sentences": [], "annotations": [], "relations": []}, {"offset": 7744, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Using whole-slide H&E-stained ovarian tumor samples from The Cancer Genome Atlas (TCGA), we previously applied a hand-crafted image segmentation, feature-based machine learning approach to identify morphologic features associated with chemotherapy response in OvCa patients. In the present study, we have taken a different approach, using a deep learning neural network method based on the Inception V3 directed acyclic graph architecture to predict chemotherapy response status using the same image set as in our previous image segmentation approach. In addition, we piloted occlusion sensitivity analysis (OSA) to identify morphological features in the pathology images that are associated with resistance to chemotherapy. This proof-of-principle study suggests that deep learning, in particular with the Inception V3 architecture, can be applied to other cancer types and probably, with modifications, to other imaging modalities.", "sentences": [], "annotations": [], "relations": []}, {"offset": 8678, "infons": {"section_type": "METHODS", "type": "title_1"}, "text": "2. Methods", "sentences": [], "annotations": [], "relations": []}, {"offset": 8689, "infons": {"section_type": "METHODS", "type": "title_2"}, "text": "2.1. TCGA Ovarian Cancer Whole-Slide Image Dataset ", "sentences": [], "annotations": [], "relations": []}, {"offset": 8741, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "Whole-slide, frozen-section, H&E-stained images of ovarian cancer analyzed in this study (all of them designated as high-grade serous carcinoma) were downloaded from the TCGA Genomic Data Commons portal. Platinum responsiveness labels (sensitive/resistant) of the cancers provided by the TCGA database were used as our ground truth in the analysis. The cancers were categorized as platinum-resistant if the platinum-free interval was less than 6 months and the patient experienced progression or recurrence. They were categorized as platinum-sensitive if the platinum-free interval was 6 months or more without evidence of progression or recurrence. The entire cohort consisted of 174 chemotherapy-sensitive (chemo-sensitive) patients and 74 chemotherapy-resistant (chemo-resistant) patients (Table 1). The average age of the cohort was 60.0 years (range, 30.5 to 87.5). The majority of the patients were defined as WHO high grade (grade 3) with stage III or IV disease, and 37 were defined as \u201cgrade 2\u201d. To assess whether the relationship between tumor grade and chemotherapy response was more than expected by chance, we created a contingency table and performed Fisher\u2019s exact test. The results did not demonstrate a statistically significant association of chemotherapy resistance with tumor grade (p = 0.3287) (Supplementary Table S1), tumor stage (p = 0.216, Fisher\u2019s exact test) (Supplementary Table S2), or patient age (p = 0.087, Mann\u2013Whitney test) (Supplementary Figure S1). ", "sentences": [], "annotations": [], "relations": []}, {"offset": 10237, "infons": {"section_type": "METHODS", "type": "title_2"}, "text": "2.2. Tile Datastore Generation via Image Preprocessing", "sentences": [], "annotations": [], "relations": []}, {"offset": 10292, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "Based on high-resolution images, regions of interest (ROIs) at a magnification of 20X (size: 1072 \u00d7 648 pixels) were selected by an expert gynecologic pathologist using the Aperio ImageScope (Leica Biosystems). That selection was performed to ensure that the majority of the fields to be analyzed represented tumor. We know of no reason to expect that choice of ROIs would introduce significant bias, although that possibility cannot be ruled out. To account for spatial heterogeneity of the tumor tissues, an average of 10 ROIs per slide from different views of the tissue blocks were selected from the H&E-stained ScanScope virtual slide set (Supplementary Figure S2). As a result, a total of 2389 ROIs were selected, 1680 of them from sensitive tumors and 709 from resistant ones. ROIs were further tiled in non-overlapping 299 \u00d7 299-pixel windows, and incomplete tiles smaller than the window size were excluded. That process generated over 14,000 tiles in total for image analysis. For detailed information regarding the number of tiles, ROIs, and slides for resistant/sensitive classification, see Supplementary Table S3.", "sentences": [], "annotations": [], "relations": []}, {"offset": 11422, "infons": {"section_type": "METHODS", "type": "title_2"}, "text": "2.3. Deep Learning with Convolutional Neural Network", "sentences": [], "annotations": [], "relations": []}, {"offset": 11475, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "For independent testing of models generated, we left a total of 40 slides (2370 tiles) out of the training process. We then used 95% of the remaining tiles for training and 5% of the tiles for validation (Supplementary Table S3). Only the training tiles (but not the validation or test tiles) were used to update network parameters. The validation tiles were used to evaluate network performance during the training process. The test-set tiles were then used to assess the network generalizability after the network had been fully trained. To ensure the reproducibility of the results, the training and test process was repeated a total of 16 times after creating random splits of the training and validation datasets with a ratio of 95:5 while retaining the same test set. To assess the effect of class imbalance on the results, we performed two different experiments. One was to upsize the number of resistance images; the other was to downsize the number of sensitive images so that the numbers of resistant and sensitive images were matched with each other. We based our CNN model on the Inception V3 architecture developed by Google researchers. That architecture makes use of inception modules that include multiple convolutions with different filter sizes and a max or average pooling layer. The Inception V3 architecture starts with five convolutional and two max pooling layers that are then followed by eleven inception modules. The architecture ends the sequence with an average pooling layer, a dropout layer, a fully connected layer, and then a softmax output layer. For drug response classification, we trained the whole network, including the last fully connected layer and also the prior layers.", "sentences": [], "annotations": [], "relations": []}, {"offset": 13187, "infons": {"section_type": "METHODS", "type": "title_2"}, "text": "2.4. Training the Inception V3 Network", "sentences": [], "annotations": [], "relations": []}, {"offset": 13226, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "We trained the Inception V3 architecture following the procedure previously described. The network parameters were first initialized to those that were achieved by ImageNet competition and then updated on our training set data via backpropagation. We used RMSProp optimization, with a learning rate of 10\u22125, gradient decay factor of 0.99, regularization of 10\u22124, and epsilon of 10\u22128 for training the weights. In addition to the fully connected layer, we also optimized the weights and biases of all previous learnable layers (i.e., the convolution and activation layers). That strategy was used for the classification of drug response. The training jobs were run for 50 epochs, which corresponded to over 50,000 iterations. We computed the predictive accuracy on the training and validation datasets, and similar to other studies, we used the model with the best validation score as our final model for application to the test set, which had been left out of the entire training process. ", "sentences": [], "annotations": [], "relations": []}, {"offset": 14221, "infons": {"section_type": "METHODS", "type": "title_2"}, "text": "2.5. Statistical Analysis", "sentences": [], "annotations": [], "relations": []}, {"offset": 14247, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "Once the training phase was completed, we then used the test dataset (composed of tiles not used in training) to evaluate model performance. The probabilities for each slide were aggregated using the mean probability of its tiles. ROC curves and the corresponding AUCs were computed using Matlab and GraphPad 9.0 software. Confusion matrix charts were computed and visualized using Matlab, and an optimal cut-point (derived from the ROC curve) was calculated by the Youden J-index method. Slide probability distributions and relationships to chemotherapy response in the same test dataset were analyzed using the two-tailed Mann\u2013Whitney U-test. ", "sentences": [], "annotations": [], "relations": []}, {"offset": 14895, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "We used the Kaplan\u2013Meier method to examine the association between the predicted slide probabilities and patient survival, including both overall survival (OS) and progression-free survival (PFS). The patients were then dichotomized into two groups based on the predicted slide probabilities with the Youden J-index cutoff (0.2612 in this case). Survival differences between the two groups were assessed using the log-rank test. In the multivariate Cox proportional hazards model analysis, the slide probability score, stage, and tumor grade were treated as ordinal categorical variables, and patient age was treated as a continuous variable. The Wald test was used to evaluate survival differences in the multivariate analysis.", "sentences": [], "annotations": [], "relations": []}, {"offset": 15626, "infons": {"section_type": "METHODS", "type": "title_2"}, "text": "2.6. Identification of Histopathologic Features Associated with Chemotherapy Response", "sentences": [], "annotations": [], "relations": []}, {"offset": 15712, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "In an attempt to identify histopathological factors that might explain the predictiveness of the neural network results, we piloted the use of occlusion sensitivity analysis (OSA). In OSA, the network\u2019s sensitivity to serial perturbations of small regions of the image is determined. The mask size used was 15 \u00d7 15 pixels, and the mask value was defined as the channel-wise mean of the input data. The mask was moved across the image, and the change in probability score for the given class was determined as a function of mask position. The step size for traversing the mask across the image was 10 pixels in both vertical and horizontal directions. Finally, we used bicubic interpolation to produce a smooth map the same size as the input data. The occlusion sensitivity map highlights which parts of the image are most important to the classification. That is, when that part of the image is occluded, the probability score for the predicted class rises or falls accordingly. By convention, red areas of the map have a higher positive value and are evidence for the given class. When red areas are occluded, the probability score for the class probability, as predicted by the deep learning algorithm, decreases. Blue areas of the map with small positive values or negative values indicate parts of the image that lead to negligible change or opposite change in the score when occluded, suggesting that their features have negligible or opposite impact on the predicted class. To identify the features more clearly, we superimposed the OSA maps on the original tile images or else toggled back and forth between the map and the corresponding histopathology tile. ", "sentences": [], "annotations": [], "relations": []}, {"offset": 17382, "infons": {"section_type": "RESULTS", "type": "title_1"}, "text": "3. Results", "sentences": [], "annotations": [], "relations": []}, {"offset": 17393, "infons": {"section_type": "RESULTS", "type": "title_2"}, "text": "3.1. A Deep Learning Framework for Digital Analysis of Histopathology Images ", "sentences": [], "annotations": [], "relations": []}, {"offset": 17471, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "In this study, we sought to develop a deep learning framework for automatic predictive analysis of tumor slides using whole-slide images publicly available in TCGA\u2019s Cancer Digital Image Archive (CDIA). Our overall computational strategy is summarized in Figure 1. We first downloaded H&E-stained whole-slide images from the TCGA CDIA (Figure 1a). Because many of the slide images included non-tumor areas, regions of interest (ROIs) were then manually selected at 20x magnification by a gynecologic pathologist (Figure 1a). Because the ROIs were much larger than the input size usable by the neural network, we trained, validated, and tested the network using 299 \u00d7 299-pixel tiles obtained from non-overlapping \u2018patches\u2019 of the ROIs (Figure 1a). The tiles (six per ROI) were labeled as chemo-sensitive or chemo-resistant (i.e., as having been obtained from chemo-sensitive or chemo-resistant patients), and a tile datastore was generated (Figure 1a). The tiles were further split into training, validation, and test sets (Figure 1b). The training and validation tiles were used to train the Inception V3 network architecture, as described in the Methods section, and to select the final model (Figure 1c). Tiles in the independent test set were then used to evaluate model performance after aggregation of tiles to the slide (i.e., patient) level once the fully trained neural network had been obtained (Figure 1d). Aggregation to the patient level was appropriate because that was the level of pre-labeled sensitivity or resistance.", "sentences": [], "annotations": [], "relations": []}, {"offset": 19014, "infons": {"section_type": "RESULTS", "type": "title_2"}, "text": "3.2. Testing and Tile Aggregation Pipeline", "sentences": [], "annotations": [], "relations": []}, {"offset": 19057, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "Once the training phase was completed, we tested the fully trained model with the test dataset (Figure 2). Tiles generated from the test slides (Figure 2a) were used as inputs and fed into the trained deep learning model (Figure 2b), which then generated the class probability (range 0 to 1) for each tile (Figure 2c). We then aggregated the per-tile classification results on an ROI basis by averaging the probabilities obtained for the six tiles from the ROI (Figure 2d). Similarly, we further aggregated the per-ROI classification results on a slide basis by averaging the probabilities obtained on the ROIs from the same slide (Figure 2e). For each slide, we then obtained the class probability at the slide (i.e., patient) level, from which we calculated the AUC statistics (Figure 2f).", "sentences": [], "annotations": [], "relations": []}, {"offset": 19849, "infons": {"section_type": "RESULTS", "type": "title_2"}, "text": "3.3. The Deep Learning Model Predicts Chemotherapy Response from Ovarian Histopathology Images", "sentences": [], "annotations": [], "relations": []}, {"offset": 19944, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "Next, we tested the generalization error of the deep learning model with a test set comprised of 29 chemo-sensitive and 11 chemo-resistant cancers. After aggregation of the statistics on a slide (i.e., patient) basis, violin plot and ROC curve analysis (Figure 3a,b) showed that chemotherapy response could be predicted using our deep-learning approach, which yielded a Cohen\u2019s d of 1.33 (considered \u201clarge\u201d) and an AUC value of 0.843. Next, we applied the Youden J index and constructed the confusion matrix (Figure 3c). The predicted classes obtained by the Inception V3 deep learning algorithm were significantly associated with the true class (p = 0.003, Fisher\u2019s exact test). This result contrasts with the non-significant association of chemotherapy response with clinical factors (i.e., grade, stage, age) in the same cohort (see Methods for direct comparison). Approximately 85% of patients were correctly classified in terms of drug sensitivity on the basis of pre-treatment histopathology, with a sensitivity of 73% and a specificity of 90% at the Youden J point (Figure 3c). The large value of Cohen\u2019s d (1.33) indicates that the difference between sensitive and resistant may be \u201cmeaningful\u201d as well as statistically significant. Repeated random sub-sampling to obtain 16 different training sets gave an average test set AUC value of 0.846 \u00b1 0.009 (SE) (range, 0.781\u20130.900) (Figure 3d), consistent with the result for the first random choice of the training set. Calculations using upsizing and downsizing to match sensitive and resistant dataset sizes indicated that the AUC results were not much impacted by class imbalance (Supplementary Figure S3).", "sentences": [], "annotations": [], "relations": []}, {"offset": 21626, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "We next determined the relationship between predicted probabilities from the slides and patient outcome, including both overall survival (OS) and progression-free survival (PFS). When the Youden J-index-based cut point was applied, Kaplan\u2013Meier analysis showed that the network classifier correlated significantly with both OS (Figure 4a, p = 0.0084) and PFS (Figure 4b, p = 0.0226). To test whether that result was independent of known predictive variables such as stage, grade, or age, we performed multivariate analysis using the Cox proportional hazards model with the network classifier and the other variables as covariates. After adjustment for stage, grade, and age, the Inception V3 probability score correlated with OS (p = 0.013) and PFS (p = 0.045) (Supplementary Tables S4 and S5). Those results further confirmed the prediction of chemotherapy response using the Inception V3 deep learning model.", "sentences": [], "annotations": [], "relations": []}, {"offset": 22539, "infons": {"section_type": "RESULTS", "type": "title_2"}, "text": "3.4. Visualization of Chemotherapy Response-Associated Features Identified by the Deep Learning Model", "sentences": [], "annotations": [], "relations": []}, {"offset": 22641, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "To assist pathologists in their classification of whole-slide images of ovarian cancer tissues, we next sought to identify morphological features associated with chemotherapy response by using OSA (Figure 5). For high-confidence tiles (Figure 5a), the dynamic range of the occlusion sensitivity map is narrow, and the blue areas denote smaller positive values (Figure 5b). The overlaid image (Figure 5c) explicitly shows features associated with responsive disease. More instructive are tiles for which the network is ambivalent about the prediction (i.e., with a probability equal to ~0.5 for resistant and ~0.5 for sensitive) (Figure 5d). In such cases, the occlusion sensitivity map has a much wider dynamic range and can be used to compare which features (e.g., cell types) in the image the network identified with different response classes (Figure 5e). From the overlaid image (Figure 5f), we could discern features or regions that contributed to the chemotherapy resistance (red areas with positive values). In contrast, blue areas of the map with negative values are parts of the image that lead to an increase in the score when occluded. Often those areas are suggestive of the opposite class (\u201csensitive\u201d in this case).", "sentences": [], "annotations": [], "relations": []}, {"offset": 23875, "infons": {"section_type": "DISCUSS", "type": "title_1"}, "text": "4. Discussion", "sentences": [], "annotations": [], "relations": []}, {"offset": 23889, "infons": {"section_type": "DISCUSS", "type": "paragraph"}, "text": "This study demonstrates the use of an Inception V3 convolution neural network deep learning model to predict the response of high-grade serous ovarian cancer patients to platinum-based chemotherapy on the basis of pre-treatment histopathology slides. The deep learning classifier achieved a mean ROC AUC of 0.846 \u00b1 0.009 with an accuracy of 85% in correctly classifying tumors previously labeled as resistant or sensitive in the TCGA ovarian cancer dataset. Accordingly, the predictions also correlated with OS and PFS. Those studies demonstrated that features learned by the deep learning model can distinguish resistant from sensitive diseases despite staining and processing artifacts present in the TCGA frozen sections. Occlusion sensitivity analysis (OSA) could further assist in the prediction of chemotherapy response at the time of pathological diagnosis, but further studies, including multiplexed immunohistochemical analyses, will be necessary for a fuller interpretation of the factors involved.", "sentences": [], "annotations": [], "relations": []}, {"offset": 24899, "infons": {"section_type": "DISCUSS", "type": "paragraph"}, "text": "We previously reported that particular nucleus morphology features (size and shape) in segmented histopathology images were correlated with chemotherapy response in the same ovarian cancer samples as those used in the present study. Different from that \u201cfeature engineering\u201d approach to prediction, which requires the definition of problem-specific features, deep learning networks learn image feature representations from the data autonomously. As a result, the need for domain knowledge to achieve useful results is greatly decreased. Deep learning image analysis networks are trained end-to-end directly from image labels and raw pixels; hence, they show potential for general and highly variable tasks across many fine-grained object categories. Generalizability of this study\u2019s results is suggested by qualitatively consistent data obtained in an independent study using a different (series-structured) deep learning architecture (VGGNet), slide tiling strategy, composition of cohort, and factor analysis methodology in generating and analyzing a regression model for prediction of the response to therapy.", "sentences": [], "annotations": [], "relations": []}, {"offset": 26018, "infons": {"section_type": "DISCUSS", "type": "paragraph"}, "text": "Deep learning models are often described as \u201cblack-box\u201d due to the opaque nature of the algorithms, which are trained rather than explicitly programmed; hence, reasons for results are difficult for humans to interpret. Our introduction of OSA is an initial attempt to ameliorate that uncertainty by discovering what parts of an image are most important for deep learning classification.", "sentences": [], "annotations": [], "relations": []}, {"offset": 26409, "infons": {"section_type": "DISCUSS", "type": "paragraph"}, "text": "This study has limitations. (i) The sizes of the overall cohort (248 patients) and test set (40 patients) were relatively small. However, that was easily sufficient to achieve statistically robust results for the two-class prediction; (ii) There was no independent patient cohort from a source other than TCGA to evaluate the model for generalization of results. However, it should be noted that the TCGA samples were obtained from numerous institutions and represent a wide spread of age, stage, processing methods, and other non-histopathological variables. (iii) The dataset comprises only high-grade serous carcinomas and predominantly advanced-stage tumors that do not fully represent the diversity and clinical heterogeneity of ovarian cancers. Of note, the TCGA dataset includes \u201cgrade 2\u201d for high-grade serous carcinoma. That is not a currently recognized grade for ovarian serous tumors, which are now defined just as low- or high-grade serous; however, no significant difference in response was noted in this study that would indicate a large difference between the \u201cgrade 2\u201d and \u201cgrade 3\u201d tumors. (iv) This study used only ROIs and included pre-treatment samples only from patients who later received frontline platinum-based chemotherapy. (v) The TCGA specimens analyzed were frozen sections, adding artifacts beyond those that would be seen with H&E slides prepared from formalin-fixed paraffin-embedded (FFPE) tissues. Hence, more accurate predictions of response to therapy might be obtainable by the CNN system from FFPE samples. Whereas FFPE slides are less than ideal for sequencing studies, they are much better than frozen in terms of visual features as well as availability in pathology archives. Further evaluation of the CNN classifier for a larger cohort, FFPE slides, and/or tissue microarrays would provide additional useful information. However, the CNN framework presented here could potentially add to the corpus of information on clinical trial patients as they are selected for platinum-based or more recently developed therapeutic regimens.", "sentences": [], "annotations": [], "relations": []}, {"offset": 28494, "infons": {"section_type": "CONCL", "type": "title_1"}, "text": "5. Conclusions", "sentences": [], "annotations": [], "relations": []}, {"offset": 28509, "infons": {"section_type": "CONCL", "type": "paragraph"}, "text": "This is a proof-of-principle study demonstrating the application of an Inception V3 deep learning model for prediction of ovarian cancer response to platinum-based chemotherapy based solely on histopathology images. Its results, if further developed, and if combined with other predictive variables (e.g., including nucleus morphology, demographic data, stage, grade, and \u2018omic\u2019 profilingmay have utility in clinical management. The desirability of extending the approach to FFPE samples and additional tumor types is apparent.", "sentences": [], "annotations": [], "relations": []}, {"offset": 29041, "infons": {"section_type": "CONCL", "type": "footnote"}, "text": "Disclaimer/Publisher\u2019s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.", "sentences": [], "annotations": [], "relations": []}, {"offset": 29413, "infons": {"section_type": "SUPPL", "type": "title"}, "text": "Supplementary Materials", "sentences": [], "annotations": [], "relations": []}, {"offset": 29437, "infons": {"section_type": "SUPPL", "type": "paragraph"}, "text": "The following supporting information can be downloaded at . Figure S1: Association of chemotherapy response status with patient age in the study cohort (median difference: 2.6 years). Figure S2: (a) Number of whole-slide images per class. (b) Distribution of the number of ROIs per slide. (c) Association of the number of ovarian cases with 5 ROIs per slide with chemotherapy response. There was no significant effect (Fisher\u2019s exact p = 0.7906, odds ratio = 1.191). Figure S3: Effect of class imbalance on the network performance. Receiver operating characteristic (ROC) curves for the test set in the cases of (a) upsize and (b) downsize. Table S1: Association of chemotherapy response status with tumor grade in the study cohort (p = 0.3287, Fisher\u2019s exact test). Table S2: Association of chemotherapy response status with tumor stage in the study cohort (p = 0.216, Fisher\u2019s exact test). Table S3: Dataset information for chemo-resistant vs. chemo-sensitive classification (number of patients/WSIs, ROIs, and tiles in each category). Table S4: Multivariate analysis of overall survival for the 40-patient test set. Due to the small sample size and class imbalance, the stage and age variables do not show significant effects. The tests are underpowered. This table shows that histopathological score is an independent predictor of survival for the TCGA cohort. Table S5: Multivariate analysis of progression-free survival for the 40-patient test set. Due to the small sample size and class imbalance, the stage and age variables do not show significant effects. The tests are underpowered. This table shows that histopathological score is an independent predictor of progression-free survival for the TCGA cohort.", "sentences": [], "annotations": [], "relations": []}, {"offset": 31161, "infons": {"section_type": "AUTH_CONT", "type": "title"}, "text": "Author Contributions", "sentences": [], "annotations": [], "relations": []}, {"offset": 31182, "infons": {"section_type": "AUTH_CONT", "type": "paragraph"}, "text": "Y.L.: conception of the project, implementation of deep learning and other algorithms, data curation, interpretive analysis, writing (including initial draft). B.C.L.: review and advice on histopathological issues, editing. X.H.: non-histopathological statistical analyses, editing. B.M.B.: computing methodology, editing. J.N.W.: Contributions re study design, methods, results, interpretation, presentation; editing, review. All authors have read and agreed to the published version of the manuscript.", "sentences": [], "annotations": [], "relations": []}, {"offset": 31686, "infons": {"section_type": "SUPPL", "type": "title"}, "text": "Data Availability Statement", "sentences": [], "annotations": [], "relations": []}, {"offset": 31714, "infons": {"section_type": "SUPPL", "type": "paragraph"}, "text": "The data in the paper can be found in the TCGA database (, accessed on 6 August 2023) and all data are publicly available.", "sentences": [], "annotations": [], "relations": []}, {"offset": 31837, "infons": {"section_type": "COMP_INT", "type": "title"}, "text": "Conflicts of Interest", "sentences": [], "annotations": [], "relations": []}, {"offset": 31859, "infons": {"section_type": "COMP_INT", "type": "paragraph"}, "text": "All authors declare no potential conflict of interest.", "sentences": [], "annotations": [], "relations": []}, {"offset": 31914, "infons": {"section_type": "REF", "type": "title"}, "text": "References", "sentences": [], "annotations": [], "relations": []}, {"offset": 31925, "infons": {"fpage": "7", "lpage": "33", "name_0": "surname:Siegel;given-names:R.L.", "name_1": "surname:MIller;given-names:K.D.", "name_2": "surname:Fuchs;given-names:H.E.", "name_3": "surname:Jemal;given-names:A.", "pub-id_doi": "10.3322/caac.21654", "pub-id_pmid": "33433946", "section_type": "REF", "source": "CA Cancer J Clin.", "type": "ref", "volume": "71", "year": "2021"}, "text": "Cancer Statistics, 2021", "sentences": [], "annotations": [], "relations": []}, {"offset": 31949, "infons": {"fpage": "2519", "lpage": "2529", "name_0": "surname:Cannistra;given-names:S.A.", "pub-id_doi": "10.1056/NEJMra041842", "pub-id_pmid": "15590954", "section_type": "REF", "source": "N. Engl. J Med.", "type": "ref", "volume": "351", "year": "2004"}, "text": "Cancer of the ovary", "sentences": [], "annotations": [], "relations": []}, {"offset": 31969, "infons": {"fpage": "63", "lpage": "66", "name_0": "surname:Selvanayagam;given-names:Z.E.", "name_1": "surname:Cheung;given-names:T.H.", "name_2": "surname:Wei;given-names:N.", "name_3": "surname:Chin;given-names:K.V.", "pub-id_doi": "10.1016/j.cancergencyto.2004.01.024", "pub-id_pmid": "15381375", "section_type": "REF", "source": "Cancer Genet. Cytogenet.", "type": "ref", "volume": "154", "year": "2004"}, "text": "Prediction of chemotherapeutic response in ovarian cancer with DNA microarray expression profiling", "sentences": [], "annotations": [], "relations": []}, {"offset": 32068, "infons": {"fpage": "1126", "lpage": "1134", "name_0": "surname:Kulkarni;given-names:P.M.", "name_1": "surname:Robinson;given-names:E.J.", "name_2": "surname:Pradhan;given-names:J.S.", "name_3": "surname:Gartrell-Corrado;given-names:R.D.", "name_4": "surname:Rohr;given-names:B.R.", "name_5": "surname:Trager;given-names:M.H.", "name_6": "surname:Geskin;given-names:L.J.", "name_7": "surname:Kluger;given-names:H.M.", "name_8": "surname:Saenger;given-names:Y.M.", "pub-id_pmid": "31636101", "section_type": "REF", "source": "Clin Cancer Res.", "type": "ref", "volume": "26", "year": "2020"}, "text": "Deep learning based on standard H&E images of primary melanoma tumors identifes patients at risk of visceral recurrence and death", "sentences": [], "annotations": [], "relations": []}, {"offset": 32198, "infons": {"fpage": "20", "lpage": "25", "name_0": "surname:Chetrit;given-names:A.", "name_1": "surname:Hirsh-Yechezkel;given-names:G.", "name_2": "surname:Ben-David;given-names:Y.", "pub-id_doi": "10.1200/JCO.2007.11.6905", "pub-id_pmid": "18165636", "section_type": "REF", "source": "J. Clin. Oncol.", "type": "ref", "volume": "26", "year": "2008"}, "text": "Effect of BRCA1/2 mutations on long-term survival of patients with invasive ovarian cancer: The national Israeli study of ovarian cancer", "sentences": [], "annotations": [], "relations": []}, {"offset": 32335, "infons": {"fpage": "486", "lpage": "494", "name_0": "surname:Liu;given-names:Y.", "name_1": "surname:Yasukawa;given-names:M.", "name_2": "surname:Chen;given-names:K.", "name_3": "surname:Hu;given-names:L.", "name_4": "surname:Broaddus;given-names:R.R.", "name_5": "surname:Ding;given-names:L.", "name_6": "surname:Mardis;given-names:E.R.", "name_7": "surname:Spellman;given-names:P.", "name_8": "surname:Levine;given-names:D.A.", "name_9": "surname:Mills;given-names:G.B.", "pub-id_doi": "10.1001/jamaoncol.2015.1432", "pub-id_pmid": "26181259", "section_type": "REF", "source": "JAMA Oncol.", "type": "ref", "volume": "1", "year": "2015"}, "text": "Association of Somatic Mutations of ADAMTS Genes With Chemotherapy Sensitivity and Survival in High-Grade Serous Ovarian Carcinoma", "sentences": [], "annotations": [], "relations": []}, {"offset": 32466, "infons": {"fpage": "88410", "lpage": "88420", "name_0": "surname:Yasukawa;given-names:M.", "name_1": "surname:Liu;given-names:Y.", "name_2": "surname:Hu;given-names:L.", "name_3": "surname:Cogdell;given-names:D.", "name_4": "surname:Gharpure;given-names:K.M.", "name_5": "surname:Pradeep;given-names:S.", "name_6": "surname:Nagaraja;given-names:A.S.", "name_7": "surname:Sood;given-names:A.K.", "name_8": "surname:Zhang;given-names:W.", "pub-id_doi": "10.18632/oncotarget.11120", "pub-id_pmid": "29179445", "section_type": "REF", "source": "Oncotarget", "type": "ref", "volume": "8", "year": "2016"}, "text": "ADAMTS16 mutations sensitize ovarian cancer cells to platinum-based chemotherapy", "sentences": [], "annotations": [], "relations": []}, {"offset": 32547, "infons": {"fpage": "E131", "lpage": "E138", "name_0": "surname:Huang;given-names:S.", "name_1": "surname:Ingber;given-names:D.E.", "pub-id_doi": "10.1038/13043", "pub-id_pmid": "10559956", "section_type": "REF", "source": "Nat. Cell Biol.", "type": "ref", "volume": "1", "year": "1999"}, "text": "The structural and mechanical complexity of cell-growth control", "sentences": [], "annotations": [], "relations": []}, {"offset": 32611, "infons": {"fpage": "415", "lpage": "425", "name_0": "surname:Capo-chichi;given-names:C.D.", "name_1": "surname:Cai;given-names:K.Q.", "name_2": "surname:Smedberg;given-names:J.", "name_3": "surname:Ganjei-Azar;given-names:P.", "name_4": "surname:Godwin;given-names:A.K.", "name_5": "surname:Xu;given-names:X.X.", "pub-id_pmid": "21627864", "section_type": "REF", "source": "Chin. J. Cancer", "type": "ref", "volume": "30", "year": "2011"}, "text": "Loss of A-type lamin expression compromises nuclear envelope integrity in breast cancer", "sentences": [], "annotations": [], "relations": []}, {"offset": 32699, "infons": {"fpage": "4872", "lpage": "4877", "name_0": "surname:Kilian;given-names:K.A.", "name_1": "surname:Bugarija;given-names:B.", "name_2": "surname:Lahn;given-names:B.T.", "name_3": "surname:Mrksich;given-names:M.", "pub-id_doi": "10.1073/pnas.0903269107", "pub-id_pmid": "20194780", "section_type": "REF", "source": "Proc. Natl. Acad. Sci. USA", "type": "ref", "volume": "107", "year": "2010"}, "text": "Geometric cues for directing the differentiation of mesenchymal stem cells", "sentences": [], "annotations": [], "relations": []}, {"offset": 32774, "infons": {"fpage": "221", "lpage": "248", "name_0": "surname:Shen;given-names:D.", "name_1": "surname:Wu;given-names:G.", "name_2": "surname:Suk;given-names:H.I.", "pub-id_doi": "10.1146/annurev-bioeng-071516-044442", "pub-id_pmid": "28301734", "section_type": "REF", "source": "Annu. Rev. Biomed. Eng.", "type": "ref", "volume": "19", "year": "2017"}, "text": "Deep learning in medical image analysis", "sentences": [], "annotations": [], "relations": []}, {"offset": 32814, "infons": {"fpage": "1", "lpage": "9", "name_0": "surname:Szegedy;given-names:C.", "section_type": "REF", "source": "Proceedings of the the IEEE Conference on Computer Vision and Pattern Recogniztion", "type": "ref"}, "text": "Going Deeper with Convolutions", "sentences": [], "annotations": [], "relations": []}, {"offset": 32845, "infons": {"fpage": "85", "lpage": "117", "name_0": "surname:Schmidhuber;given-names:J.", "pub-id_doi": "10.1016/j.neunet.2014.09.003", "pub-id_pmid": "25462637", "section_type": "REF", "source": "Neural Netw.", "type": "ref", "volume": "61", "year": "2015"}, "text": "Deep learning in neural networks: An overview", "sentences": [], "annotations": [], "relations": []}, {"offset": 32891, "infons": {"fpage": "550", "lpage": "566", "name_0": "surname:Xing;given-names:F.", "name_1": "surname:Xie;given-names:Y.", "name_2": "surname:Yang;given-names:L.", "pub-id_doi": "10.1109/TMI.2015.2481436", "pub-id_pmid": "26415167", "section_type": "REF", "source": "IEEE Trans. Med. Imaging", "type": "ref", "volume": "35", "year": "2016"}, "text": "An automatic learning-based framework for robust nucleus segmentation", "sentences": [], "annotations": [], "relations": []}, {"offset": 32961, "infons": {"fpage": "2032", "name_0": "surname:Simon;given-names:O.", "name_1": "surname:Yacoub;given-names:R.", "name_2": "surname:Jain;given-names:S.", "name_3": "surname:Tomaszewski;given-names:J.E.", "name_4": "surname:Sarder;given-names:P.", "pub-id_doi": "10.1038/s41598-018-20453-7", "pub-id_pmid": "29391542", "section_type": "REF", "source": "Sci. Rep.", "type": "ref", "volume": "8", "year": "2018"}, "text": "Multi-radial LBP features as a tool for rapid glomerular detection and assessment in whole slide histopathology images", "sentences": [], "annotations": [], "relations": []}, {"offset": 33080, "infons": {"fpage": "46450", "name_0": "surname:Cruz-Roa;given-names:A.", "pub-id_doi": "10.1038/srep46450", "pub-id_pmid": "28418027", "section_type": "REF", "source": "Sci. Rep.", "type": "ref", "volume": "7", "year": "2017"}, "text": "Accurate and reproducible invasive breast cancer detection in whole-slide images: A deep learning approach for quantifying tumor extent", "sentences": [], "annotations": [], "relations": []}, {"offset": 33216, "infons": {"fpage": "1196", "lpage": "1206", "name_0": "surname:Sirinukunwattana;given-names:K.", "pub-id_doi": "10.1109/TMI.2016.2525803", "pub-id_pmid": "26863654", "section_type": "REF", "source": "IEEE Trans. Med. Imaging", "type": "ref", "volume": "35", "year": "2016"}, "text": "Locality sensitive deep learning for detection and classificaiton of nuclei in routine colon cancer histology images", "sentences": [], "annotations": [], "relations": []}, {"offset": 33333, "infons": {"fpage": "157", "lpage": "164", "name_0": "surname:Linder;given-names:N.", "name_1": "surname:Taylor;given-names:J.C.", "name_2": "surname:Colling;given-names:R.", "name_3": "surname:Pell;given-names:R.", "name_4": "surname:Alveyn;given-names:E.", "name_5": "surname:Joseph;given-names:J.", "pub-id_doi": "10.1136/jclinpath-2018-205328", "pub-id_pmid": "30518631", "section_type": "REF", "source": "J. Clin. Pathol.", "type": "ref", "volume": "72", "year": "2019"}, "text": "Deep learning for detecting tumour-infiltraing lymphocytes in testicular germ cell tumours", "sentences": [], "annotations": [], "relations": []}, {"offset": 33424, "infons": {"fpage": "181", "lpage": "193", "name_0": "surname:Saltz;given-names:J.", "name_1": "surname:Gupta;given-names:R.", "name_2": "surname:Hou;given-names:L.", "name_3": "surname:Kurc;given-names:T.", "name_4": "surname:Singh;given-names:P.", "name_5": "surname:Nguyen;given-names:V.", "pub-id_doi": "10.1016/j.celrep.2018.03.086", "pub-id_pmid": "29617659", "section_type": "REF", "source": "Cell Rep.", "type": "ref", "volume": "23", "year": "2018"}, "text": "Spatial organization and molecular correlaton of tumor-infiltrating lymphocytes usng deep learning on pathology images", "sentences": [], "annotations": [], "relations": []}, {"offset": 33543, "infons": {"fpage": "3941", "name_0": "surname:Xia;given-names:D.", "name_1": "surname:Casanova;given-names:R.", "name_2": "surname:Machiraju;given-names:D.", "name_3": "surname:McKee;given-names:T.D.", "name_4": "surname:Weder;given-names:W.", "name_5": "surname:Beck;given-names:A.H.", "pub-id_doi": "10.1038/s41598-018-22254-4", "pub-id_pmid": "29500362", "section_type": "REF", "source": "Sci. Rep.", "type": "ref", "volume": "8", "year": "2018"}, "text": "Computatoinally-guided development of a stromal inflammation histologic biomarker in lung squamous cell carcinoma", "sentences": [], "annotations": [], "relations": []}, {"offset": 33657, "infons": {"fpage": "1502", "lpage": "1512", "name_0": "surname:Ehteshami;given-names:B.B.", "name_1": "surname:Mullooly;given-names:M.", "name_2": "surname:Pfeiffer;given-names:R.M.", "name_3": "surname:FAn;given-names:S.", "name_4": "surname:Vacek;given-names:P.M.", "name_5": "surname:Weaver;given-names:D.L.", "pub-id_doi": "10.1038/s41379-018-0073-z", "pub-id_pmid": "29899550", "section_type": "REF", "source": "Mod. Pathol.", "type": "ref", "volume": "31", "year": "2018"}, "text": "Using deep convolutional neural networks to identify and classify tumor-associated stroma in diagnostic breast biopsies", "sentences": [], "annotations": [], "relations": []}, {"offset": 33777, "infons": {"fpage": "12054", "name_0": "surname:Arvaniti;given-names:E.", "name_1": "surname:Fricker;given-names:K.S.", "name_2": "surname:Moret;given-names:M.", "name_3": "surname:Rupp;given-names:N.", "name_4": "surname:Hermanns;given-names:T.", "name_5": "surname:Frankhauser;given-names:C.", "pub-id_doi": "10.1038/s41598-018-30535-1", "pub-id_pmid": "30104757", "section_type": "REF", "source": "Sci. Rep.", "type": "ref", "volume": "8", "year": "2018"}, "text": "Automated Gleason grading of prostate cancer tissue microarrays via deep learning", "sentences": [], "annotations": [], "relations": []}, {"offset": 33859, "infons": {"fpage": "2585", "lpage": "2593", "name_0": "surname:Casanova;given-names:R.", "name_1": "surname:Xia;given-names:D.", "name_2": "surname:Rulle;given-names:U.", "name_3": "surname:Nanni;given-names:P.", "name_4": "surname:Grossmann;given-names:J.", "name_5": "surname:Vrugt;given-names:B.", "pub-id_doi": "10.1158/0008-5472.CAN-16-2363", "pub-id_pmid": "28364001", "section_type": "REF", "source": "Cancer Res.", "type": "ref", "volume": "77", "year": "2017"}, "text": "Morphoproteomic characterization of lung squamous cell carcinoma fragmentation, a histological marker of increased tumor invasiveness", "sentences": [], "annotations": [], "relations": []}, {"offset": 33993, "infons": {"fpage": "1559", "lpage": "1567", "name_0": "surname:Coudray;given-names:N.", "name_1": "surname:Sakellaropoulos;given-names:P.S.", "name_2": "surname:Sakellaropoulos;given-names:T.", "name_3": "surname:Narula;given-names:N.", "name_4": "surname:Snuder;given-names:M.", "name_5": "surname:Fenyo;given-names:D.", "pub-id_doi": "10.1038/s41591-018-0177-5", "pub-id_pmid": "30224757", "section_type": "REF", "source": "Nat. Med.", "type": "ref", "volume": "24", "year": "2018"}, "text": "Classification and mutation prediction from non-small cell lung cancer histopathology images using deep learning", "sentences": [], "annotations": [], "relations": []}, {"offset": 34106, "infons": {"fpage": "14", "name_0": "surname:Chen;given-names:M.", "name_1": "surname:Zhang;given-names:B.", "name_2": "surname:Topatana;given-names:W.", "name_3": "surname:Cao;given-names:J.", "name_4": "surname:Zhu;given-names:H.", "name_5": "surname:Juengpanich;given-names:S.", "name_6": "surname:Mao;given-names:Q.", "name_7": "surname:Yu;given-names:H.", "name_8": "surname:Cai;given-names:X.", "pub-id_pmid": "32550270", "section_type": "REF", "source": "npj Precis. Oncol.", "type": "ref", "volume": "4", "year": "2020"}, "text": "Classification and mutation prediction based on histopathology H&E images in liver cancer using deep learning", "sentences": [], "annotations": [], "relations": []}, {"offset": 34216, "infons": {"fpage": "29", "name_0": "surname:Wu;given-names:M.", "name_1": "surname:Yan;given-names:C.", "name_2": "surname:Liu;given-names:H.", "name_3": "surname:Liu;given-names:Q.", "pub-id_doi": "10.1042/BSR20180289", "section_type": "REF", "source": "Biosci. Rep.", "type": "ref", "volume": "38", "year": "2018"}, "text": "Automatic classification of ovarian cancer types from cytological images using deep convolutional neural networks", "sentences": [], "annotations": [], "relations": []}, {"offset": 34330, "infons": {"fpage": "105815", "name_0": "surname:Shin;given-names:S.J.", "name_1": "surname:You;given-names:S.C.", "name_2": "surname:Jeon;given-names:H.", "name_3": "surname:Jung;given-names:J.W.", "name_4": "surname:An;given-names:M.H.", "name_5": "surname:Park;given-names:R.W.", "name_6": "surname:Roh;given-names:J.", "pub-id_doi": "10.1016/j.cmpb.2020.105815", "pub-id_pmid": "33160111", "section_type": "REF", "source": "Comput. Methods Programs Biomed.", "type": "ref", "volume": "198", "year": "2021"}, "text": "Style transfer strategy for developing a generalizable deep learning application in digital pathology", "sentences": [], "annotations": [], "relations": []}, {"offset": 34432, "infons": {"fpage": "102093", "name_0": "surname:Wang;given-names:C.W.", "name_1": "surname:Chang;given-names:C.C.", "name_2": "surname:Lee;given-names:Y.C.", "name_3": "surname:Lin;given-names:Y.J.", "name_4": "surname:Lo;given-names:S.C.", "name_5": "surname:Hsu;given-names:P.C.", "name_6": "surname:Liou;given-names:Y.A.", "name_7": "surname:Wang;given-names:C.H.", "name_8": "surname:Chao;given-names:T.K.", "pub-id_doi": "10.1016/j.compmedimag.2022.102093", "section_type": "REF", "source": "Comput. Medican Imaging Graph.", "type": "ref", "volume": "99", "year": "2022"}, "text": "Weakly supervised deep learning for prediciton of treatment effectiveness on ovarian cancer from histopathology images", "sentences": [], "annotations": [], "relations": []}, {"offset": 34551, "infons": {"fpage": "19165", "name_0": "surname:Laury;given-names:A.R.", "name_1": "surname:Blom;given-names:S.", "name_2": "surname:Ropponen;given-names:T.", "name_3": "surname:Virtanen;given-names:A.", "name_4": "surname:Carpen;given-names:O.M.", "pub-id_doi": "10.1038/s41598-021-98480-0", "pub-id_pmid": "34580357", "section_type": "REF", "source": "Sci. Rep.", "type": "ref", "volume": "11", "year": "2021"}, "text": "Artificial intelligence-based image analysis can predict outcome in high-grade serous carcinoma via histology alone", "sentences": [], "annotations": [], "relations": []}, {"offset": 34667, "infons": {"elocation-id": "236", "name_0": "surname:Yu;given-names:K.H.", "name_1": "surname:Hu;given-names:V.", "name_2": "surname:Wang;given-names:F.", "name_3": "surname:Matulonis;given-names:U.A.", "name_4": "surname:Mutter;given-names:G.I.", "name_5": "surname:Golden;given-names:J.A.", "name_6": "surname:Kohane;given-names:I.S.", "pub-id_doi": "10.1186/s12916-020-01684-w", "pub-id_pmid": "32807164", "section_type": "REF", "source": "BMC Med.", "type": "ref", "volume": "18", "year": "2020"}, "text": "Deciphering serous ovarian carcinoma histopathology and platinum-response by convolutional neural networks", "sentences": [], "annotations": [], "relations": []}, {"offset": 34774, "infons": {"fpage": "102164", "name_0": "surname:Akazawa;given-names:M.", "name_1": "surname:Hashimoto;given-names:K.", "pub-id_doi": "10.1016/j.artmed.2021.102164", "pub-id_pmid": "34629152", "section_type": "REF", "source": "Artif. Intell. Med.", "type": "ref", "volume": "120", "year": "2021"}, "text": "Artificial intelligence in gynecologic cancers: Current status and future challenges\u2014A systematic review", "sentences": [], "annotations": [], "relations": []}, {"offset": 34881, "infons": {"elocation-id": "e36383", "name_0": "surname:Liu;given-names:Y.", "name_1": "surname:Sun;given-names:Y.", "name_2": "surname:Broaddus;given-names:R.", "name_3": "surname:Liu;given-names:J.", "name_4": "surname:Sood;given-names:A.K.", "name_5": "surname:Shmulevich;given-names:J.", "name_6": "surname:Zhang;given-names:W.", "pub-id_doi": "10.1371/journal.pone.0036383", "pub-id_pmid": "22590536", "section_type": "REF", "source": "PLoS ONE", "type": "ref", "volume": "7", "year": "2012"}, "text": "Integrated analysis of gene expression and tumor nuclear image profiles associated with chemotherapy response in serous ovarian carcinoma", "sentences": [], "annotations": [], "relations": []}, {"offset": 35019, "infons": {"fpage": "2818", "lpage": "2826", "name_0": "surname:Szegedy;given-names:C.", "name_1": "surname:Vanhoucke;given-names:V.", "name_2": "surname:Ioffe;given-names:S.", "name_3": "surname:Slens;given-names:J.", "name_4": "surname:Wojna;given-names:Z.", "section_type": "REF", "source": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition", "type": "ref"}, "text": "Rethinking the Inception Architecture for Computer Vision", "sentences": [], "annotations": [], "relations": []}, {"offset": 35077, "infons": {"fpage": "609", "lpage": "615", "pub-id_doi": "10.1038/nature10166", "pub-id_pmid": "21720365", "section_type": "REF", "source": "Nature", "type": "ref", "volume": "474", "year": "2011"}, "text": "Integrated genomic analyses of ovarian carcinoma", "sentences": [], "annotations": [], "relations": []}, {"offset": 35126, "infons": {"fpage": "29", "lpage": "36", "name_0": "surname:Hanley;given-names:J.A.", "name_1": "surname:McNeil;given-names:B.J.", "pub-id_doi": "10.1148/radiology.143.1.7063747", "pub-id_pmid": "7063747", "section_type": "REF", "source": "Radiology", "type": "ref", "volume": "143", "year": "1982"}, "text": "The meaning and use of the area under a receiver operating characteristic (ROC) curve", "sentences": [], "annotations": [], "relations": []}, {"offset": 35212, "infons": {"fpage": "419", "lpage": "430", "name_0": "surname:Ruopp;given-names:M.D.", "name_1": "surname:Perkins;given-names:N.J.", "name_2": "surname:Whitcomb;given-names:B.W.", "name_3": "surname:Schisterman;given-names:E.F.", "pub-id_doi": "10.1002/bimj.200710415", "pub-id_pmid": "18435502", "section_type": "REF", "source": "Biom. J.", "type": "ref", "volume": "50", "year": "2008"}, "text": "Youden index and optimal cut-point estimated from observations affected by a lower limit of detection", "sentences": [], "annotations": [], "relations": []}, {"offset": 35314, "infons": {"fpage": "457", "lpage": "481", "name_0": "surname:Kaplan;given-names:E.L.", "name_1": "surname:Meier;given-names:P.", "pub-id_doi": "10.1080/01621459.1958.10501452", "section_type": "REF", "source": "J. Amer. Statist. Assoc.", "type": "ref", "volume": "53", "year": "1958"}, "text": "Nonparametric estimation from incomplete observations", "sentences": [], "annotations": [], "relations": []}, {"offset": 35368, "infons": {"name_0": "surname:Zeiler;given-names:M.D.", "name_1": "surname:Fergus;given-names:R.", "name_2": "surname:Fleet;given-names:D.", "name_3": "surname:Fleet;given-names:D.", "name_4": "surname:Pajdla;given-names:T.", "name_5": "surname:Schiele;given-names:B.", "name_6": "surname:Tuytelaars;given-names:T.", "section_type": "REF", "source": "Visualizing and Understanding Convolutional Networks", "type": "ref", "year": "2014"}, "text": "", "sentences": [], "annotations": [], "relations": []}, {"offset": 35369, "infons": {"fpage": "775", "lpage": "784", "name_0": "surname:Laak;given-names:J.", "name_1": "surname:Litjens;given-names:G.", "name_2": "surname:Ciompi;given-names:F.", "pub-id_doi": "10.1038/s41591-021-01343-4", "pub-id_pmid": "33990804", "section_type": "REF", "source": "Nat. Med.", "type": "ref", "volume": "27", "year": "2021"}, "text": "Deep learning in histopathology: The path to the clinic", "sentences": [], "annotations": [], "relations": []}, {"offset": 35425, "infons": {"fpage": "628", "lpage": "629", "name_0": "surname:Weinstein;given-names:J.N.", "pub-id_doi": "10.1126/science.282.5389.627g", "pub-id_pmid": "9841413", "section_type": "REF", "source": "Science", "type": "ref", "volume": "282", "year": "1998"}, "text": "Fishing expeditions", "sentences": [], "annotations": [], "relations": []}, {"offset": 35445, "infons": {"file": "cancers-15-04044-g001.jpg", "id": "cancers-15-04044-f001", "section_type": "FIG", "type": "fig_caption"}, "text": "Computational pipeline for training and testing the deep learning model. (a), A tile datastore was generated from images of ovarian cancer tissues. (b), Tiles were then separated into training, validation, and held-out test sets. (c), The Inception V3 architecture was fully trained using the training and validation tiles. (d), Testing was performed on tiles from the test set and then aggregated per slide (i.e., per patient) to extract the ROC statistics.", "sentences": [], "annotations": [], "relations": []}, {"offset": 35904, "infons": {"file": "cancers-15-04044-g002.jpg", "id": "cancers-15-04044-f002", "section_type": "FIG", "type": "fig_caption"}, "text": "Testing and tile aggregation pipeline. (a), Tiles from test slides. (b), The trained deep learning network. (c), The predicted probabilities for all the tiles. (d), Tile aggregation per ROI. (e), ROI aggregation per slide. (f), Class prediction on the basis of slide probability.", "sentences": [], "annotations": [], "relations": []}, {"offset": 36184, "infons": {"file": "cancers-15-04044-g003.jpg", "id": "cancers-15-04044-f003", "section_type": "FIG", "type": "fig_caption"}, "text": "Classification of chemotherapy response status on a test set of 40 ovarian cancer patients. (a), Distribution of predicted slide probabilities of chemotherapy response (i.e., resistant or sensitive) with slide probability calculated after tile aggregation. (b), Receiver operating characteristic (ROC) curve from the first random test set of 40 slides. (c), Illustrative confusion matrix for the test set. (d), Test-set receiver operating characteristic (ROC) curves for 16 random training set samplings.", "sentences": [], "annotations": [], "relations": []}, {"offset": 36689, "infons": {"file": "cancers-15-04044-g004.jpg", "id": "cancers-15-04044-f004", "section_type": "FIG", "type": "fig_caption"}, "text": "Association of the slide probabilities with patient overall survival (a) and progression-free survival (b). Note that this result is not independent of optimization through selection of the Youden J-index cut point.", "sentences": [], "annotations": [], "relations": []}, {"offset": 36905, "infons": {"file": "cancers-15-04044-g005.jpg", "id": "cancers-15-04044-f005", "section_type": "FIG", "type": "fig_caption"}, "text": "Visualization of chemotherapy-response-associated features in representative tile images identified by the deep learning model. (a), A high-confidence tile image predicted by the deep learning network to be from a sensitive tumor with a probability score of 0.98. (b), Occlusion sensitivity analysis (OSA) map for the sensitive class. (c), Image superimposing the OSA map on the original tile image. (d), An ambiguous tile image predicted to have essentially identical scores for sensitivity and resistance. (e), OSA map for the resistant class for (d). (f), Image superimposing the OSA map on the original tile image (d).", "sentences": [], "annotations": [], "relations": []}, {"offset": 37528, "infons": {"file": "cancers-15-04044-t001.xml", "id": "cancers-15-04044-t001", "section_type": "TABLE", "type": "table_caption"}, "text": "Clinicopathologic characteristics of TCGA patients with serous OvCa in the cohort used for training, validating, and testing the convolutional neural network system.", "sentences": [], "annotations": [], "relations": []}, {"offset": 37694, "infons": {"file": "cancers-15-04044-t001.xml", "id": "cancers-15-04044-t001", "section_type": "TABLE", "type": "table", "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<table frame=\"hsides\" rules=\"groups\"><thead><tr><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">No. of Patients</th><th colspan=\"3\" align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\">248</th></tr></thead><tbody><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Chemotherapy response <sup>\u03be</sup></td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Resistant</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">74</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Sensitive</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">174</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Age</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Mean, years [SD]</td><td colspan=\"3\" align=\"center\" valign=\"middle\" rowspan=\"1\">60.0 [11.4]</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Range</td><td colspan=\"3\" align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\">30.5\u201387.5</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">FIGO Stage <sup>\u00b6</sup></td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">II</td><td colspan=\"3\" align=\"center\" valign=\"middle\" rowspan=\"1\">13</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">III</td><td colspan=\"3\" align=\"center\" valign=\"middle\" rowspan=\"1\">196</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">IV</td><td colspan=\"3\" align=\"center\" valign=\"middle\" rowspan=\"1\">36</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Unknown</td><td colspan=\"3\" align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\">3</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">WHO Grade</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">2</td><td colspan=\"3\" align=\"center\" valign=\"middle\" rowspan=\"1\">37</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">3</td><td colspan=\"3\" align=\"center\" valign=\"middle\" rowspan=\"1\">204</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Unknown</td><td colspan=\"3\" align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\">7</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Vital status</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Alive</td><td colspan=\"3\" align=\"center\" valign=\"middle\" rowspan=\"1\">94</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Dead</td><td colspan=\"3\" align=\"center\" valign=\"middle\" rowspan=\"1\">150</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Unknown</td><td colspan=\"3\" align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\">4</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Recurrent disease <sup>\u03b6</sup></td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Yes</td><td colspan=\"3\" align=\"center\" valign=\"middle\" rowspan=\"1\">216</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">No</td><td colspan=\"3\" align=\"center\" valign=\"middle\" rowspan=\"1\">29</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Unknown</td><td colspan=\"3\" align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\">3</td></tr></tbody></table>\n"}, "text": "No. of Patients\t248\t \tChemotherapy response \u03be\t\t\t\t \tResistant\t\t74\t\t \tSensitive\t\t174\t\t \tAge\t\t\t\t \tMean, years [SD]\t60.0 [11.4]\t \tRange\t30.5\u201387.5\t \tFIGO Stage \u00b6\t\t\t\t \tII\t13\t \tIII\t196\t \tIV\t36\t \tUnknown\t3\t \tWHO Grade\t\t\t\t \t2\t37\t \t3\t204\t \tUnknown\t7\t \tVital status\t\t\t\t \tAlive\t94\t \tDead\t150\t \tUnknown\t4\t \tRecurrent disease \u03b6\t\t\t\t \tYes\t216\t \tNo\t29\t \tUnknown\t3\t \t", "sentences": [], "annotations": [], "relations": []}, {"offset": 38049, "infons": {"file": "cancers-15-04044-t001.xml", "id": "cancers-15-04044-t001", "section_type": "TABLE", "type": "table_footnote"}, "text": "Abbreviations: TCGA, The Cancer Genome Atlas; FIGO, International Federation of Gynecology and Obstetrics; SD, standard deviation; WHO, World Health Organization. \u03be: Platinum status was defined as resistant if the platinum-free interval was less than 6 months and the patient experienced progression or recurrence. It was defined as sensitive if the platinum-free interval was 6 months or more and there was no evidence of progression or recurrence. \u00b6: Cases were staged according to the 1988 FIGO staging system. \u03b6: Local recurrence after the date of initial surgical resection.", "sentences": [], "annotations": [], "relations": []}], "annotations": [], "relations": []}]}]