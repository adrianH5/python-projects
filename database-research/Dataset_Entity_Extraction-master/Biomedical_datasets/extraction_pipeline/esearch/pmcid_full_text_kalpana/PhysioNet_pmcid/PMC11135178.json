[{"bioctype": "BioCCollection", "source": "PMC", "date": "20240819", "key": "pmc.key", "version": "1.0", "infons": {}, "documents": [{"bioctype": "BioCDocument", "id": "11135178", "infons": {"license": "CC BY"}, "passages": [{"bioctype": "BioCPassage", "offset": 0, "infons": {"article-id_doi": "10.1088/1361-6579/ad4954", "article-id_other": "PMEA-105607.R1", "article-id_pmc": "11135178", "article-id_pmid": "39150768", "article-id_publisher-id": "pmeaad4954", "article-id_publisher-manuscript": "ad4954", "elocation-id": "055019", "issue": "5", "kwd": "electrocardiogram (ECG) ECG digitization deep learning synthetic data data augmentation denoising CNN", "license": "\nOriginal content from this work may be used under the terms of the Creative Commons Attribution 4.0 license. Any further distribution of this work must maintain attribution to the author(s) and the title of the work, journal citation and DOI.", "name_0": "surname:Shivashankara;given-names:Kshama Kodthalu", "name_1": "surname:Deepanshi", "name_2": "surname:Mehri Shervedani;given-names:Afagh", "name_3": "surname:Clifford;given-names:Gari D", "name_4": "surname:Reyna;given-names:Matthew A", "name_5": "surname:Sameni;given-names:Reza", "section_type": "TITLE", "type": "front", "volume": "45", "year": "2024"}, "text": "ECG-Image-Kit: a synthetic image generation toolbox to facilitate deep learning-based electrocardiogram digitization", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 117, "infons": {"section_type": "ABSTRACT", "type": "abstract_title_1"}, "text": "Abstract", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 126, "infons": {"section_type": "ABSTRACT", "type": "abstract"}, "text": " Objective. Cardiovascular diseases are a major cause of mortality globally, and electrocardiograms (ECGs) are crucial for diagnosing them. Traditionally, ECGs are stored in printed formats. However, these printouts, even when scanned, are incompatible with advanced ECG diagnosis software that require time-series data. Digitizing ECG images is vital for training machine learning models in ECG diagnosis, leveraging the extensive global archives collected over decades. Deep learning models for image processing are promising in this regard, although the lack of clinical ECG archives with reference time-series data is challenging. Data augmentation techniques using realistic generative data models provide a solution. Approach. We introduce ECG-Image-Kit, an open-source toolbox for generating synthetic multi-lead ECG images with realistic artifacts from time-series data, aimed at automating the conversion of scanned ECG images to ECG data points. The tool synthesizes ECG images from real time-series data, applying distortions like text artifacts, wrinkles, and creases on a standard ECG paper background. Main results. As a case study, we used ECG-Image-Kit to create a dataset of 21\u2009801 ECG images from the PhysioNet QT database. We developed and trained a combination of a traditional computer vision and deep neural network model on this dataset to convert synthetic images into time-series data for evaluation. We assessed digitization quality by calculating the signal-to-noise ratio and compared clinical parameters like QRS width, RR, and QT intervals recovered from this pipeline, with the ground truth extracted from ECG time-series. The results show that this deep learning pipeline accurately digitizes paper ECGs, maintaining clinical parameters, and highlights a generative approach to digitization. Significance. The toolbox has broad applications, including model development for ECG image digitization and classification. The toolbox currently supports data augmentation for the 2024 PhysioNet Challenge, focusing on digitizing and classifying paper ECG images.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 2217, "infons": {"section_type": "INTRO", "type": "title_1"}, "text": "Introduction", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 2230, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Cardiovascular diseases (CVDs) are the primary cause of mortality globally among adults aged 37\u201370 years (Dagenais), and the electrocardiogram (ECG) is the most accessible and widely used tool for CVD diagnosis. Clinical ECG is most accurately studied through standard 12-lead recordings. Every day, clinicians conduct millions of ECGs, and wearable and personal devices generate millions more. There are billions of digital diagnostic ECGs globally and billions more in conventional formats such as microfilms, printed papers and scanned images. Although this legacy contains invaluable information on prevalent and rare CVDs and their evolution across generations and geography, we are not currently \u2018learning\u2019 from ECG archives. Due to natural deterioration, lack of funding and a transition to digital ECGs, non-digital ECG archives worldwide will soon be destroyed, before we can learn from them. This will be an irreversible loss for CVD research, especially for low and low and middle-income countries (LMICs), where paper ECGs are still more common. Importantly, the ECG is the only biological signal which has been acquired globally for decades, without significant changes in its acquisition protocol. As a result, ECG data is abundant, and beyond human experts\u2019 capacity in prescreening these data. Machine learning (ML) algorithms can help automate the process of ECG-based diagnostic decision-making. However, paper ECGs or scanned ECG images are not compatible with state-of-the-art ML algorithms that are trained and tested on ECG time-series. Although non-digital ECGs can be scanned and archived as images, there is little incentive to do so; because currently ECG images are not automatically searchable for anomalies, and are incompatible with annotation software that analyze ECG time-series (Siontis et al ). For example, ECG biomarkers, such as RR, PR, QRS, QT intervals, waveforms and rhythms are easily accessible from ECG time-series and could help improve the performance of existing ML models. Digitization of the existing paper ECG archives is therefore essential.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 4331, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Furthermore, access to paper ECGs are limited primarily by privacy concerns, as they contain personal and sensitive information. The Health Insurance Portability and Accountability Act (HIPAA) mandates safeguards for protecting the privacy of health information, often necessitating patient consent for data usage, thereby reducing the availability of open-source datasets for training ML models (Annas). Consequently, there is a growing interest in modeling ECGs synthetically in a privacy-preserving way. Our work focuses on producing synthetic paper-like ECG images from ground truth time-series data, facilitating the training of ML and deep learning digitization solutions within privacy constraints. We demonstrate the toolbox\u2019s utility by developing a deep learning ECG digitization model and extracting clinical parameters to establish the accuracy of the model for clinical applications. Our developed tool for synthetic ECG image generation and digitization has been implemented in Python and is available online in the ECG-Image-Kit toolbox: https://github.com/alphanumericslab/ecg-image-kit. The toolbox has also been used for the 2024 PhysioNet Challenge on the digitization and classification of ECG images (George B. Moody PhysioNet Challenge, PhysioNet)", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 5603, "infons": {"section_type": "INTRO", "type": "title_1"}, "text": "Related work", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 5616, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The growing interest in generating realistic synthetic data and digital twins, driven by privacy preservation and HIPAA mandates, has led to innovations in synthetic medical data generation, especially in electronic health records (EHR). Weldon et al utilized a federated generative adversarial network (GAN) for EHR generation; Choi et al demonstrated EHR generation through medGAN; and EHR-Safe proposed a sequential encoder-decoder architecture with GANs (Yoon).", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 6082, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Accurate ECG digitization is crucial for advancing cardiology patient treatment and research. Automated analysis of digitized ECGs facilitates early cardiovascular disease diagnosis.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 6265, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "In the ECG context, various digitization methods have been proposed; including the grayscale thresholding and contour-based digitization method by Ravichandran et al, color segmentation and median filtering for noise removal by Garg et al, and the combination of optical character recognition (OCR) with image processing techniques for digitization and artifact removal (Baydoun et al , Ganesh et al ). However, classical image processing methods, sensitive to input quality and environmental artifacts, often struggle with low-quality, distorted paper ECG records.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 6831, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Recent advancements in deep learning have also been applied to the digitization of paper ECG records. Mishra et al used deep learning to determine the binarization threshold for grid removal. Li et al approached digitization as a segmentation problem, employing the U-Net architecture for digitizing noisy ECG scans. These methods are effective but face limitations due to a lack of diverse noise artifacts, such as handwritten text and environmental reflections, in the training datasets. Additionally, there is a scarcity of paper ECG records with ground truth time-series data representing noisy records.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 7439, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Our research addresses these gaps by utilizing deep learning for paper ECG digitization and enriching the training dataset with synthetic images from realistic generative models. Numerous studies have illustrated synthetic time-series ECG generation, from dynamical models simulating adult and fetal ECGs (McSharry et al , Sameni et al ) to artificial vector models for abnormal rhythms (Clifford et al ) and signal decomposition for morphological modeling (Roonizi and Sameni). Recent advances include GAN-based synthetic ECG generation, with applications ranging from simulating various cardiac conditions (Zhu et al , Wulan et al , Zhang and Babaeizadeh) to creating comprehensive repositories of DeepFake ECGs (Thambawita). These developments underscore the feasibility of generating synthetic time-series ECG using generative models. Our approach uniquely combines privacy-preserving synthetic ECG image generation with standard paper ECG backgrounds and sequential artifact addition, creating synthetic paper-like ECG images with underlying real ECG time-series data.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 8513, "infons": {"section_type": "INTRO", "type": "title_1"}, "text": "Synthetic ECG image generation pipeline", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 8553, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The proposed methodology involves multiple stages. First, a synthetic paper ECG dataset is created. This process includes adding distortions step-by-step to time-series data plotted on standard ECG grids, as shown in figure 1 and detailed in the sequel.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 8807, "infons": {"file": "pmeaad4954f1_hr.jpg", "id": "pmeaad4954f1", "section_type": "FIG", "type": "fig_caption"}, "text": "Proposed pipeline for generating synthetic ECG images.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 8862, "infons": {"section_type": "INTRO", "type": "title_2"}, "text": "Background", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 8873, "infons": {"section_type": "INTRO", "type": "title_3"}, "text": "The standard ECG paper format", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 8903, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Standard surface ECG acquisition records heart activity using a 12-lead system with ten electrodes on the body, including the limbs and chest. This setup includes three limb leads (I, II, III), three augmented limb leads (aVR, aVL, aVF), and six precordial leads (V1\u2013V6). These leads, despite some geometrical redundancy, offer comprehensive cardiac perspectives, crucial for diagnosing arrhythmias, myocardial infarction, and other heart conditions (Malmivuo and Plonsey). The limb leads provide frontal plane views, while precordial leads assess the heart\u2019s horizontal plane. Recent advancements include reduced lead ECG systems, using fewer electrodes with computational methods, including machine and deep learning, to reconstruct a complete 12-lead ECG (Alday, Reyna, Dwivedi et al , Whyte et al ).", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 9711, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Conventionally, analog and digital ECG machines printed ECGs on so-called thermal paper at a horizontal speed of 25 mm s\u22121 and a vertical scale of 1\u2009mV per 10 mm. Modern ECG machines, whether printing hard copies or generating PDF images, use the same convention. The standard paper ECG features two grids: a coarse grid of 5 mm \u00d7 5 mm corresponding to 0.5\u2009mV in the vertical (amplitude) and 0.2 s in the horizontal (time) directions, and a fine grid of 1 mm \u00d7 1 mm corresponding to 0.1\u2009mV vertically and 40 ms horizontally, as shown in figure 2. Historically, a calibration pulse of 1\u2009mV amplitude and 0.2 s width is also printed on most paper ECGs (Luthra).", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 10383, "infons": {"file": "pmeaad4954f2_hr.jpg", "id": "pmeaad4954f2", "section_type": "FIG", "type": "fig_caption"}, "text": "The standard grid on printed ECG papers/images.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 10431, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "While most paper ECG grids are red-pink in color, there is no widely accepted standard for ECG paper color. Modern digital ECGs are typically generated as PDF files appropriate for printing on A4 or US Letter-sized papers. Standard paper ECGs usually display all 12 leads in 2.5 s segments over four rows. Additionally, leads II, V1, V2, or V5 are often plotted as a continuous 10 s strip at the bottom, for rhythm analysis. Older ECG machines swept the 2.5 s segments across different leads asynchronously. Therefore, the 2.5 s segments of the different leads did not correspond to the same time frame. This is an important point of caution for ECG digitization algorithms, as they would not be able to benefit from the synchrony of the channel segments to improve the extracted ECG time-series through multichannel post-processing. However, the long strip(s), do overlap with the shorter segments.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 11331, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Although the majority of paper ECG records follow the 12-lead representation (3 \u00d7 4 segments + 1 strip), there are printed ECGs that do not adhere to this format. To account for the variability across real paper ECG records, ECG-Image-Kit enables users to adjust the lead format.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 11612, "infons": {"section_type": "INTRO", "type": "title_3"}, "text": "ECG image vs time-series temporal and amplitude resolutions", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 11672, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The ECG digitization process involves several key parameters: the length of the ECG segment T (in seconds), the time-series sampling frequency , the scanned image resolution in dots-per-inch (DPI, denoted as D), and the amplitude resolution, which in digital ECG devices is related to the analog-to-digital converter (ADC) resolution and the analog input dynamic range. Understanding these parameters is crucial for aligning the digitized ECG with the original time-series.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 12146, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Printing and rescanning an ECG involves interpolation and resampling. In analog devices or printers, this process converts discrete time samples into a continuous waveform on paper. Therefore, the original sampling frequency  and the ADC resolution become irrelevant once printed, as the signal reverts to a continuous form. Upon scanning, the ECG is quantized and resampled as a two-dimensional image at a resolution of D DPI, i.e. each 1-inch square of the ECG is digitized into a D\u2009\u00d7\u2009D array, each pixel represented in B bits. Typically, B\u2009=\u20098, yielding 24 bits or 3 bytes per pixel. As a result, when a standard ECG is printed on paper, at the correct scale, and then scanned, each 1-inch segment corresponds to D pixels horizontally and vertically. So each coarse ECG square (0.5\u2009mV amplitude, 200 ms time) maps to a square of  pixels. Therefore, the amplitude resolution of the scanned ECG is  millivolts, and the temporal resolution is  seconds, resulting in an image-based sampling frequency of  As we see, the image-based sampling frequency is independent of the original , and increasing D yields smoother waveforms but does not add information beyond  (which is bounded by the anti-aliasing filter of the original ECG device\u2019s analog front-end). As a rule of thumb, from (1), we may conclude that in order to preserve the typical ECG spectrum that is dominantly below 100 Hz, a resolution of at least 200 DPI is recommended for ECG scanning and digitization (assuming that the image is full-screen, utilizing all the image DPI for the ECG image).", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 13717, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The accurate calculation of ECG grid size from the image DPI and paper size is reliable only when using a standard full-paper size scanner. However, for ECG images captured by cameras, smartphones, screenshots, or altered through cropping, resizing or compression, the equivalency of 1 inch on the actual paper to the captured image DPI may not be accurate. Therefore, image file metadata DPI can be unreliable for recovering pixel-wise time and amplitude resolutions. In this case, ECG digitization algorithms may employ techniques that directly analyze the ECG grid sizes from the image, using image processing methods that for instance utilize pixel marginal distributions or spectral methods to detect the regular ECG grid patterns. ECG-Image-Kit offers multiple algorithms for these purposes.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 14515, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "In the final stage, to recover the ECG time-series at its original sampling frequency, the digitized signal can be resampled from  back to , using a conventional or fractional resampler. This enables alignment and comparison between the original and reconstruction time-series. This step is also crucial for maintaining the integrity of the ECG data and ECG-based measurements, including RR-intervals and QT-intervals.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 14934, "infons": {"section_type": "INTRO", "type": "title_3"}, "text": "The ECG time-series dataset used for model training", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 14986, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The synthetic paper ECG generation pipeline requires time-series data as the ground truth. For this purpose, we used the PTB-XL clinical ECG dataset (Goldberger et al , Wagner et al ). The dataset contains 21\u2009801 clinical 12-lead ECGs from 18\u2009869 patients, each of a 10 s duration. It also includes extensive metadata and statistics on signal properties and demographics such as age, sex, height, and weight. Each record provides the standard set of 12 ECG leads (I, II, III, aVR, aVL, aVF, V1, V2, V3, V4, V5, and V6) (Wagner et al ). In addition to the PTB-XL dataset, we used other 12-lead clinical ECG datasets such as the CPSC and CPSC-Extra Databases (Liu), the INCART Database (Tihonenko et al ), the Georgia 12-lead ECG database (G12EC), and the PTB database (Bousseljot et al ). These datasets were used as part of the 2021 PhysioNet Challenges on multilead ECG annotation (Reyna). Segments of these data were extracted as short 10 s time-series arrays from the entire data, to construct standard 12-lead ECGs. Real ECG time-series recorded in real environments can be contaminated by various types of measurement noises, such as baseline artifacts, powerline interference, motion artifacts, muscle noise, and additive device noises (Moody et al , Clifford et al ). We added a combination of these noises to the ECG time-series (prior to conversion to images) at different levels of signal-to-noise ratio (SNR), using the PhysioNet noise stress-test dataset (Moody et al ), and the synthetic noise generator from the open-source electrophysiological toolbox (OSET) (Sameni, Sameni et al ).", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 16589, "infons": {"section_type": "INTRO", "type": "title_2"}, "text": "Printed text artifacts", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 16612, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Typically, ECG records, whether in printed format or in EHRs, contain printed lead names, patient information/ID, ECG calibration pulse, date, physician/referrer\u2019s name, diagnostic codes/keywords, ECG-based measurements, and various medical terminologies. Many of these fields are protected health information (PHI) and need to be redacted to preserve privacy when shared in the public domain. ECG-Image-Kit accommodates the printing of such information through its command-line options. The lead names (I, II, III, V1, V2, V3, V4, V5, V6, aVL, aVF, aVR) are printed alongside their respective ECG segments on the synthetically generated ECG image (cf figure 3(a)). The user of the toolbox has the option to choose whether there should be an overlap between ECG segments and printed text artifacts. Although overlapped characters pose a problem in digitizing paper ECG records (Ganesh et al ), they are added to represent realistic paper ECGs, which occasionally print text with partial overlap with the ECG traces. Further, to add other printed information such as date, patient record numbers, etc the toolkit uses the corresponding fields from the WFDB header files that accompany all PhysioNet data files, or through a customizable text-based template file. These texts are superimposed on the synthetically generated ECG image obtained from the previous step (cf figure 3(b)).", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 17996, "infons": {"file": "pmeaad4954f3_hr.jpg", "id": "pmeaad4954f3", "section_type": "FIG", "type": "fig_caption"}, "text": "Distortion-less synthetic ECG images with lead names (left) and printed text (right).", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 18082, "infons": {"section_type": "INTRO", "type": "title_3"}, "text": "Handwritten text artifacts", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 18109, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Scanned ECGs may contain annotations or handwritten diagnoses from the healthcare provider. Our synthetic ECG image generation pipeline optionally simulates such handwritten text artifacts to create more realistic ECG images.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 18335, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Most handwritten text on paper ECG records consists of medical terms related to cardiology. We collected a set of medical texts related to ECG and CVDs and used natural language processing (NLP) to extract relevant keywords and phrases. The resulting set of keywords and phrases was converted to handwritten-style images using pretrained models, and the resulting images were overlaid on the ECG images from the previous step of our pipeline. We used the Python-based en_core_sci_md model from sciSpacy (Neumann et al ) for the NLP step, which provides a fast and efficient pipeline for tokenization, parts-of-speech tagging, dependency parsing, and named entity recognition. Next, we retrained the SpaCy model (Honnibal and Montani) on our collected medical texts to retain words/phrases in the ECG context. The dependency parser and the parts of speech tagger in the released models were retrained on the treebank of McClosky and Charniak, which is based on the GENIA 1.0 corpus (Kim et al ). Major named entity recognition models was trained on the MedMentions dataset (Mohan and Li). ECG-Image-Kit parses words from an input text file or from online links using the BeautifulSoup library (Richardson), performs parts-of-speech tagging on the parsed words, and then uses named entity recognition from the aforementioned models to identify ECG-related keywords, which are randomly chosen and added as handwritten text.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 19756, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The extracted words are converted into handwritten-style text to overlay on the synthetic ECG image. We use a pretrained recurrent neural network (RNN) transducer-based model paired with a soft window to generate handwritten text from the extracted words (Graves). One of the major challenges in converting words to handwritten text is that the input and output sequences vary greatly in length depending on the handwriting style, pen size, etc. The RNN transducer-based model can predict output sequences of different lengths and unknown alignments from the input sequence (Graves). The soft window determines the length of the output handwritten sequence by convolving with the input text string, resulting in outputs of varying lengths for different handwriting styles. Our current handwritten text pipeline allows the user to choose from seven different handwriting styles to overlay onto the ECG image. The coordinates for overlaying the text can be chosen by the user of the toolbox or, if not specified, are selected randomly. Examples of the resulting images are shown in figure 4.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 20846, "infons": {"file": "pmeaad4954f4_hr.jpg", "id": "pmeaad4954f4", "section_type": "FIG", "type": "fig_caption"}, "text": "Handwritten and printed text artifacts on synthetic paper ECG.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 20909, "infons": {"section_type": "INTRO", "type": "title_3"}, "text": "Paper wrinkles and creases", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 20936, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Wrinkles and creases are common distortions in scanned paper-based ECG images. Wrinkle distortions arise due to the uneven surface of the wrinkled document. When the scanner light passes over this uneven surface, shadows or reflections from the wrinkles may distort the resulting image. This can cause areas of the image to appear darker or lighter than the actual paper, or lead to the image appearing blurry or distorted. Creases, in contrast, result from the physical fold in the scanned paper. As the scanner light passes over the crease, it can create a shadow that manifests as a dark/bright line in the resulting image, potentially making the text or image in the creased area difficult to read or interpret.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 21652, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Creases can be simulated in images through image processing techniques, using blurred lines spaced linearly to represent paper folds. The placement and orientation of these crease artifacts are mathematically determined by line equations and translations, based on the crease count, inclination angle, and image dimensions. We apply Gaussian blurring to the crease lines to simulate blurring effects, commonly used in image processing to replicate the impact of an unfocused camera, that affect deep neural network performance (Dodge and Karam). This technique realistically integrates creases within image boundaries, enhancing synthetic paper-like ECG image authenticity. The blurring is mathematically represented as a convolution with a Gaussian kernel:  where x and y represent the coordinates in the Euclidean space, and \u03c3 denotes the standard deviation of the Gaussian distribution in pixels. Applying Gaussian blurring to the crease lines results in more realistic images by simulating a shadow effect in the creases, commonly seen in scanned paper ECG images. Assuming a Gaussian mask of size L\u2009\u00d7\u2009L, if the Gaussian kernel is centered within the mask, the blurring effect resembles light reflections off the top of the paper. Displacing the Gaussian kernel\u2019s center from the mask\u2019s center, resulting in non-symmetric blurring at each point, simulates light reflection from different angles.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 23062, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Wrinkles can be considered textures and synthesized using advanced texture synthesis techniques such as image quilting (Efros and Freeman). Image quilting begins with a plain wrinkle image as a seed, followed by the random selection of a patch from this image. This patch forms the foundation for synthesizing the entire wrinkle texture. Multiple patches are generated and seamlessly blended using the minimum boundary error cut method (Liang et al ). This method aims to identify the optimal boundary between two patches by minimizing the error in the overlap region. The minimum cost path through the overlap is determined using dynamic programming based on the algorithm proposed in (Davis). Rather than using a straight line between the patches, this method computes the minimum cost path that delineates the boundary of the new block. Consequently, the placement of texture patches appears smoother and more natural, significantly reducing noticeable sharp edges between the patches.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 24051, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Let  and  be two blocks overlapping along their vertical edges, with  and  representing the regions of overlap between them. The error surface e is defined as the squared difference between  and : . The error surface e is traversed for each row  in the overlapping region, and the minimum error path E is computed using dynamic programming as follows:  where  denotes the cumulative minimum error at position (i,\u2009j) in the error matrix E. The minimum error path is obtained by taking the minimum of the three adjacent pixels in the previous row  and adding it to the corresponding pixel in the current row (i). The last row of E contains the minimal value, indicating the end of the minimal vertical path through the error surface. Backtracking from the last row identifies the path of the best-fit boundary between  and  (Efros and Freeman), resulting in a seamless and visually coherent texture synthesis. This image quilting technique, combined with the minimum boundary error cut method, helps generate a realistic paper-based texture with wrinkles and creases. Thus the resultant image exhibits natural and realistic blending, contributing to the overall authenticity of the synthetic ECG images.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 25255, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Together, wrinkles and creases are added as cumulative transforms on the ECG image to add realistic distortions, as shown in figure 5.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 25390, "infons": {"file": "pmeaad4954f5_hr.jpg", "id": "pmeaad4954f5", "section_type": "FIG", "type": "fig_caption"}, "text": "Wrinkle and crease artifacts on synthetic ECG images.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 25444, "infons": {"section_type": "INTRO", "type": "title_3"}, "text": "Perspective artifacts", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 25466, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "We apply perspective transformations on the synthetic paper ECG image to incorporate different camera viewpoints that could have been used while scanning or taking pictures of paper ECG records. Traditionally, perspective transformations have been widely used in image augmentation for computer vision applications. Wang et al refers to the use of perspective transformations for data augmentation to produce new images captured from different camera viewpoints, specifically for object detection applications. Perspective transforms are simulated by applying geometric transformations to distortionless ECG images. Affine, projective, or homography transformations are utilized to introduce variations in scaling, rotation, and skewing, mimicking the perspective distortions encountered in real paper ECGs. Affine transformations preserve parallelism of lines and can be used to simulate translations, scaling, rotations and shear transformations. Thus, they simulate parallel movements of a camera when scanning a paper ECG. Given an ECG image, the affine transformation can be represented by the matrix transform:  where (x,\u2009y) are the coordinates of a pixel in the original image I, and  are the transformed coordinates after the affine transformation.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 26725, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Projective transformations, which include affine transformations as a special case, can also simulate skew transformations. Unlike affine transformations, projective transformations do not preserve parallelism and are employed to simulate the alteration of perceived images with changes in the observer\u2019s viewpoint. In ECG-Image-Kit, projective transformations are integrated into the synthetic paper ECG generation pipeline to mimic observational changes in mobile- or camera-based ECG images. The matrix equation for a projective, or perspective, transformation is given by:  where (x,\u2009y) are the coordinates of a pixel in the original ECG image I,  are the transformed coordinates after the projective transformation, and w\u2032 is a scaling factor that ensures homogeneous coordinate representation. In (5), the elements a, b, c, d, e, f, g, h, and i control the scaling, rotation, shear, skew and perspective effects applied to the image. These transformations add depth and simulate different viewing angles and positions, further enhancing the resemblance to real ECG images.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 27810, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The aforementioned transformations are implemented using the imgaug library in Python (Jung), a tool for image augmentation in machine learning experiments. Imgaug supports numerous augmentation techniques, enables their easy combination, and executes them in random order, making it ideal for generating highly variable synthetic ECG image datasets.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 28161, "infons": {"section_type": "INTRO", "type": "title_3"}, "text": "Imaging artifacts and noise", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 28189, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The final distortions added to the synthetic paper ECG images include generic imaging noise modeled by Gaussian noise, Poisson noise, salt and pepper noise, and color temperatures. These are crucial for creating realistic synthetic images and enhancing the robustness of machine and deep learning models trained on these images. Gaussian noise typically arises in digital images during image acquisition, which in this case involves scanning or photographing paper ECG images or ECG images from a monitor. Modeling sensor noise, Gaussian noise is added independently to each pixel:  where  represents the noisy pixel value,  is the original pixel value of the ECG images, and  is a random value drawn from a Gaussian distribution with mean 0 and standard deviation \u03b7.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 28959, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Poisson-distributed Shot noise, commonly used to model electromagnetic and photonics noises during image acquisition, can be added to each pixel:  where  is a random value drawn from a Poisson distribution with parameter \u03bb, and the clipping ensures the pixel value remains within the range [0, 255] (for 8-bit per color image representations).", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 29308, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Salt and pepper noise models camera sensor malfunctions, which may occur when scanning ECG images. This noise randomly sets pixels to either the minimum or maximum intensity:  where the probability p determines the density of the salt and pepper noise.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 29561, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Finally, color temperatures are simulated by adjusting the image\u2019s color channels. A color temperature value is selected, and the color channels are transformed using algorithms such as color temperature scaling or white balance adjustment to mimic the desired effect. The RGB values of the image change according to a temperature value ranging from 1000 to 40\u2009000 Kelvin, with lower values corresponding to orangish tinges and higher values to bluish tinges.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 30025, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Modifications to color temperature are useful for simulating the aging and wearing effects of ECG thermal paper.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 30138, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "In ECG-Image-Kit, these artifacts are added in user-adjustable proportions to the synthetic ECG image using the imgaug library in Python.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 30276, "infons": {"section_type": "INTRO", "type": "title_1"}, "text": "Case study: a combined image processing and deep learning model for ECG image digitization", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 30367, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "We utilized ECG-Image-Kit to create a diverse dataset for training an ECG digitization model. These synthetic ECG images were generated from the PTB diagnostic ECG database time-series consisting of 549 records (Bousseljot et al ). The trained model was then applied to evaluate the fidelity of a synthetic paper ECG dataset generated from the PhysioNet QT Database (Laguna et al , Mark and Moody, Goldberger et al ), both in terms of signal quality and accuracy of extracting ECG-based measurements.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 30868, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The digitization process involves multiple steps. First, preprocessing techniques including image registration and OCR are used to correct distortions and remove text from the images. Next, a denoising CNN network, trained on the synthetic dataset, denoises the images and eliminates the ECG grid. The denoised image is then divided into segments, processed to address discontinuities, and transformed into corresponding time-series data for ECG-based waveform measurements. Each step of the ECG digitization pipeline is detailed in this section.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 31415, "infons": {"section_type": "INTRO", "type": "title_2"}, "text": "Rotation compensation", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 31437, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Rotation compensation is a crucial preprocessing step for images captured by cameras or scanned with minor or major rotations. This step aims to align the images and remove any skew, shear, and rotations in the scanned paper ECG images. We explored two methods for rotation compensation: keypoint matching and a Radon transform-based technique. In our experiments, the Radon transform-based method proved to be more effective for rotation compensation.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 31890, "infons": {"section_type": "INTRO", "type": "title_3"}, "text": "Image registration using keypoint matching", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 31933, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Image registration involves matching, aligning, and overlaying two or more images of a scene captured from different viewpoints. It transforms different image sets into a single unified coordinate system and is widely used in vision-based applications (Tareen and Saleem). The main steps in image registration include keypoint detection, keypoint matching, and image reconstruction from keypoints. Keypoints are specific points that characterize the image and are used to compute the transformation. Descriptors, which are histograms of the image gradient, characterize the appearance of a keypoint. The Oriented Features from Accelerated Segment Test (FAST) and Rotated Binary Robust Independent Elementary Feature (BRIEF) descriptor (ORB) algorithm and the scale-invariant feature transform (SIFT) algorithm are two methods for keypoint detection. ORB is notably more efficient and faster than SIFT, being computationally faster by nearly two orders of magnitude (Rublee et al ).", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 32915, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The ORB algorithm (Rublee et al ) can be used to analyze a reference paper ECG image I ref and the input paper ECG image I input to identify regions of significant pixel intensity change. ORB uses a combination of oriented FAST for corner detection and BRIEF for descriptor computation. The oFAST algorithm detects keypoints in both I ref and I input, ordering them using the Harris Corner measure (Rosin). To ensure scale invariance of detected keypoints, ORB employs a multi-scale image pyramid, with each level comprising a downsampled version of the image from the previous level. By detecting keypoints at each level, ORB effectively locates important points across different scales. After obtaining the keypoints, the orientation for each keypoint patch is computed. rBRIEF (Rotation-aware BRIEF) converts the keypoints identified by oFAST into a binary feature vector. The descriptors,  and , are calculated and compared to establish correspondences between keypoints in the reference and input images, thereby generating the rotation matrix to align the input image with the reference axes.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 34014, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "However, not all detected keypoints may have reliable matches due to noise or image artifacts. To mitigate this, we use the Random Sample Consensus (RANSAC) algorithm, a robust matching technique (Vinay et al ). RANSAC iteratively selects a subset of correspondences from the set C, denoting correspondences between keypoints in I ref and I input as , and estimates the transformation matrix T that best aligns the keypoints  and . This process, repeated multiple times, refines the transformation estimate and filters out outliers. Once the affine transformation matrix T is obtained, it is applied to the input scanned ECG image I input, warping the image to match the spatial alignment of the reference image I ref. This registration process ensures the input ECG image closely resembles the reference image in geometric configuration.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 34853, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "In the use case, we employed ORB-RANSAC to detect 50 keypoints in the ECG image and a template ECG image. After computing keypoints, we used a greedy algorithm for point matching between the two images, employing the Hamming distance as the metric for keypoint matching. We selected the match corresponding to the least Hamming distance. Subsequently, we determined the homography matrix based on the best-matched keypoints and applied this matrix to the rotated ECG image to restore the original image and compensate for rotation. However, the ORB algorithm may not work for all scanned paper ECG images due to high variability in the dataset, making it challenging to compute keypoints from a template ECG image. Sample results obtained from ORB are shown in figures 6 and 7.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 35631, "infons": {"file": "pmeaad4954f6_hr.jpg", "id": "pmeaad4954f6", "section_type": "FIG", "type": "fig_caption"}, "text": "Image alignment using Oriented FAST and Rotated BRIEF descriptor (ORB).", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 35703, "infons": {"file": "pmeaad4954f7_hr.jpg", "id": "pmeaad4954f7", "section_type": "FIG", "type": "fig_caption"}, "text": "Matched keypoints in rotated image and reference image.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 35759, "infons": {"section_type": "INTRO", "type": "title_3"}, "text": "Image registration using Radon transform", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 35800, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The Radon transform is widely used for computed tomographic reconstruction (Helgason and Helgason). It mathematically represents an image in terms of its projection profiles. In continuous form, the Radon transform of a 2D signal (or image)  is defined as:  where \u03c1 is the distance parameter, \u03b8 is the angle parameter, and  represents the Dirac delta function.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 36167, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The Radon transform\u2019s fundamental principle is that -dimensional line integrals through an n-dimensional volume (like a 2D image) allow the recovery of original n-dimensional Fourier values through their -dimensional Fourier transform. It transforms an n-dimensional volume into a complete set of -dimensional line integrals. The image is sampled along a set of  parallel lines at varying angles, accumulating intensity values along each line integral to form a projection profile. The Radon transform represents these profiles as a function of distance parameter \u03c1 and angle parameter \u03b8. The inverse Radon transform reverts these line integrals to the original image (Hjouj and Jouini). The Radon transform plot across different angles, known as a Sinogram due to its sinusoidal shape, reveals the image\u2019s rotation angle. Consequently, inversely rotating the image by the angle estimated from the Radon transform restores the original ECG image.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 37120, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The Radon transform is particularly useful for tasks like rotation compensation (Bisht et al , Nacereddine et al ). By analyzing projection profiles at various angles, it enables the estimation of rotation angles between two images or signals. This facilitates the alignment or correction of rotation in images or signals, aiding various image processing and analysis tasks, such as correcting rotation or shear transformations in scanned images.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 37567, "infons": {"section_type": "INTRO", "type": "title_2"}, "text": "Character removal", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 37585, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Text artifact removal is the next step in our pipeline, ensuring the accurate digitization of underlying ECG signals. Character removal is achieved using standard OCR algorithms that execute text localization and detection. This process is followed by image inpainting to mask the text present in the image.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 37893, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Text localization is the initial step in our approach, aiming to identify and localize text regions within the scanned ECG image. This algorithm detects regions containing characters but does not recognize individual characters. The Keras-OCR library utilizes CRAFT (Character Recognition Awareness For Text detection) for text localization. CRAFT employs a fully convolutional network architecture based on VGG-16 for encoding, and its decoding part includes skip connections similar to U-Net (Baek et al ). Additionally, CRAFT has a refined anchor box generation scheme to predict text regions, providing bounding boxes around areas expected to contain characters. The algorithm generates a set of bounding boxes, denoted as , where each bounding box Bi  is represented by its top-left and bottom-right coordinates  and , respectively.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 38731, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Following text localization, the CRNN model is employed for text detection within localized regions. Keras-OCR implements a CRNN-based model for text recognition. CRNN, combining convolutional neural networks and RNNs, processes images containing sequential information like letters (Shi et al ). The CRNN model learns the mapping function F to transform localized text regions into corresponding text labels, denoted as , where each Li  represents the recognized text in the ith region enclosed by bounding box Bi .", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 39248, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "After obtaining the character mask, it is blanked out by applying image inpainting using the fast marching method, a prevalent technique for this purpose (Telea). Image inpainting in removed text regions of the ECG image involves several steps. The fast marching method employs a distance map, indicating the distances from known or inpainted pixels to missing regions. This map directs the inpainting process, prioritizing pixels close to the missing text regions. For each missing pixel, a first-order approximation is calculated using nearby pixels, their image values, and gradients, following the equation:  where I(q) denotes the image value at pixel q, and  the gradient at pixel q. The distance map aids in selecting the most appropriate nearby pixels for the approximation based on their proximity to the missing pixels. Leveraging the distance map and accounting for local image structures and gradients, the fast marching method effectively inpaints the removed text regions in the ECG image.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 40252, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Overall, the combination of text detection, the fast marching method, and the use of a distance map facilitates accurate and efficient inpainting of removed text regions in the ECG image. An example of our text removal stage is illustrated in figure 8.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 40505, "infons": {"file": "pmeaad4954f8_hr.jpg", "id": "pmeaad4954f8", "section_type": "FIG", "type": "fig_caption"}, "text": "Removal of text artifacts through optical character recognition.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 40570, "infons": {"section_type": "INTRO", "type": "title_2"}, "text": "Grid removal", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 40583, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "We formulated ECG paper grid removal as a denoising problem using the Denoising CNN (DnCNN) architecture (figure 9), which effectively handles Gaussian noise at unknown levels and manages three general image denoising tasks: blind Gaussian denoising, single-image super-resolution with multiple upscaling factors, and JPEG image deblocking with varying quality factors (Zhang et al ). The input to DnCNN is a noisy observation , where x represents the clean ECG and v denotes the background grid, and the expected output is a clean ECG plotted on a white paper background. The sample result is shown in figure 10.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 41197, "infons": {"file": "pmeaad4954f9_hr.jpg", "id": "pmeaad4954f9", "section_type": "FIG", "type": "fig_caption"}, "text": "Denoising CNN architecture used for grid removal.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 41247, "infons": {"file": "pmeaad4954f10_hr.jpg", "id": "pmeaad4954f10", "section_type": "FIG", "type": "fig_caption"}, "text": "Synthetic paper ECG image before and after grid removal.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 41304, "infons": {"section_type": "INTRO", "type": "title_3"}, "text": "Training the denoising CNN model", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 41337, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Synthetic ECG images were generated using ECG-Image-Kit at  DPI resolution. The RGB images were divided into 3 channels, as the model will be trained on single-channel images. Each channel was further divided into 30 \u00d7 30 pixel patches with a 5-pixel overlap. The raw image patches were scaled from 0\u2013255 to 0\u20131. These patches, generated from a diverse dataset synthesized from 549 time-series records of the PTB Dataset (Bousseljot et al ), result in approximately 100\u2009000 patches with corresponding ground truth for training. The patch dataset was next shuffled, and a 5-fold cross-validation was conducted for model evaluation. In each round, images in the leave-out set (20%) were used solely for testing, and patches were generated from the 80% training set, ensuring no testing image is leaked into the training set. This resulted in a 20:80% test:train split. The patch dataset was then fed into the denoising neural network.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 42277, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "For the network architecture, we used a convolutional kernel of size 7 \u00d7 7 to capture a significant portion of the grid in the patches (Simonyan and Zisserman). A high noise level typically requires a larger effective patch size to capture more context information for restoration (Levin and Nadler). Assuming the  model, where x represents the clean ECG and v denotes the background grid, we can adopt a residual learning-based formulation to learn a residual mapping . Here, the residual image to be predicted is considered to be the grid noise. The loss in terms of the trainable parameters is given by:  where \u0398 represents the trainable parameters,  represents N noisy-ground truth patch pairs, and  is the Frobenius norm. The training goal is to learn  and subtract this predicted residual from the image to obtain the clean ECG image without the grid.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 43139, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The DnCNN we used comprises 17 layers. The first layer consists of a Conv2D + ReLU layer with 64 filters of size 7 \u00d7 7. Rectified Linear Units were used for non-linearity in the architecture. By combining convolution with ReLU, DnCNN progressively separates image structure from noisy observation through hidden layers. Layers 2 to 16 consist of Conv2D + Batch normalization + ReLU layers with 64 filters of size . Batch normalization was done to accelerate training and enhance denoising performance (Zhang et al ). The last layer used 1 filter of size  to produce the output image. The model was trained using early stopping for 30 epochs until mean squared error loss saturation, reducing the loss to an order of 10\u22125. The model was also trained without early stopping for 500 epochs, to observe the loss curve\u2019s further progression. However, as the loss plateaued at 10\u22125, the model trained for 30 epochs was selected.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 44069, "infons": {"section_type": "INTRO", "type": "title_3"}, "text": "Employing the trained model for grid removal", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 44114, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "During runtime, input ECG images are segmented and given to the trained DnCNN-based model. Each image is split into R, G, and B channels and split into overlapping  patches to avoid boundary artifacts when re-stitched together (Xu et al ). These patches are processed through the denoising CNN, yielding grid-removed patches that are stitched together using the Exponential Distance Weighted method by Wu et al. This method applies distance-based weighting to the overlapping areas, ensuring smoother reconstruction. The result is a seamlessly reconstructed, clean ECG image post-grid removal.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 44708, "infons": {"section_type": "INTRO", "type": "title_2"}, "text": "Region of interest (ROI) detection", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 44743, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The image, after text and grid removal, undergoes ROI detection to segment the leads. As standard ECG prints contain multiple rows of data, we split them into ECG strips to aid in mask retrieval and time-series data conversion. For the current study, we employed a histogram-based method for ROI detection to estimate the boundary regions between the ECG strips, aiming to identify the segments containing ECG time-series. We used the fact that rows of pixels with ECG segments typically have lower pixel intensities compared to the regions between segments, in dark foreground (black/grey) images.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 45342, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Let  denote the pixel intensity value at coordinates (x,\u2009y) of the image, where x is the row index and y is the column index. We compute the mean pixel intensity  row-wise by averaging intensities along each row, with W being the image\u2019s width. Then, we plot pixel intensity vs row number, which typically shows global minima at ECG segments and global maxima between them. To smooth the pixel intensity curve and emphasize the global minima corresponding to ECG segments, we applied a non-causal moving average filter. The filtered pixel intensity curve is computed as:  where L is the filter order (L\u2009=\u200911 in the later reported results), and . The separation regions between ECG segments are estimated as the rows between global minima. We then draw bounding boxes around the ECG signals using the estimated rows. These bounding boxes encapsulate the regions of interest containing individual ECG strips, which are then separated row-wise for subsequent processing and time-series data conversion. An example of the ROI detection results is shown in figure 11.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 46413, "infons": {"file": "pmeaad4954f11_hr.jpg", "id": "pmeaad4954f11", "section_type": "FIG", "type": "fig_caption"}, "text": "Synthetic paper ECG image strips separated after region of interest detection.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 46492, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "More advanced ROI detection methods, like variants of the well-known you only look once (YOLO) model (Redmon et al ), can also be adapted for ECG applications. A pretrained YOLOv7 model is provided in ECG-Image-Kit for ROI detection.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 46726, "infons": {"section_type": "INTRO", "type": "title_2"}, "text": "ECG time-series extraction", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 46753, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The final step in the digitization pipeline is to convert segmented and denoised ECG segments into time-series data. In this stage, we use the fact that the ECG signal is a function (in the mathematical term), implying that when ECG segments are horizontally aligned (as a result of rotation compensation described in section 4.1), there is exactly one corresponding ECG point per vertical column of the image segment. Thus, time-series recovery can be framed as identifying the most likely pixel per column. Furthermore, since the ECG waveform is a continuous time-series that adheres to the Nyquist frequency, it is continuous in time. Consequently, depending on the temporal and amplitude resolutions, the pixels most likely representing the ECG in adjacent columns are located near each other. In essence, the problem is a search for the most likely set of adjacent pixels forming the ECG curve, which can be done by a Viterbi search or similar methods (Fortune et al ). In ECG-Image-Kit, several functions are provided for this stage. A simple method involves applying local smoothing filter followed by a column-wise peak search.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 47889, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Here, we introduce a more detailed method using connected component analysis (CCA) on binarized segmented ECG images. CCA identifies contiguous regions, known as connected components, in a binary image based on a predefined connectivity criterion between pixels (Ganesh et al ). These connected components are labeled to uniquely identify each region for subsequent processing. The segmented ECG strips are given to CCA. The pixels within a connected component region receive unique labels through connected component labeling. Converting the ECG mask to time-series data can be complicated by discontinuities in the mask, which may arise from grid removal algorithms or residual artifacts in the image. CCA operates by scanning an image pixel-by-pixel and identifying regions with identical pixel intensities. For CCA, we first convert the image from RGB to grayscale and then apply a binary threshold. The binary threshold is implemented using a  thresholding filter.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 48859, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Next, we perform connected component labeling, fusing connected components within a specified distance threshold. Thresholds are set for the height, width, and area of the connected components. Components smaller than these thresholds are discarded, helping to eliminate stray pixels, character residuals and artifacts. Larger segments representing the background are also removed using a lower bound threshold. The distance threshold for fusing nearby components is determined using the Hausdorff distance (Zhao et al ), calculated using only the outer pixels of the components for computational efficiency. A connectivity of 4 for connected component labeling was found as optimal, considering the thickness of the ECG segments and the selected DPI of 200. This results in a mask for time-series extraction.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 49669, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "After creating the connected mask, it undergoes blurring with a  rectangular filter to capture neighborhood information along the horizontal (time) axis. This filter, focusing on filtering along the time axis, gathers contextual information for each pixel. The blurring filter\u2019s neighborhood information is crucial for determining whether a given pixel is part of the ECG signal, an assessment that can be framed as a maximum likelihood problem. We can gauge the likelihood of a pixel being part of the ECG signal based on its neighboring pixels\u2019 involvement in the signal. To extract the ECG signal pixels, we examine each column of the blurred mask, denoted by , and identify the pixel with the lowest intensity using:  where  represents the pixel index with the lowest intensity in column x. This is based on the assumption of a dark foreground signal, where ECG pixels are generally darker than the background, making the pixel with the lowest intensity the most likely candidate to be part of the ECG signal. Sample ECG time-series overlaid on the ECG image segments are shown in figure 12.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 50769, "infons": {"file": "pmeaad4954f12_hr.jpg", "id": "pmeaad4954f12", "section_type": "FIG", "type": "fig_caption"}, "text": "Obtained time-series ECG signal plotted in red superimposed on the synthetic paper ECG strip.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 50863, "infons": {"section_type": "INTRO", "type": "title_2"}, "text": "Conversion into physical units", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 50894, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "By this stage, we have a vector matching the ECG segment\u2019s pixel width, where each entry indicates the most likely vertical index of the ECG wave. To translate pixel indices to volts and seconds, we need the physical units per pixel. For accurately scanned images, this data can be derived from section 3.1.2 or directly from the estimated ECG fine or coarse grid sizes. For the latter, considering each coarse grid equates to 0.5\u2009mV in amplitude, we use this amplitude scaling factor:  Applying this scaling factor to the pixel index translates the data into a time-series representation in millivolts for the ECG image. As discussed in section 3.1.2, the sampling frequency of the extracted time-series is obtained from (1) (or can be inferred from the coarse or fine grid sizes in pixels). Importantly, this sampling frequency is different from the original time-series sampling frequency . Hence, if required for waveform comparisons, the extracted signal should be resampled to .", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 51883, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "As a time-series, the extracted ECG waveforms may be further filtered using the state-of-the-art ECG filtering algorithms.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 52006, "infons": {"section_type": "INTRO", "type": "title_2"}, "text": "Results", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 52014, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "We present the results of the ECG digitization pipeline in terms of quantitative signal quality metrics and ECG-based measurements.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 52146, "infons": {"section_type": "INTRO", "type": "title_3"}, "text": "ECG time-series recovery performance", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 52183, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The digitization pipeline, trained on synthetic paper ECG images from the PTB diagnostic ECG database (Bousseljot et al , Goldberger et al ), was evaluated on synthetic ECG images from a distinct dataset, the QT database (Laguna et al , Mark and Moody). This dataset consisted of 1000 images, ensuring no overlap between the training and evaluation datasets. The evaluation set images were generated at a 200 DPI resolution and dimensions of 2200 \u00d7 1700 pixels.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 52646, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "We employed both the standard SNR and an ad hoc SNR metric to assess the algorithm\u2019s performance in retrieving the ECG time-series. The standard SNR definition we used is:  which weights all sample points similarly. However, the standard SNR may not necessarily be the best metric for this problem from a practical perspective. In fact, one of the common issues in ECG digitization is that discrete mis-detected pixels may result in occasional spikes in the extracted time-series. While these spikes significantly impact the standard SNR metric, they are not necessarily the most detrimental for classification and human-based diagnosis applications. In fact, machine learning models, combined with appropriate filters, can remove spike noises. Human annotators are also adept at detecting unwanted spikes through visual inspection. Therefore, we may seek an SNR metric that is less susceptible to occasional spikes. Based on this observation, we propose the following modified SNR metric:  Accordingly, in , instead of using the average of the noise power, we use the median of the noise power, which is more robust to occasional outliers.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 53789, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "The standard SNR and the median-based SNR were both calculated per record. For this purpose, all time series extracted from the digitization pipeline were resampled to their original sampling frequency (250 Hz) and sample-wise aligned using the peak of their cross-correlation functions. Functions such as finddelay in MATLAB and scipy.signal.correlation_lags in Python can be used for this alignment. This ensures that the algorithms are not disadvantaged or underrated due to missing only a few pixels at the beginning or end of the ECG segments.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 54338, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "In figure 13, the histogram of SNR values for the 1000 evaluation images is shown. Accordingly, the synthetic paper ECG dataset of 1000 images produced an average  standard deviation (STD) SNR of 11.88 dB \u00b1 8.91 dB. The mean square error (MSE) was calculated as an additional evaluation metric, resulting in a mean  STD of 55.0\u2009\u00b5V \u00b1 0.52\u2009mV for our synthetic paper ECG dataset. The average  STD of the modified SNR metric SNRmed were 26.54 dB \u00b1 10.11 dB, respectively. Accordingly, the significant superiority of SNRmed over the conventional SNR metric confirms that spike noises are the major issue in the ECG extraction pipeline. To mitigate the impact of outliers, we further calculated the average and standard deviations of the reconstruction SNRs over the middle 95th percentile ranges (from 2.5% to 97.5% of the SNR distributions). The results are summarized in table 1. These results demonstrate the algorithm\u2019s ability to recover the ECG time series.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 55308, "infons": {"file": "pmeaad4954f13_hr.jpg", "id": "pmeaad4954f13", "section_type": "FIG", "type": "fig_caption"}, "text": "Histograms of the standard SNR metric (a) and the modified SNR using the median noise power (b) generated for the digitization of 8505 synthetically generated images using real ECG samples from the QT database. The average and standard deviation of the standard SNR are 11.88 dB and 8.91 dB, respectively. The average and standard deviation of SNRmed are 26.54 dB and 10.11 dB, respectively. Accordingly, the significantly higher values of SNRmed over the conventional SNR metric confirms that spike noises are the major issue in the ECG extraction pipeline.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 55867, "infons": {"file": "pmeaad4954t1.xml", "id": "pmeaad4954t1", "section_type": "TABLE", "type": "table_caption"}, "text": "Summary of the evaluation results over the middle 95th percentile (from 2.5 pct to 97.5 pct) of the different evaluation metrics.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 55997, "infons": {"file": "pmeaad4954t1.xml", "id": "pmeaad4954t1", "section_type": "TABLE", "type": "table", "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<table xmlns:xlink=\"http://www.w3.org/1999/xlink\" frame=\"hsides\" rules=\"groups\"><colgroup span=\"1\"><col align=\"left\" span=\"1\"/><col align=\"center\" span=\"1\"/><col align=\"center\" span=\"1\"/><col align=\"center\" span=\"1\"/></colgroup><thead><tr><th align=\"left\" colspan=\"1\" rowspan=\"1\" valign=\"bottom\">Metric</th><th align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"bottom\">2.5th pct</th><th align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"bottom\">97.5th pct</th><th align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"bottom\">Average \u00b1 STD</th></tr></thead><tbody><tr><td align=\"left\" colspan=\"1\" rowspan=\"1\" valign=\"top\">SNR (dB)</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">\u22121.8</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">23.0</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">12.7 \u00b1 4.8</td></tr><tr><td align=\"left\" colspan=\"1\" rowspan=\"1\" valign=\"top\">SNR<inline-formula><alternatives><tex-math id=\"M165\">\\documentclass[12pt]{minimal}\n\\usepackage{amsmath}\n\\usepackage{wasysym}\n\\usepackage{amsfonts}\n\\usepackage{amssymb}\n\\usepackage{amsbsy}\n\\usepackage{upgreek}\n\\usepackage{mathrsfs}\n\\setlength{\\oddsidemargin}{-69pt}\n\\begin{document}\n$_{\\textrm{med}}$\\end{document}</tex-math><inline-graphic xlink:href=\"pmeaad4954ieqn67.jpg\"/></alternatives></inline-formula> (dB)</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">5.7</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">36.5</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">27.6 \u00b1 5.4</td></tr><tr><td align=\"left\" colspan=\"1\" rowspan=\"1\" valign=\"top\">MSE (<italic toggle=\"yes\">\u00b5</italic>V)</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">0.1</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">226.0</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">12.8 \u00b1 34.2</td></tr><tr><td align=\"left\" colspan=\"1\" rowspan=\"1\" valign=\"top\">RR interval error (ms)</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">0.0</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">116.2</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">3.7 \u00b1 13.2</td></tr><tr><td align=\"left\" colspan=\"1\" rowspan=\"1\" valign=\"top\">QRS width (ms)</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">0.4</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">32.2</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">6.4 \u00b1 5.6</td></tr><tr><td align=\"left\" colspan=\"1\" rowspan=\"1\" valign=\"top\">QT interval error (ms)</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">0.3</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">56.6</td><td align=\"center\" colspan=\"1\" rowspan=\"1\" valign=\"top\">6.8 \u00b1 8.4</td></tr></tbody></table>\n"}, "text": "Metric\t2.5th pct\t97.5th pct\tAverage \u00b1 STD\t \tSNR (dB)\t\u22121.8\t23.0\t12.7 \u00b1 4.8\t \tSNR (dB)\t5.7\t36.5\t27.6 \u00b1 5.4\t \tMSE (\u00b5V)\t0.1\t226.0\t12.8 \u00b1 34.2\t \tRR interval error (ms)\t0.0\t116.2\t3.7 \u00b1 13.2\t \tQRS width (ms)\t0.4\t32.2\t6.4 \u00b1 5.6\t \tQT interval error (ms)\t0.3\t56.6\t6.8 \u00b1 8.4\t \t", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 56275, "infons": {"section_type": "INTRO", "type": "title_3"}, "text": "Clinical parameter preservation", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 56307, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "While SNR is a standard metric of signal quality, the evaluation of the extracted ECG time-series should also be assessed in terms of the accuracy in extracting clinical biomarkers such as the RR interval (or its reciprocal, the heart rate), QRS width, QT interval, etc. We performed this evaluation on a dataset of 10\u2009000 synthetically generated ECG images by the ECG-Image-Kit at a 200\u2009dpi resolution and of size 2200 \u00d7 1700 pixels. The images were generated from different 10 s segments of the QT database (Laguna et al , Mark and Moody). The database contains 100 fifteen-minute two-lead ECG recordings. The synthetically generated images were digitized using the proposed digitization pipeline. The QRS widths, RR intervals, and QT intervals were measured from the original ECG time-series and from the ECG estimate recovered from the images, using the peak_det_likelihood.m R-peak detector from OSET (Sameni). The R-peaks were next given to wavedet_3D.m from ECG-Kit (Demski and Soria), to extract the fiducial points of the ECG, including the QRS onset/offset and the T-wave offset (from time-series and post-extraction from images). The accuracy of the estimated QRS widths, RR and QT intervals were used to determine how well clinical parameters were preserved throughout the digitization pipeline (Dumitru et al ). The QRS widths, RR and QT-intervals of the reference ECG time-series data and the ones obtained from the digitized time-series data were measured and compared, as shown in figure 14. It can be seen from the corresponding figures that the reference and extracted measurements are highly correlated.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 57935, "infons": {"file": "pmeaad4954f14_hr.jpg", "id": "pmeaad4954f14", "section_type": "FIG", "type": "fig_caption"}, "text": "Comparison of estimates of various clinical parameters extracted from time-series post ECG digitization vs the reference measurements from the original ECG time-series.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 58104, "infons": {"section_type": "DISCUSS", "type": "title_1"}, "text": "Discussion", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 58115, "infons": {"section_type": "DISCUSS", "type": "paragraph"}, "text": "The results of our ECG image digitization study indicate that the ECG-Image-Kit effectively synthesizes realistic ECG images that closely mirror the characteristics of actual scanned ECGs. Looking forward, optimizations could further enhance the pipeline\u2019s performance across diverse ML-based ECG analysis. To note, the ECG digitization pipeline can be improved to adapt to more variable real-world scenarios. A detailed examination of underperforming cases through visual inspection and SNR metrics highlighted specific performance bootlenecks: (1) low-amplitude ECG signals that increase quantization noise (from time-series to images and from images back to time-series), (2) adjacent overlapping leads, (3) residual noise from text or grid artifacts, which occasionally introduce spike noises in the ECG time-series, and (4) imaging artifacts especially when ECG images are captured with mobile phones or scanned in non-standard aspect ratios. Moreover, in practical settings, the quality of clinical ECG images often varies, suggesting that synthetic training datasets should match the artifact distributions typical of specific clinical environments. Future research should aim to refine synthetic ECG generation to produce even more diverse images to be used for training robust digitization algorithms that effectively handle these artifacts. Optimizing deep-learning models for specific scenarios and allowing users to select the most appropriate model based on their available data could significantly enhance the practicality and accuracy of ECG digitization in diverse clinical settings.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 59717, "infons": {"section_type": "DISCUSS", "type": "paragraph"}, "text": "ECG-Image-Kit is generally computationally efficient, although for generating very large training sets for deep learning applications or foundational models, the speed of the code can be further improved. Among the different steps of the pipeline, the slowest component is the generation of handwritten-like text artifacts using an RNN transducer-based model, which is particularly time-consuming due to its large number of parameters (totaling 3.4 million parameters Graves). Techniques like model freezing, pruning, and quantization could significantly reduce this latency in the future, enhancing overall efficiency without sacrificing substantial model performance. Pruning methods have successfully reduced computation times, and quantization has achieved up to threefold speedups with acceptable precision trade-offs (Molchanov et al , Krishnamoorthi, Kumar et al ).", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 60590, "infons": {"section_type": "DISCUSS", "type": "paragraph"}, "text": "Wrinkles and creases are the next slowest step of ECG-Image-Kit. Raad et al propose implementation strategies of the image quilting algorithm using partial parallel processing, allowing a significant speed-up when run with multi-core processors. Incorporating these techniques can significantly reduce the wrinkle generation step run time. Further, Wei and Levoy proposed using tree-structured vector quantization for faster texture synthesis that provided nearly 150 times the speedup for certain textures. This technique can further be incorporated into our implementation for faster texture synthesis.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 61195, "infons": {"section_type": "DISCUSS", "type": "paragraph"}, "text": "Overall, while ECG-Image-Kit effectively mimics real ECGs and supports their digitization, ongoing improvements and optimizations are essential for enhancing performance and extending applicability in clinical practice. Using this tool, we are able to generate synthetic\u2014yet realistic\u2014ECG images for which we have access to the ground-truth time-series. This enables researchers to develop and evaluate their ECG digitization pipelines in a standardized manner; an open research problem that is investigated in the 2024 PhysioNet Challenge on ECG image digitization and classification (George B. Moody PhysioNet Challenge, PhysioNet).", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 61834, "infons": {"section_type": "CONCL", "type": "title_1"}, "text": "Conclusion", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 61845, "infons": {"section_type": "CONCL", "type": "paragraph"}, "text": "In this work, we introduced ECG-Image-Kit, a novel tool for creating synthetic paper-like ECG images from time-series data, and assessed its utility in a case study for training a comprehensive ECG image digitization pipeline combining image processing and deep learning techniques. The generated synthetic images effectively mimic real paper ECGs with realistic distortions such as handwritten text, wrinkles, and perspective changes. Using SNR, a modified SNR definition based on median noise power, and MSE metrics, we demonstrated the effectiveness of our toolset in accurately digitizing ECG images, evidenced by high SNR values (low MSE) and the close resemblance of synthetic images to original time-series data.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 62565, "infons": {"section_type": "CONCL", "type": "paragraph"}, "text": "This research addresses the scarcity of real patient ECG data due to privacy and regulatory constraints. By generating synthetic ECG images, we provide a means to develop and test ECG analysis algorithms while ensuring privacy compliance. Our approach offers a diverse, controlled dataset that facilitates rigorous testing and enhancement of digitization techniques. This synthetic dataset is invaluable for developing algorithms, augmenting training data for machine learning models, and advancing automated ECG diagnoses.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 63089, "infons": {"section_type": "CONCL", "type": "paragraph"}, "text": "In the clinical parameter extraction results, the measurements obtained from the original ECG time series were compared with those made after the ECG digitization pipeline. While this approach objectively assessed the performance of the digitization algorithm, the results are not indicative of the actual clinical parameter measurements, as they were also impacted by inaccuracies in R-peak detection and fiducial-point extraction algorithms, which are independent from the digitization algorithm. In the future, we can evaluate the performances of clinical parameters against human annotations.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 63686, "infons": {"section_type": "CONCL", "type": "paragraph"}, "text": "Future research could expand the synthetic dataset with more variations like electrode misplacements, noise patterns, and heart rate variability. Collaborating with medical experts to conduct a Turing test could validate the synthetic data\u2019s realism. Employing measures like the Kappa value in these tests would assess the perceptual fidelity of the synthetic dataset, confirming its utility in clinical settings for tasks like algorithmic ECG annotation and training. Furthermore, incorporating advanced techniques like GANs could result in complementary models with even more realistic and varied ECG types.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 64298, "infons": {"section_type": "CONCL", "type": "paragraph"}, "text": "Optimizing the denoising CNN model and integrating advanced deep learning models or techniques like RNNs or attention mechanisms could refine the digitization process\u2019s accuracy and efficiency. Applying the pipeline to large datasets and diverse clinical scenarios will offer insights into its effectiveness across various ECG recording environments. Moreover, including domain-specific knowledge, like cardiac anatomical information or waveform characteristics, could enhance the digitization precision and lead to more accurate recovery and interpretation of ECG data.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 64871, "infons": {"section_type": "CONCL", "type": "paragraph"}, "text": "This research therefore lays the groundwork for high-accuracy, generalizable ECG digitization solutions using synthetic ECG data, a critical step toward advancing ECG analysis in low resourced settings and enhancing global patient care standards.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 65118, "infons": {"section_type": "SUPPL", "type": "title_1"}, "text": "Data availability statement", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 65146, "infons": {"section_type": "SUPPL", "type": "paragraph"}, "text": "The data that support the findings of this study are openly available at the following URL/DOI: https://github.com/alphanumericslab/ecg-image-kit/.", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 65294, "infons": {"section_type": "REF", "type": "title"}, "text": "References", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 65305, "infons": {"elocation-id": "124003", "name_0": "surname:Alday;given-names:E A P", "pub-id_doi": "10.1088/1361-6579/abc960", "pub-id_pmid": "33176294", "section_type": "REF", "source": "Physiol. Meas.", "type": "ref", "volume": "41", "year": "2021"}, "text": "Classification of 12-lead ECGs: the PhysioNet/computing in cardiology challenge 2020", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 65390, "infons": {"fpage": "1486", "lpage": "90", "name_0": "surname:Annas;given-names:G J", "pub-id_doi": "10.1056/NEJMlim035027", "pub-id_pmid": "12686707", "section_type": "REF", "source": "New Engl. J. Med.", "type": "ref", "volume": "348", "year": "2003"}, "text": "HIPAA regulations: a new era of medical-record privacy?", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 65446, "infons": {"fpage": "9357", "lpage": "66", "name_0": "surname:Baek;given-names:Y", "name_1": "surname:Lee;given-names:B", "name_2": "surname:Han;given-names:D", "name_3": "surname:Yun;given-names:S", "name_4": "surname:Lee;given-names:H", "pub-id_doi": "10.1109/cvpr.2019.00959", "section_type": "REF", "type": "ref", "year": "2019"}, "text": "Character region awareness for text detection", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 65492, "infons": {"fpage": "1", "lpage": "8", "name_0": "surname:Baydoun;given-names:M", "name_1": "surname:Safatly;given-names:L", "name_2": "surname:Abou Hassan;given-names:O K", "name_3": "surname:Ghaziri;given-names:H", "name_4": "surname:El Hajj;given-names:A", "name_5": "surname:Isma\u2019eel;given-names:H", "pub-id_doi": "10.1109/JTEHM.2019.2949784", "section_type": "REF", "source": "IEEE J. Transl. Eng. Health Med.", "type": "ref", "volume": "7", "year": "2019"}, "text": "High precision digitization of paper-based ECG records: a step toward machine learning", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 65579, "infons": {"comment": "(available at: https://api.semanticscholar.org/CorpusID:4973468)", "fpage": "30", "lpage": "35", "name_0": "surname:Bisht;given-names:S S", "name_1": "surname:Gupta;given-names:B", "name_2": "surname:Rahi;given-names:P", "section_type": "REF", "source": "Int. J. Eng. Res. Appl.", "type": "ref", "volume": "4", "year": "2014"}, "text": "Image registration concept and techniques: a review", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 65631, "infons": {"fpage": "317", "lpage": "8", "name_0": "surname:Bousseljot;given-names:R", "name_1": "surname:Kreiseler;given-names:D", "name_2": "surname:Schnabel;given-names:A", "pub-id_doi": "10.1515/bmte.1995.40.s1.317", "section_type": "REF", "source": "Biomed. Tech./Biomed. Eng.", "type": "ref", "volume": "40", "year": "1995"}, "text": "Nutzung der EKG-Signaldatenbank CARDIODAT der PTB \u00fcber das Internet", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 65700, "infons": {"comment": "(available at: https://proceedings.mlr.press/v68/choi17a)", "fpage": "pp 286", "lpage": "305", "name_0": "surname:Choi;given-names:E", "name_1": "surname:Biswal;given-names:S", "name_2": "surname:Malin;given-names:B", "name_3": "surname:Duke;given-names:J", "name_4": "surname:Stewart;given-names:W F", "name_5": "surname:Sun;given-names:J", "section_type": "REF", "type": "ref", "year": "2017"}, "text": "Generating multi-label discrete patient records using generative adversarial networks", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 65786, "infons": {"fpage": "p 18", "name_0": "surname:Clifford;given-names:G D", "name_1": "surname:Azuaje;given-names:F", "name_2": "surname:Mcsharry;given-names:P", "section_type": "REF", "source": "Advanced Methods and Tools for ECG Data Analysis", "type": "ref", "volume": "vol 6", "year": "2006"}, "text": "", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 65787, "infons": {"fpage": "595", "name_0": "surname:Clifford;given-names:G D", "name_1": "surname:Nemati;given-names:S", "name_2": "surname:Sameni;given-names:R", "pub-id_doi": "10.1088/0967-3334/31/5/001", "pub-id_pmid": "20308774", "section_type": "REF", "source": "Physiol. Meas.", "type": "ref", "volume": "31", "year": "2010"}, "text": "An artificial vector model for generating abnormal electrocardiographic rhythms", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 65867, "infons": {"fpage": "785", "lpage": "94", "name_0": "surname:Dagenais;given-names:G R", "pub-id_doi": "10.1016/S0140-6736(19)32007-0", "pub-id_pmid": "31492501", "section_type": "REF", "source": "Lancet", "type": "ref", "volume": "395", "year": "2020"}, "text": "Variations in common diseases, hospital admissions and deaths in middle-aged adults in 21 countries from five continents (PURE): a prospective cohort study", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66023, "infons": {"fpage": "354", "lpage": "60", "name_0": "surname:Davis;given-names:J", "pub-id_doi": "10.1109/CVPR.1998.698630", "section_type": "REF", "type": "ref", "year": "1998"}, "text": "Mosaics of scenes with moving objects", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66061, "infons": {"fpage": "e8", "name_0": "surname:Demski;given-names:A J", "name_1": "surname:Soria;given-names:M L", "pub-id_doi": "10.5334/jors.86", "section_type": "REF", "source": "J. Open Res. Softw.", "type": "ref", "volume": "4", "year": "2016"}, "text": "ecg-kit: a MATLAB toolbox for cardiovascular signal processing", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66124, "infons": {"fpage": "1", "lpage": "6", "name_0": "surname:Dodge;given-names:S", "name_1": "surname:Karam;given-names:L", "pub-id_doi": "10.1109/QoMEX.2016.7498955", "section_type": "REF", "type": "ref", "year": "2016"}, "text": "Understanding how image quality affects deep neural networks", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66185, "infons": {"comment": "(arXiv:2301.02607)", "name_0": "surname:Dumitru;given-names:M", "name_1": "surname:Li;given-names:Q", "name_2": "surname:Alday;given-names:E A P", "name_3": "surname:Rad;given-names:A B", "name_4": "surname:Clifford;given-names:G D", "name_5": "surname:Sameni;given-names:R", "section_type": "REF", "type": "ref", "year": "2023"}, "text": "A data-driven Gaussian process filter for electrocardiogram denoising", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66255, "infons": {"fpage": "62", "lpage": "67", "name_0": "surname:Dwivedi;given-names:T", "name_1": "surname:Xue;given-names:J", "name_2": "surname:Treiman;given-names:D", "name_3": "surname:Dubey;given-names:A", "name_4": "surname:Albert;given-names:D", "pub-id_doi": "10.1016/j.jelectrocard.2022.12.001", "pub-id_pmid": "36641988", "section_type": "REF", "source": "J. Electrocardiol.", "type": "ref", "volume": "77", "year": "2023"}, "text": "Machine learning models of 6-lead ECGs for the interpretation of left ventricular hypertrophy (LVH)", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66355, "infons": {"fpage": "341", "lpage": "6", "name_0": "surname:Efros;given-names:A A", "name_1": "surname:Freeman;given-names:W T", "pub-id_doi": "10.1145/3596711.3596771", "section_type": "REF", "type": "ref", "year": "2001"}, "text": "Image quilting for texture synthesis and transfer", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66405, "infons": {"elocation-id": "106890", "name_0": "surname:Fortune;given-names:J D", "name_1": "surname:Coppa;given-names:N E", "name_2": "surname:Haq;given-names:K T", "name_3": "surname:Patel;given-names:H", "name_4": "surname:Tereshchenko;given-names:L G", "pub-id_doi": "10.1016/j.cmpb.2022.106890", "pub-id_pmid": "35598436", "section_type": "REF", "source": "Comput. Methods Programs Biomed.", "type": "ref", "volume": "221", "year": "2022"}, "text": "Digitizing ECG image: a new method and open-source software code", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66470, "infons": {"fpage": "1", "lpage": "9", "name_0": "surname:Ganesh;given-names:S", "name_1": "surname:Bhatti;given-names:P T", "name_2": "surname:Alkhalaf;given-names:M", "name_3": "surname:Gupta;given-names:S", "name_4": "surname:Shah;given-names:A J", "name_5": "surname:Tridandapani;given-names:S", "pub-id_doi": "10.1109/JTEHM.2021.3083482", "section_type": "REF", "source": "IEEE J. Transl. Eng. Health Med.", "type": "ref", "volume": "9", "year": "2021"}, "text": "Combining optical character recognition with paper ECG digitization", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66538, "infons": {"fpage": "35", "lpage": "38", "name_0": "surname:Garg;given-names:D K", "name_1": "surname:Thakur;given-names:D", "name_2": "surname:Sharma;given-names:S", "name_3": "surname:Bhardwaj;given-names:S", "pub-id_doi": "10.5120/7411-0485", "section_type": "REF", "source": "Int. J. Comput. Appl.", "type": "ref", "volume": "48", "year": "2012"}, "text": "ECG paper records digitization through image processing techniques", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66605, "infons": {"comment": "(available at: https://physionetchallenges.org/2024/) (Accessed 16 January 2024)", "section_type": "REF", "source": "Digitization and Classification of ECG Images: The George B. Moody PhysioNet Challenge 2024", "type": "ref", "year": "2024"}, "text": "", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66606, "infons": {"fpage": "e215", "lpage": "20", "name_0": "surname:Goldberger;given-names:A L", "name_1": "surname:Amaral;given-names:L A N", "name_2": "surname:Glass;given-names:L", "name_3": "surname:Hausdorff;given-names:J M", "name_4": "surname:Ivanov;given-names:P C", "name_5": "surname:Mark;given-names:R G", "name_6": "surname:Mietus;given-names:J E", "name_7": "surname:Moody;given-names:G B", "name_8": "surname:Peng;given-names:C-K", "name_9": "surname:Stanley;given-names:H E", "pub-id_doi": "10.1161/01.CIR.101.23.e215", "pub-id_pmid": "10851218", "section_type": "REF", "source": "Circulation", "type": "ref", "volume": "101", "year": "2000"}, "text": "PhysioBank, PhysioToolkit and PhysioNet: components of a new research resource for complex physiologic signals", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66717, "infons": {"comment": "(arXiv:1211.3711)", "name_0": "surname:Graves;given-names:A", "section_type": "REF", "type": "ref", "year": "2012"}, "text": "Sequence transduction with recurrent neural networks", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66770, "infons": {"comment": "(arXiv:1308.0850)", "name_0": "surname:Graves;given-names:A", "section_type": "REF", "type": "ref", "year": "2013"}, "text": "Generating sequences with recurrent neural networks", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66822, "infons": {"name_0": "surname:Helgason;given-names:S", "name_1": "surname:Helgason;given-names:S", "section_type": "REF", "source": "The Radon Transform", "type": "ref", "volume": "vol 2", "year": "1999"}, "text": "", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66823, "infons": {"fpage": "17", "lpage": "23", "name_0": "surname:Hjouj;given-names:F I", "name_1": "surname:Jouini;given-names:M S", "pub-id_doi": "10.1145/3506651.3506654", "section_type": "REF", "type": "ref", "year": "2021"}, "text": "On image registration using the radon transform: review-and-improvement", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66895, "infons": {"fpage": "688", "lpage": "97", "name_0": "surname:Honnibal;given-names:M", "name_1": "surname:Montani;given-names:I", "section_type": "REF", "source": "Proceedings of the Association for Computational Linguistics (ACL)", "type": "ref", "year": "2017"}, "text": "", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66896, "infons": {"comment": "(available at: https://buildmedia.readthedocs.org/media/pdf/imgaug/stable/imgaug.pdf)", "name_0": "surname:Jung;given-names:A", "section_type": "REF", "type": "ref", "year": "2019"}, "text": "Imgaug documentation", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66917, "infons": {"fpage": "i180", "lpage": "2", "name_0": "surname:Kim;given-names:J-D", "name_1": "surname:Ohta;given-names:T", "name_2": "surname:Tateisi;given-names:Y", "name_3": "surname:Tsujii;given-names:J", "pub-id_doi": "10.1093/bioinformatics/btg1023", "pub-id_pmid": "12855455", "section_type": "REF", "source": "Bioinformatics", "type": "ref", "volume": "19", "year": "2003"}, "text": "GENIA corpus\u2014a semantically annotated corpus for bio-textmining", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 66983, "infons": {"comment": "(arXiv:1806.08342)", "name_0": "surname:Krishnamoorthi;given-names:R", "section_type": "REF", "type": "ref", "year": "2018"}, "text": "Quantizing deep convolutional networks for efficient inference: a whitepaper", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 67060, "infons": {"comment": "(available at: https://www.usenix.org/conference/hotcloud19/presentation/kumar)", "name_0": "surname:Kumar;given-names:A", "name_1": "surname:Balasubramanian;given-names:A", "name_2": "surname:Venkataraman;given-names:S", "name_3": "surname:Akella;given-names:A", "section_type": "REF", "type": "ref", "year": "2019"}, "text": "Accelerating deep learning inference via freezing", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 67110, "infons": {"fpage": "673", "lpage": "6", "name_0": "surname:Laguna;given-names:P", "name_1": "surname:Mark;given-names:R G", "name_2": "surname:Goldberg;given-names:A", "name_3": "surname:Moody;given-names:G B", "pub-id_doi": "10.1109/CIC.1997.648140", "section_type": "REF", "type": "ref", "year": "1997"}, "text": "A database for evaluation of algorithms for measurement of QT and other waveform intervals in the ECG", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 67212, "infons": {"fpage": "2833", "lpage": "40", "name_0": "surname:Levin;given-names:A", "name_1": "surname:Nadler;given-names:B", "pub-id_doi": "10.1109/CVPR.2011.5995309", "section_type": "REF", "type": "ref", "year": "2011"}, "text": "Natural image denoising: optimality and inherent bounds", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 67268, "infons": {"elocation-id": "104077", "name_0": "surname:Li;given-names:Y", "name_1": "surname:Qu;given-names:Q", "name_2": "surname:Wang;given-names:M", "name_3": "surname:Yu;given-names:L", "name_4": "surname:Wang;given-names:J", "name_5": "surname:Shen;given-names:L", "name_6": "surname:He;given-names:K", "pub-id_doi": "10.1016/j.compbiomed.2020.104077", "pub-id_pmid": "33171291", "section_type": "REF", "source": "Comput. Biol. Med.", "type": "ref", "volume": "127", "year": "2020"}, "text": "Deep learning for digitizing highly noisy paper-based ECG records", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 67334, "infons": {"fpage": "127", "lpage": "50", "name_0": "surname:Liang;given-names:L", "name_1": "surname:Liu;given-names:C", "name_2": "surname:Xu;given-names:Y-Q", "name_3": "surname:Guo;given-names:B", "name_4": "surname:Shum;given-names:H-Y", "pub-id_doi": "10.1145/501786.501787", "section_type": "REF", "source": "ACM Trans. Graph.", "type": "ref", "volume": "20", "year": "2001"}, "text": "Real-time texture synthesis by patch-based sampling", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 67386, "infons": {"fpage": "1368", "lpage": "73", "name_0": "surname:Liu;given-names:F", "pub-id_doi": "10.1166/jmihi.2018.2442", "section_type": "REF", "source": "J. Med. Imaging Health Inform.", "type": "ref", "volume": "8", "year": "2018"}, "text": "An open access database for evaluating the algorithms of electrocardiogram rhythm and morphology abnormality detection", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 67505, "infons": {"name_0": "surname:Luthra;given-names:A", "section_type": "REF", "source": "ECG Made Easy", "type": "ref", "year": "2019"}, "text": "", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 67506, "infons": {"name_0": "surname:Malmivuo;given-names:J A", "name_1": "surname:Plonsey;given-names:R", "section_type": "REF", "source": "Bioelectromagnetism, Principles and Applications of Bioelectric and Biomagnetic Fields", "type": "ref", "year": "1995"}, "text": "", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 67507, "infons": {"comment": "(available at: https://physionet.org/content/qtdb/1.0.0/)", "name_0": "surname:Mark;given-names:R G", "name_1": "surname:Moody;given-names:G B", "section_type": "REF", "type": "ref", "year": "1999"}, "text": "The QT database", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 67523, "infons": {"fpage": "pp 101", "lpage": "4", "name_0": "surname:McClosky;given-names:D", "name_1": "surname:Charniak;given-names:E", "section_type": "REF", "type": "ref", "year": "2008"}, "text": "Self-training for biomedical parsing", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 67560, "infons": {"fpage": "289", "lpage": "94", "name_0": "surname:McSharry;given-names:P E", "name_1": "surname:Clifford;given-names:G D", "name_2": "surname:Tarassenko;given-names:L", "name_3": "surname:Smith;given-names:L A", "pub-id_doi": "10.1109/TBME.2003.808805", "pub-id_pmid": "12669985", "section_type": "REF", "source": "IEEE Trans. Biomed. Eng.", "type": "ref", "volume": "50", "year": "2003"}, "text": "A dynamical model for generating synthetic electrocardiogram signals", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 67629, "infons": {"fpage": "422", "lpage": "32", "name_0": "surname:Mishra;given-names:S", "name_1": "surname:Khatwani;given-names:G", "name_2": "surname:Patil;given-names:R", "name_3": "surname:Sapariya;given-names:D", "name_4": "surname:Shah;given-names:V", "name_5": "surname:Parmar;given-names:D", "name_6": "surname:Dinesh;given-names:S", "name_7": "surname:Daphal;given-names:P", "name_8": "surname:Mehendale;given-names:N", "pub-id_doi": "10.1007/s40846-021-00632-0", "pub-id_pmid": "34149335", "section_type": "REF", "source": "J. Med. Biol. Eng.", "type": "ref", "volume": "41", "year": "2021"}, "text": "ECG paper record digitization and diagnosis using deep learning", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 67693, "infons": {"comment": "(arXiv:1902.09476)", "name_0": "surname:Mohan;given-names:S", "name_1": "surname:Li;given-names:D", "section_type": "REF", "type": "ref", "year": "2019"}, "text": "MedMentions: a large biomedical corpus annotated with UMLS concepts", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 67761, "infons": {"comment": "(arXiv:1611.06440)", "name_0": "surname:Molchanov;given-names:P", "name_1": "surname:Tyree;given-names:S", "name_2": "surname:Karras;given-names:T", "name_3": "surname:Aila;given-names:T", "name_4": "surname:Kautz;given-names:J", "section_type": "REF", "type": "ref", "year": "2016"}, "text": "Pruning convolutional neural networks for resource efficient inference", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 67832, "infons": {"fpage": "pp 381", "lpage": "4", "name_0": "surname:Moody;given-names:G B", "name_1": "surname:Muldrow;given-names:W", "name_2": "surname:Mark;given-names:R G", "section_type": "REF", "type": "ref", "year": "1984"}, "text": "A noise stress test for arrhythmia detectors", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 67877, "infons": {"fpage": "2227", "lpage": "40", "name_0": "surname:Nacereddine;given-names:N", "name_1": "surname:Tabbone;given-names:S", "name_2": "surname:Ziou;given-names:D", "pub-id_doi": "10.1016/j.patcog.2015.01.017", "section_type": "REF", "source": "Pattern Recognit.", "type": "ref", "volume": "48", "year": "2015"}, "text": "Similarity transformation parameters recovery based on Radon transform. Application in image registration and object recognition", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 68006, "infons": {"comment": "(arXiv:1902.07669)", "name_0": "surname:Neumann;given-names:M", "name_1": "surname:King;given-names:D", "name_2": "surname:Beltagy;given-names:I", "name_3": "surname:Ammar;given-names:W", "section_type": "REF", "type": "ref", "year": "2019"}, "text": "ScispaCy: fast and robust models for biomedical natural language processing", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 68082, "infons": {"comment": "(available at: https://physionet.org/about/challenge/) (Accessed 16 January 2024)", "section_type": "REF", "source": "PhysioNet Challenges", "type": "ref", "year": "2024"}, "text": "", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 68083, "infons": {"elocation-id": "1800107", "name_0": "surname:Ravichandran;given-names:L", "name_1": "surname:Harless;given-names:C", "name_2": "surname:Shah;given-names:A J", "name_3": "surname:Wick;given-names:C A", "name_4": "surname:Mcclellan;given-names:J H", "name_5": "surname:Tridandapani;given-names:S", "pub-id_doi": "10.1109/JTEHM.2013.2262024", "pub-id_pmid": "26594601", "section_type": "REF", "source": "IEEE J. Transl. Eng. Health Med.", "type": "ref", "volume": "1", "year": "2013"}, "text": "Novel tool for complete digitization of paper electrocardiography data", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 68154, "infons": {"name_0": "surname:Redmon;given-names:J", "name_1": "surname:Divvala;given-names:S", "name_2": "surname:Girshick;given-names:R", "name_3": "surname:Farhadi;given-names:A", "pub-id_doi": "10.1109/CVPR.2016.91", "section_type": "REF", "type": "ref", "year": "2016"}, "text": "You only look once: unified, real-time object detection", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 68210, "infons": {"name_0": "surname:Reyna;given-names:M A", "pub-id_doi": "10.13026/34va-7q14", "section_type": "REF", "type": "ref", "year": "2022"}, "text": "Will two do? Varying dimensions in electrocardiography: the PhysioNet/computing in cardiology challenge 2021", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 68319, "infons": {"comment": "(available at: www.crummy.com/software/BeautifulSoup/)", "name_0": "surname:Richardson;given-names:L", "section_type": "REF", "type": "ref", "year": "2023"}, "text": "Beautiful Soup documentation (version 4.12.2)", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 68365, "infons": {"fpage": "1453", "lpage": "61", "name_0": "surname:Roonizi;given-names:E K", "name_1": "surname:Sameni;given-names:R", "pub-id_doi": "10.1016/j.compbiomed.2013.06.017", "pub-id_pmid": "24034737", "section_type": "REF", "source": "Comput. Biol. Med.", "type": "ref", "volume": "43", "year": "2013"}, "text": "Morphological modeling of cardiac signals based on signal decomposition", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 68437, "infons": {"fpage": "291", "lpage": "307", "name_0": "surname:Rosin;given-names:P L", "pub-id_doi": "10.1006/cviu.1998.0719", "section_type": "REF", "source": "Comput. Vis. Image Underst.", "type": "ref", "volume": "73", "year": "1999"}, "text": "Measuring corner properties", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 68465, "infons": {"fpage": "2564", "lpage": "71", "name_0": "surname:Rublee;given-names:E", "name_1": "surname:Rabaud;given-names:V", "name_2": "surname:Konolige;given-names:K", "name_3": "surname:Bradski;given-names:G", "pub-id_doi": "10.1109/ICCV.2011.6126544", "section_type": "REF", "type": "ref", "year": "2011"}, "text": "ORB: an efficient alternative to SIFT or SURF", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 68511, "infons": {"comment": "(available at: https://github.com/alphanumericslab/OSET.git)", "name_0": "surname:Sameni;given-names:R", "section_type": "REF", "type": "ref", "year": "2006\u20132024"}, "text": "The open-source electrophysiological toolbox (OSET)", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 68563, "infons": {"fpage": "1", "lpage": "14", "name_0": "surname:Sameni;given-names:R", "name_1": "surname:Clifford;given-names:G D", "name_2": "surname:Jutten;given-names:C", "name_3": "surname:Shamsollahi;given-names:M B", "pub-id_doi": "10.1155/2007/43407", "section_type": "REF", "source": "EURASIP J. Adv. Signal Process.", "type": "ref", "volume": "2007", "year": "2007"}, "text": "Multichannel ECG and noise modeling: application to maternal and fetal ECG signals", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 68646, "infons": {"fpage": "2298", "lpage": "304", "name_0": "surname:Shi;given-names:B", "name_1": "surname:Bai;given-names:X", "name_2": "surname:Yao;given-names:C", "pub-id_doi": "10.1109/TPAMI.2016.2646371", "pub-id_pmid": "28055850", "section_type": "REF", "source": "IEEE Trans. Pattern Anal. Mach. Intell.", "type": "ref", "volume": "39", "year": "2016"}, "text": "An end-to-end trainable neural network for image-based sequence recognition and its application to scene text recognition", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 68768, "infons": {"comment": "(arXiv:1409.1556)", "name_0": "surname:Simonyan;given-names:K", "name_1": "surname:Zisserman;given-names:A", "section_type": "REF", "type": "ref", "year": "2014"}, "text": "Very deep convolutional networks for large-scale image recognition", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 68835, "infons": {"fpage": "465", "lpage": "78", "name_0": "surname:Siontis;given-names:K C", "name_1": "surname:Noseworthy;given-names:P A", "name_2": "surname:Attia;given-names:Z I", "name_3": "surname:Friedman;given-names:P A", "pub-id_doi": "10.1038/s41569-020-00503-2", "pub-id_pmid": "33526938", "section_type": "REF", "source": "Nat. Rev. Cardiol.", "type": "ref", "volume": "18", "year": "2021"}, "text": "Artificial intelligence-enhanced electrocardiography in cardiovascular disease management", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 68925, "infons": {"fpage": "1", "lpage": "10", "name_0": "surname:Tareen;given-names:S A K", "name_1": "surname:Saleem;given-names:Z", "pub-id_doi": "10.1109/ICOMET.2018.8346440", "section_type": "REF", "type": "ref", "year": "2018"}, "text": "A comparative analysis of SIFT, SURF, KAZE, AKAZE, ORB and BRISK", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 68990, "infons": {"fpage": "23", "lpage": "34", "name_0": "surname:Telea;given-names:A", "pub-id_doi": "10.1080/10867651.2004.10487596", "section_type": "REF", "source": "J. Graph. Tools", "type": "ref", "volume": "9", "year": "2004"}, "text": "An image inpainting technique based on the fast marching method", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 69054, "infons": {"elocation-id": "21896", "name_0": "surname:Thambawita;given-names:V", "pub-id_doi": "10.1038/s41598-021-01295-2", "pub-id_pmid": "34753975", "section_type": "REF", "source": "Sci. Rep.", "type": "ref", "volume": "11", "year": "2021"}, "text": "Deepfake electrocardiograms using generative adversarial networks are the beginning of the end for privacy issues in medicine", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 69180, "infons": {"comment": "(available at: https://www.physionet.org/content/incartdb/1.0.0/)", "name_0": "surname:Tihonenko;given-names:V", "name_1": "surname:Khaustov;given-names:A", "name_2": "surname:Ivanov;given-names:S", "name_3": "surname:Rivin;given-names:A", "name_4": "surname:Yakushenko;given-names:E", "section_type": "REF", "source": "PhysioBank PhysioToolkit and PhysioNet", "type": "ref", "year": "2008"}, "text": "St Petersburg INCART 12-lead arrhythmia database", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 69229, "infons": {"fpage": "174", "lpage": "84", "name_0": "surname:Vinay;given-names:A", "name_1": "surname:Rao;given-names:A S", "name_2": "surname:Shekhar;given-names:V S", "name_3": "surname:Kumar C;given-names:A", "name_4": "surname:Murthy;given-names:K N B", "name_5": "surname:Natarajan;given-names:S", "pub-id_doi": "10.1016/j.procs.2015.10.068", "section_type": "REF", "source": "Proc. Comput. Sci.", "type": "ref", "volume": "70", "year": "2015"}, "text": "Feature extractionusing ORB-RANSAC for face recognition", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 69285, "infons": {"fpage": "1", "lpage": "15", "name_0": "surname:Wagner;given-names:P", "name_1": "surname:Strodthoff;given-names:N", "name_2": "surname:Bousseljot;given-names:R-D", "name_3": "surname:Kreiseler;given-names:D", "name_4": "surname:Lunze;given-names:F I", "name_5": "surname:Samek;given-names:W", "name_6": "surname:Schaeffter;given-names:T", "pub-id_doi": "10.1038/s41597-020-0495-6", "pub-id_pmid": "31896794", "section_type": "REF", "source": "Sci. Data", "type": "ref", "volume": "7", "year": "2020"}, "text": "PTB-XL, a large publicly available electrocardiography dataset", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 69348, "infons": {"fpage": "4935", "lpage": "43", "name_0": "surname:Wang;given-names:K", "name_1": "surname:Fang;given-names:B", "name_2": "surname:Qian;given-names:J", "name_3": "surname:Yang;given-names:S", "name_4": "surname:Zhou;given-names:X", "name_5": "surname:Zhou;given-names:J", "pub-id_doi": "10.1109/ACCESS.2019.2962572", "section_type": "REF", "source": "IEEE Access", "type": "ref", "volume": "8", "year": "2019"}, "text": "Perspective transformation data augmentation for object detection", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 69414, "infons": {"fpage": "479", "lpage": "88", "name_0": "surname:Wei;given-names:L-Y", "name_1": "surname:Levoy;given-names:M", "pub-id_doi": "10.1145/344779.345009", "section_type": "REF", "type": "ref", "year": "2000"}, "text": "Fast texture synthesis using tree-structured vector quantization", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 69479, "infons": {"comment": "(arXiv:2109.02543)", "name_0": "surname:Weldon;given-names:J", "name_1": "surname:Ward;given-names:T", "name_2": "surname:Brophy;given-names:E", "section_type": "REF", "type": "ref", "year": "2021"}, "text": "Generation of synthetic electronic health records using a federated GAN", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 69551, "infons": {"fpage": "S135", "name_0": "surname:Whyte;given-names:S", "name_1": "surname:Farhat;given-names:K", "name_2": "surname:Sample;given-names:K", "name_3": "surname:Barber;given-names:R", "name_4": "surname:Vera;given-names:A", "name_5": "surname:Shaw;given-names:A", "name_6": "surname:Wells-Serrano;given-names:N", "name_7": "surname:Xue;given-names:J", "name_8": "surname:Albert;given-names:D", "name_9": "surname:Stavrakis;given-names:S", "pub-id_doi": "10.1016/j.hrthm.2023.03.478", "section_type": "REF", "source": "Heart Rhythm", "type": "ref", "volume": "20", "year": "2023"}, "text": "Clinical validation of a mobile, artificial intelligence-guided, 12-lead ECG device", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 69635, "infons": {"fpage": "7112", "name_0": "surname:Wu;given-names:L", "name_1": "surname:Hu;given-names:S", "name_2": "surname:Liu;given-names:C", "pub-id_doi": "10.3390/s21217112", "pub-id_pmid": "34770418", "section_type": "REF", "source": "Sensors", "type": "ref", "volume": "21", "year": "2021"}, "text": "Exponential-distance weights for reducing grid-like artifacts in patch-based medical image registration", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 69739, "infons": {"fpage": "122", "lpage": "36", "name_0": "surname:Wulan;given-names:N", "name_1": "surname:Wang;given-names:W", "name_2": "surname:Sun;given-names:P", "name_3": "surname:Wang;given-names:K", "name_4": "surname:Xia;given-names:Y", "name_5": "surname:Zhang;given-names:H", "pub-id_doi": "10.1016/j.neucom.2020.04.076", "section_type": "REF", "source": "Neurocomputing", "type": "ref", "volume": "404", "year": "2020"}, "text": "Generating electrocardiogram signals by deep learning", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 69793, "infons": {"fpage": "1", "lpage": "17", "name_0": "surname:Xu;given-names:Y", "name_1": "surname:Hu;given-names:S", "name_2": "surname:Du;given-names:Y", "pub-id_doi": "10.1155/2022/2177159", "section_type": "REF", "source": "Comput. Math. Methods Med.", "type": "ref", "volume": "2022", "year": "2022"}, "text": "Research on optimization scheme for blocking artifacts after patch-based medical image reconstruction", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 69895, "infons": {"fpage": "141", "name_0": "surname:Yoon;given-names:J", "pub-id_doi": "10.1038/s41746-023-00888-7", "pub-id_pmid": "37567968", "section_type": "REF", "source": "npj Digit. Med.", "type": "ref", "volume": "6", "year": "2023"}, "text": "EHR-safe: generating high-fidelity and privacy-preserving synthetic electronic health records", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 69989, "infons": {"fpage": "3142", "lpage": "55", "name_0": "surname:Zhang;given-names:K", "name_1": "surname:Zuo;given-names:W", "name_2": "surname:Chen;given-names:Y", "name_3": "surname:Meng;given-names:D", "name_4": "surname:Zhang;given-names:L", "pub-id_doi": "10.1109/TIP.2017.2662206", "pub-id_pmid": "28166495", "section_type": "REF", "source": "IEEE Trans. Image Process.", "type": "ref", "volume": "26", "year": "2017"}, "text": "Beyond a Gaussian denoiser: residual learning of deep CNN for image denoising", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 70067, "infons": {"fpage": "6", "lpage": "14", "name_0": "surname:Zhang;given-names:Y-H", "name_1": "surname:Babaeizadeh;given-names:S", "pub-id_doi": "10.1016/j.jelectrocard.2021.08.019", "pub-id_pmid": "34474312", "section_type": "REF", "source": "J. Electrocardiol.", "type": "ref", "volume": "69", "year": "2021"}, "text": "Synthesis of standard 12-lead electrocardiograms using two-dimensional generative adversarial networks", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 70170, "infons": {"fpage": "581", "lpage": "6", "name_0": "surname:Zhao;given-names:C", "name_1": "surname:Shi;given-names:W", "name_2": "surname:Deng;given-names:Y", "pub-id_doi": "10.1016/j.patrec.2004.09.022", "section_type": "REF", "source": "Pattern Recognit. Lett.", "type": "ref", "volume": "26", "year": "2005"}, "text": "A new Hausdorff distance for image matching", "sentences": [], "annotations": [], "relations": []}, {"bioctype": "BioCPassage", "offset": 70214, "infons": {"fpage": "1", "lpage": "11", "name_0": "surname:Zhu;given-names:F", "name_1": "surname:Ye;given-names:F", "name_2": "surname:Fu;given-names:Y", "name_3": "surname:Liu;given-names:Q", "name_4": "surname:Shen;given-names:B", "pub-id_doi": "10.1038/s41598-019-42516-z", "pub-id_pmid": "30626917", "section_type": "REF", "source": "Sci. Rep.", "type": "ref", "volume": "9", "year": "2019"}, "text": "Electrocardiogram generation with a bidirectional LSTM-CNN generative adversarial network", "sentences": [], "annotations": [], "relations": []}], "annotations": [], "relations": []}]}]