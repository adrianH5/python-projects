[{"source": "PMC", "date": "20230126", "key": "pmc.key", "infons": {}, "documents": [{"id": "9855982", "infons": {"license": "CC BY"}, "passages": [{"offset": 0, "infons": {"article-id_doi": "10.3390/biomedicines11010067", "article-id_pmc": "9855982", "article-id_pmid": "36672575", "article-id_publisher-id": "biomedicines-11-00067", "elocation-id": "67", "issue": "1", "kwd": "deep learning drug-target interaction binding affinity graph neural network attention", "license": "Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).", "name_0": "surname:Bae;given-names:Haelee", "name_1": "surname:Nam;given-names:Hojung", "name_2": "surname:Wang;given-names:Lei", "section_type": "TITLE", "type": "front", "volume": "11", "year": "2023"}, "text": "GraphATT-DTA: Attention-Based Novel Representation of Interaction to Predict Drug-Target Binding Affinity", "sentences": [], "annotations": [], "relations": []}, {"offset": 106, "infons": {"section_type": "ABSTRACT", "type": "abstract"}, "text": "Drug-target binding affinity (DTA) prediction is an essential step in drug discovery. Drug-target protein binding occurs at specific regions between the protein and drug, rather than the entire protein and drug. However, existing deep-learning DTA prediction methods do not consider the interactions between drug substructures and protein sub-sequences. This work proposes GraphATT-DTA, a DTA prediction model that constructs the essential regions for determining interaction affinity between compounds and proteins, modeled with an attention mechanism for interpretability. We make the model consider the local-to-global interactions with the attention mechanism between compound and protein. As a result, GraphATT-DTA shows an improved prediction of DTA performance and interpretability compared with state-of-the-art models. The model is trained and evaluated with the Davis dataset, the human kinase dataset; an external evaluation is achieved with the independently proposed human kinase dataset from the BindingDB dataset.", "sentences": [], "annotations": [], "relations": []}, {"offset": 1135, "infons": {"section_type": "INTRO", "type": "title_1"}, "text": "1. Introduction", "sentences": [], "annotations": [], "relations": []}, {"offset": 1151, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Drug development is a high-risk industry involving complex experiments, drug discovery, and pre-clinical and clinical trials. Drug discovery is the process of identifying new candidate compounds with potential therapeutic effects, and it is essential for identify drug-target interactions (DTIs). Moreover, the drug-target binding affinity (DTA) provides information on the strength of the interaction between a drug-target pair. However, as there are millions of drug-like compounds, it can take years and costs about 24 million US dollars for experimental assays of target-to-hit process for a new drug. Efficient computational models for predicting DTA are urgently needed to speed up drug development and reduce resource consumption.", "sentences": [], "annotations": [], "relations": []}, {"offset": 1889, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "There are several computational approaches to predicting DTA. One is the ligand-based method, which compares a query ligand to known ligands based on their target proteins. However, prediction results become unreliable if the number of known ligands with target proteins is insufficient. Another approach is molecular docking, which simulates the binding of the conformational spaces between compounds and proteins based on their three-dimensional (3D) structures. However, it is too challenging to produce the 3D protein-ligand complex. Another approach is the chemogenomic method that integrates the chemical attributes of drug compounds, the genomic attributes of proteins, and their interactions into a unified math framework.", "sentences": [], "annotations": [], "relations": []}, {"offset": 2620, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "In feature-based chemogenomic methods, drug-target pairs are taken as input, and their binding strength or whether to interact, determined by regression or binary classification, are output. Efficient input representation is key to accurate prediction. The commonly used drug descriptor is chemical fingerprints such as Extended Connectivity Fingerprint or Molecular ACCess System. The commonly used protein descriptor is physicochemical properties, such as amino acid composition, transition, and distribution. On constructed features, random forest, support vector machine, and artificial neural network models are applied to predict these interactions. Similarity information is also used for representation. KronRLS constructs the similarity between drugs or between target proteins with compound similarity and Smith-Waterman similarity. SimBoost constructs features for each drug, target, and drug-target pair from the similarity. However, the fixed lengths of manually selected features may result in the loss of information.", "sentences": [], "annotations": [], "relations": []}, {"offset": 3653, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Recently, data-driven features learned during training using large datasets have been shown to increase DTI prediction performance. DeepDTA learns the representation of drugs and proteins with one-dimensional (1D) convolutional neural network (CNN). However, this leaves the molecule\u2019s original graph structure unaddressed. To cover this, GraphDTA represents a molecule as a graph in which a node is an atom, and an edge is a bond. Graph neural networks (GNN) are used for molecular representation and 1D CNNs are used for protein representation. Additionally, DGraphDTA represents a protein as a contact map followed by graph convolutional network (GCN) embedding to learn DTA using protein structure. However, when modeling DTA interactions, these models consider only the global interactions between compounds and proteins.", "sentences": [], "annotations": [], "relations": []}, {"offset": 4482, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Furthermore, several studies have introduced attention mechanisms to better model the interactions between drugs and proteins for DTA prediction. DeepAffinity introduced an attention mechanism used to interpret predictions by isolating the main contributors of molecular fragments into their pairs. ML-DTI propose the mutual learning mechanism. It takes input as Simplified Molecular-Input Line-Entry System (SMILES) and amino acid sequences, and 1D CNNs are used for encoding. It leverages protein information during compound encoding and compound information during protein encoding, resulting in a probability map between a global protein descriptor and a drug string feature vector. MATT-DTI proposes a relation-aware self-attention block to remodel drugs from SMILES data, considering the correlations between atoms. With this, 1D CNN is used for encoding. The interaction is modeled via multi-head attention, in which the drug is regarded as a key and the protein as a query and value. HyperAttentionDTI uses a hyperattention module that models semantic interdependencies in spatial and channel dimensions between drug and protein sub-sequences. FusionDTA applies a fusion layer comprising multi-head linear attention to focus on important tokens from the entire biological sequence. Additionally, the protein token is pre-trained with a transformer and encoded by bidirectional long short-term memory (BI-LSTM) layers. ", "sentences": [], "annotations": [], "relations": []}, {"offset": 5909, "infons": {"section_type": "INTRO", "type": "paragraph"}, "text": "Although these studies successfully apply attention mechanisms for DTA prediction, they are limited because they learn from less informative input features that do not consider the essential regions needed to determine interaction affinities. Therefore, in this paper, we propose GraphATT-DTA, an attention-based drug and protein representation neural network that considers local-to-global interactions for DTA prediction (Figure 1). The molecular graph of the compound and protein amino acid sequences are the initial inputs. A powerful GNN model is used for compound representation, and 1D CNNs are used for protein representation. The interactions between compounds and proteins are modeled with an attention mechanism by capturing the important subregions (i.e., substructures and sub-sequences) so that the fully connected layer can predict the binding affinity between a compound and its target protein. We evaluate the performance of our model using the Davis kinase binding affinity dataset and the public, web-accessible BindingDB database of measured binding affinities. GraphATT-DTA\u2019s prediction performance is then compared with state-of-the-art (SOTA) global and local interaction modeling methods.", "sentences": [], "annotations": [], "relations": []}, {"offset": 7124, "infons": {"section_type": "METHODS", "type": "title_1"}, "text": "2. Materials and Methods", "sentences": [], "annotations": [], "relations": []}, {"offset": 7149, "infons": {"section_type": "METHODS", "type": "title_2"}, "text": "2.1. Dataset", "sentences": [], "annotations": [], "relations": []}, {"offset": 7162, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "In this study, our proposed model and comparison baselines were trained with the Davis dataset and evaluated for external validity with the BindingDB dataset. Table 1 and Supplementary Table S1 provide a summary. The Davis dataset contains the kinase protein family and relevant inhibitors with dissociation constants , whose value is transformed into the log space as ", "sentences": [], "annotations": [], "relations": []}, {"offset": 7532, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "The BindingDB dataset is publicly accessible and contains experimentally measured binding affinities whose values are expressed as  terms. For the external test, we extracted drug-target pairs in which the protein is human kinase, and the binding affinity is recorded as a  value. These values are then transformed into the log space as described.", "sentences": [], "annotations": [], "relations": []}, {"offset": 7880, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "The Davis dataset consists of six parts. Five are used for cross-validation and one is used for testing. We use the same training and testing scheme as GraphDTA. The hyperparameter is tuned using five parts with five-fold cross-validation. After tuning the hyperparameter, we train all five parts and evaluate the performance with one test part. To evaluate the generalizability of the model, BindingDB is used as the external test dataset. ", "sentences": [], "annotations": [], "relations": []}, {"offset": 8322, "infons": {"section_type": "METHODS", "type": "title_2"}, "text": "2.2. Input Data Representation", "sentences": [], "annotations": [], "relations": []}, {"offset": 8353, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "GraphATT-DTA takes SMILES as the compound input and amino acid sequence string as the protein input. First, the SMILES string is converted to a graph structure that takes atoms as nodes and bonds as edges using the open-source Deep Graph Library (DGL) v.0.4.3(2), DGL-LifeSci v.0.2.4, and RDKit v.2019.03.1(1). We used the atomic feature defined in GraphDTA (i.e., atom symbol, number of adjacent atoms, number of adjacent hydrogens, implicit values of the atoms, and whether the atom is in aromatic structures). We leverage the bond feature used by the directed message-passing neural network (DMPNN; i.e., bond type, conjugation, in the ring, stereo). Table 2 and Table 3 list detailed information for each feature. Each amino acid sequence type is encoded with an integer and cut by a maximum length of 1000. If the sequences are shorter than the maximum length, they are padded with zeros. The maximum length can cover at least 80% of all proteins.", "sentences": [], "annotations": [], "relations": []}, {"offset": 9306, "infons": {"section_type": "METHODS", "type": "title_2"}, "text": "2.3. Drug Representation Learning Model", "sentences": [], "annotations": [], "relations": []}, {"offset": 9346, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "The molecule is originally represented by a graph structure consisting of atoms and bonds. The GNN uses its structural information and applies a message-passing phase consisting of  and  functions. In the  function, node v aggregates information from its neighbor\u2019s hidden representation, . In the  function, it updates the previous hidden representation, , to a new hidden representation, , using messages  and the previous step of hidden representation, :  where  is the set of the neighbors of v in graph G, and  follows time step t of initial atom features, . This mechanism, in which atoms aggregate and update information from neighbor nodes, captures information about the substructure of the molecule. GNN models have variants, such as the graph convolutional network (GCN), graph attention network (GAT), graph isomorphism network (GIN), message-passing neural network (MPNN), and directed message-passing neural network (DMPNN), which can be leveraged by specifying the message_passing function, , and update function,  (see Table 4). The output is a drug embedding matrix, , where  is the number of atoms, and  is the dimension of the embedding vectors. In the drug embedding matrix, each atom has the information of its neighbor atoms (i.e., substructure) along with the number of GNN layers.", "sentences": [], "annotations": [], "relations": []}, {"offset": 10653, "infons": {"section_type": "METHODS", "type": "title_2"}, "text": "2.4. Protein Representation Learning Model", "sentences": [], "annotations": [], "relations": []}, {"offset": 10696, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "The Davis and BindingDB datasets have 21 and 20 amino acid types, respectively. Hence, we consider 21 and 20 amino acids for learning and testing, respectively. The integer forms of protein amino acid sequences become the input to the embedding layers. These are then used as input to three consecutive 1D convolutional layers, which learn representations from the raw sequence data of proteins. The CNN models capture local dependencies by sliding the input features with filters, and their output is the protein sub-sequence embedding matrix, , where  is the number of sub-sequences. The number of amino acids in a sub-sequence depends on the filter size. The larger the filter size, the greater the number of amino acids in the sub-sequence.", "sentences": [], "annotations": [], "relations": []}, {"offset": 11441, "infons": {"section_type": "METHODS", "type": "title_2"}, "text": "2.5. Interaction Learning Model", "sentences": [], "annotations": [], "relations": []}, {"offset": 11473, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "The relationship between the protein and the compound is a determinant key for DTA prediction. The attention mechanism can make the input pair information influence the computation of each other\u2019s representation. The input pairs can jointly learn a relationship. GraphATT-DTA model constructs the relation matrix  using dot product of protein and compound embedding where . It provides information about the relationship between the substructures of compounds and protein sub-sequences. ", "sentences": [], "annotations": [], "relations": []}, {"offset": 11963, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "GraphATT-DTA reflects the local interactions by considering the crucial relationships between protein sub-sequences and compound substructures. The subseq-wise/atom-wise SoftMax is applied to the relation matrix to construct the substructure and sub-sequence significance matrices. The formulas appear in (5) and (6). The element of substructure_significance indicates the substructure\u2019s importance to the sub-sequence. Similarly, the element of subsequence_significance indicates the sub-sequence\u2019s importance to the substructure.  ", "sentences": [], "annotations": [], "relations": []}, {"offset": 12501, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "The substructure_significance is directed to the drug embedding matrix via element-wise multiplication () with  and , where , and .  indicates each substructure\u2019s importance of the jth sub-sequence.  indicates the drug embedding matrix with the importance of the jth sub-sequence. ", "sentences": [], "annotations": [], "relations": []}, {"offset": 12785, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "Drug vector  is constructed by (8) and carries the information of the compound and the jth sub-sequence, where .  ", "sentences": [], "annotations": [], "relations": []}, {"offset": 12900, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "The concatenation of  with all sub-sequences causes  to inherit all information about the sub-sequences and compounds, where . The new drug feature is thus constructed to reflect all protein sequences and compound atoms where . ", "sentences": [], "annotations": [], "relations": []}, {"offset": 13129, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "The new protein feature is calculated the same way. Using the element-wise multiplication of the subsequence_significance and protein embedding matrix, the protein embedding matrix, , with the ith substructure significance to the sub-sequence, is constructed so that , and . The summation of  makes protein vector  with the sub-sequence information about the compound, where . After the concatenation of , the summation of  makes the new protein feature vector reflect compound sub-structure significance information, where , and .    ", "sentences": [], "annotations": [], "relations": []}, {"offset": 13665, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "Protein and drug features reflecting the local-to-global interaction information are collected via concatenation. The fully connected layers can then predict the binding affinity. We use mean squared error (MSE) as the loss function.", "sentences": [], "annotations": [], "relations": []}, {"offset": 13899, "infons": {"section_type": "METHODS", "type": "title_2"}, "text": "2.6. Implementation and Hyperparameter Settings", "sentences": [], "annotations": [], "relations": []}, {"offset": 13947, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "GraphATT-DTA was implemented with Pytorch 1.5.0, and the GNN models were built with DGL v.0.4.3(2) and DGL-LifeSci v.0.2.4. Early stopping was configured with the patience of 30 epochs to avoid potential overfitting and obtain improved generalization performance. The hyperparameter settings are summarized in Table 5. Multiple experiments are used with five-fold cross-validation, applied for hyperparameter selection. ", "sentences": [], "annotations": [], "relations": []}, {"offset": 14368, "infons": {"section_type": "METHODS", "type": "paragraph"}, "text": "The layers of GNN are important because they pertain to how many neighbor nodes are regarded by the model. Because there are many layers, the model can consider many neighbors; however, doing so can cause an over-smoothing problem in which all node embeddings converge to the same value. Additionally, if the number of layers is too small, the graph substructure will not be captured. Therefore, proper layer configuration is important. The optimal number of GNN layers was experimentally chosen for GraphATT-DTA by using each GNN graph embedding model. Specific experimental results can be found in Supplementary Table S2 and Supplementary\u00a0Figure S1.", "sentences": [], "annotations": [], "relations": []}, {"offset": 15021, "infons": {"section_type": "RESULTS", "type": "title_1"}, "text": "3. Results", "sentences": [], "annotations": [], "relations": []}, {"offset": 15032, "infons": {"section_type": "RESULTS", "type": "title_2"}, "text": "3.1. Performance Evaluation Metrics", "sentences": [], "annotations": [], "relations": []}, {"offset": 15068, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "We used the concordance index (CI) and MSE to evaluate prediction performance. We formulated the CI to estimate whether the predicted binding affinity values were in the same order as their true values.  is the prediction value with the larger affinity, ,  is the prediction value with the smaller affinity, ,  is a normalization constant, and h(x) is the step function.  ", "sentences": [], "annotations": [], "relations": []}, {"offset": 15441, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "The MSE was used to calculate the differences between predicted and true affinity values,  is the predictive score,  is the ground-truth score, and  is the number of samples. ", "sentences": [], "annotations": [], "relations": []}, {"offset": 15617, "infons": {"section_type": "RESULTS", "type": "title_2"}, "text": "3.2. Binding Affinity Prediction on Testing Data", "sentences": [], "annotations": [], "relations": []}, {"offset": 15666, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "First, we investigated the predictive performance of GraphATT-DTA using various graph embedding models. The drug was represented using different graphs embedding models such as GCN, GAT, GIN, MPNN, and DMPNN. We performed ten times repeated training and testing. In Figure 2, we report the mean and standard deviation scores of the MSE and CI from the Davis dataset. The drug embedding models showed similar performances (i.e., MSE and CI). For MSE, the GIN drug embedding model performed best with an MSE of 0.213, followed by the GCN and MPNN models with MSEs of 0.214 and 0.215. For CI, MPNN performed best, with a CI of 0.899, followed by DMPNN and GCN.", "sentences": [], "annotations": [], "relations": []}, {"offset": 16324, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "Next, using the compound embedding model, we evaluated the overall affinity prediction performance again using the Davis dataset. Figure 3 illustrates the correlations between the true and predicted affinity scores. Here, MSE, Pearson correlation, CI, and R2 values are reported on graphs\u2019 y-axes. When the model predicts the binding affinity perfectly, the slope follows the y = x line. In the Davis dataset, we observed that the predicted distribution follows the true binding affinity quite well (MSE 0.204).", "sentences": [], "annotations": [], "relations": []}, {"offset": 16838, "infons": {"section_type": "RESULTS", "type": "title_2"}, "text": "3.3. Comparison with Other Methods ", "sentences": [], "annotations": [], "relations": []}, {"offset": 16874, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "For comparisons, we considered both global and local interaction modeling methods. Global methods included DeepDTA and GraphDTA, and local methods included DeepAffinity, ML-DTI, HyperAttentionDTI, and FusionDTA. For a fair comparison, we used the same training and testing datasets. The Davis dataset consists of six parts: five for training and one for testing. Finally, the model showing the best prediction performance was selected, and if the model used early stopping for training, we also applied early stopping on the Davis testing dataset to avoid overfitting. We trained using the same hyperparameter settings described in the baseline model papers. ", "sentences": [], "annotations": [], "relations": []}, {"offset": 17534, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "DeepDTA used 1D CNNs to learn representations from the raw sequence data from SMILES of drugs and amino acids of a protein. After pooling the final convolution layer, the drug and protein features were concatenated, and the fully connected layers regressed the DTA.", "sentences": [], "annotations": [], "relations": []}, {"offset": 17800, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "GraphDTA represents drugs as molecule graphs and uses GNNs for molecule representation. The amino acid sequences were the protein inputs, and 1D CNNs were used for protein representation. Max-pooling was applied, followed by concatenation, and the DTA was predicted using hidden layers. GCN, GAT, GIN, and GCN\u2013GAT models were tested, and GIN was the best performer. Hence, we used it for molecule embedding. It did not use early stopping; thus, the best model performance on the Davis testing dataset was selected for testing on the BindingDB.", "sentences": [], "annotations": [], "relations": []}, {"offset": 18346, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "DeepAffinity takes the SMILES string of the compound and the structural propery sequence (SPS) of the protein. SPS includes secondary structure elements, solvent accessibility, physico-chemical characteristics, and lengths. The secondary structure element and solvent accessibility are determined using the SSPro prediction model, and the input is pretrained using the Seq2seq autoencoder. After the recurrent neural network (RNN) encodes the input, the pair is represented by a weighted compound and protein summation. Joint attention is then calculated using the compound and protein string pairs. In the original study, the researchers predicted the pIC50 value using a model trained by the BindingDB dataset.", "sentences": [], "annotations": [], "relations": []}, {"offset": 19059, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "ML-DTI applies a mutual learning mechanism and takes SMILES and amino acid sequences as input; 1D CNNs are used for encoding. The model leverages protein information during compound encoding and vice versa. It creates a probability map between the global protein descriptor and drug string feature vector. In the original study, the researchers used the Davis dataset processed by PADME for training and testing. The number of drugs was 72, the targets were 442, and the interactions were 31,824. However, to compare the performances, we used the same Davis dataset as GraphATT-DTA, which consisted of 68 drugs and 442 targets. ", "sentences": [], "annotations": [], "relations": []}, {"offset": 19688, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "HyperAttentionDTI takes compound SMILES and protein input as amino acid sequences. 1D CNN layers encode the compound and protein representations, and a hyperattention module models the semantic interdependencies spatially and channel-wise between the drug and protein sub-sequences. DTI is predicted via binary classification; hence, we changed the last layer and applied MSE to the loss function. ", "sentences": [], "annotations": [], "relations": []}, {"offset": 20087, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "FusionDTA uses a pretrained transformer and BI-LSTM to encode amino acid sequence, and BI-LSTM to encode SMILES. The original researchers proposed a fusion layer, which consisted of a multi-head linear attention layer that focused on the important token from the biological sequence and aggregated global information based on the attention score. The fully connected layer then predicts binding affinity. ", "sentences": [], "annotations": [], "relations": []}, {"offset": 20493, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "Table 6 and Table 7 report the MSE and CI scores of the Davis and external BindingDB datasets, respectively. We used the model trained on the Davis dataset to evaluate the BindingDB external dataset and verify its generalizability. GraphATT-DTA consistently performed well on both sets. ", "sentences": [], "annotations": [], "relations": []}, {"offset": 20781, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "For the Davis dataset, the results are shown in Table 6. GraphATT-DTA achieved an MSE of 0.204 and a CI of 0.904. The local interaction modeling methods tend to exhibit superior performance to the global interaction methods. Local interaction methods employ local characteristics extracted from protein and compound to predict DTA. This gives the model a more comprehensive insight into the interacting parts of the protein and the compound. Thus, such models perform better when predicting drug-target affinity based on the training data.", "sentences": [], "annotations": [], "relations": []}, {"offset": 21321, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "For the external BindingDB dataset test, GraphATT-DTA achieved an MSE of 1.582 and a CI of 0.651. The BindingDB dataset consisted of various large human kinase DTA pairs. The local interaction modeling methods had better results because the attention mechanism caused the model to have a more informative representation. Additionally, early stopping seems to have played an important role as it avoided overfitting. Compared with other models, GraphATT-DTA showed consistently higher performance on both the Davis and BindingDB datasets. Additionally, when comparing the performance per drug scaffold, we confirmed that no particular prediction model has a specially high or low prediction performance for a specific scaffold (Supplementary Figures S2 and S3). However, there were performance gaps between the two. We speculate that discrepancies in the predicted affinity values vs. actual affinity values (pKd) in the two datasets led to performance deterioration. That is, in the Davis dataset, the lowest pKd value was five (10 \u00b5M). However, for the BindingDB dataset, many samples had values lower than five (Supplementary Figure S4). ", "sentences": [], "annotations": [], "relations": []}, {"offset": 22466, "infons": {"section_type": "RESULTS", "type": "title_2"}, "text": "3.4. Ablation Study ", "sentences": [], "annotations": [], "relations": []}, {"offset": 22487, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "Next, we performed an ablation study of the GraphATT-DTA model to confirm the advantages obtained by the attention interaction. The ablation model used max-pooling on the drug and protein embedding matrices, followed by concatenation. The fully connected layers predicted the binding affinity. The drug and protein embedding modules were the same as those in the proposed GraphATT-DTA model. Figure 4 compares the performances of concatenation and attention. The results showed that interaction modeling with the attention mechanism had more predictive power.", "sentences": [], "annotations": [], "relations": []}, {"offset": 23047, "infons": {"section_type": "RESULTS", "type": "title_2"}, "text": "3.5. Visualization with a Case Study", "sentences": [], "annotations": [], "relations": []}, {"offset": 23084, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "The proposed GraphATT-DTA uses an attention mechanism to consider the important interactions between molecule substructures and protein sub-sequences when predicting the DTA score. For substructure and sub-sequence significance score matrices, we investigated where high attention scores existed. Thus, we prepared a visualized case study experiment for the GraphATT-DTA (Figure 5, Supplementary Figure S5). For this, we selected the complex compound Lapatinib and gene EGFR (PDB ID: 1XKK). The actual affinity was 8.38, and the predicted affinity was 7.58 via GraphATT-DTA using GCN.", "sentences": [], "annotations": [], "relations": []}, {"offset": 23669, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "For the 1XKK complex, we found that the high attention scores were clustered near the residue, from 780 to 807 of the protein and quinazoline substructure of the drug. The binding positions of the RCSB PDB showed that the focused interaction between the sub-sequence and substructure, as determined by GraphATT-DTA was one of the true binding sites. The residue, 793 Methionine, and atom, Nitrogen, have a true hydrogen bond. Figure 5a shows the 3D structure of Lapatinib and EGFR, where we colored a ligand as green, the true binding sites are yellow, and hydrogen bonds are red. In Figure 5b, we colored ligand substructures with a high attention score in orange and protein regions with a high attention score in light blue.", "sentences": [], "annotations": [], "relations": []}, {"offset": 24397, "infons": {"section_type": "RESULTS", "type": "paragraph"}, "text": "The substructure significance is visualized in Figure 5b, where a high score was matched to atoms. From the drug substructure\u2019s perspective, the quinazoline substructure referred to the sub-sequence index, including 793 methionine as the important protein sub-sequence. Figure 5c shows the significances matched to the sub-sequences. From the protein sub-sequence\u2019s perspective, the sub-sequence index, including 793 methionine, regarded quinazoline as the important compound substructure. We identified the top five significance scores from the two significance matrices, finding that they had the same substructure-subsequence pairs. This result indicates that the sub-sequence deemed important by the substructure and the substructure deemed important by the sub-sequence retain the same position in the drug target pair.", "sentences": [], "annotations": [], "relations": []}, {"offset": 25226, "infons": {"section_type": "DISCUSS", "type": "title_1"}, "text": "4. Discussion and Conclusions", "sentences": [], "annotations": [], "relations": []}, {"offset": 25256, "infons": {"section_type": "DISCUSS", "type": "paragraph"}, "text": "Identification of DTIs is an essential step for finding novel drug candidates for a given target protein or vice versa. Once initial binding molecules are successfully identified, the next step is to optimize the activity by enhancing the binding affinity between molecules. Thus, DTA prediction models could be used in many efficient ways in the compound optimization process.", "sentences": [], "annotations": [], "relations": []}, {"offset": 25634, "infons": {"section_type": "DISCUSS", "type": "paragraph"}, "text": "In this paper, we proposed an attention-based novel representation that considers local-to-global interactions to predict DTA. We used a powerful GNN to describe the raw graph data of drugs and 1D CNNs for raw amino acid sequences of proteins. The attention mechanism was used to construct a new molecule and the protein feature that reflects the relationship between the compound substructure and protein sub-sequence. Consequently, the physical interaction patterns between proteins and compounds can be captured by these attention-based protein sequential and molecule graph feature representations. Moreover, in our model, binding patterns of proteins with diverse 3D structures can be addressed during the learning phase and it is one of the advantages of employing 2D sequential features as opposed to 3D structural features. In this regard, the proposed method is not limited to be applied to specific structured proteins but can be applied to more generally structured proteins.", "sentences": [], "annotations": [], "relations": []}, {"offset": 26621, "infons": {"section_type": "DISCUSS", "type": "paragraph"}, "text": "In the case of the performance evaluation, prediction results with the Davis and BindingDB datasets clearly demonstrated the efficacy of the proposed method. We observed that the precise modeling of the interaction allowed for more efficient feature learning from training data. Consequently, when modeling DTA, if interaction patterns are observed during training for affinity prediction, the prediction performance can be improved to the point where the model can provide guidance regarding unidentified drug-protein interaction regions. In addition, our case study demonstrated that GraphATT-DTA can provide unique biological insights to help understand the predicted binding affinity based on the attention scores. We also identified a substructure with high attention scores of a compound that triggers decreasing the binding affinity between EGFR and Canertinib (Supplementary Figures S6 and S7). Notably, it is well known that the overall performance of the deep learning model heavily depends on the training data. Due to the fact that only kinase inhibitors are included in the training dataset used in this study, the performance of the proposed model against other proteins may be compromised. Thus, in order to provide more general DTA predictions, it is necessary to construct large-scale benchmark datasets containing different classes of proteins.", "sentences": [], "annotations": [], "relations": []}, {"offset": 27984, "infons": {"section_type": "DISCUSS", "type": "paragraph"}, "text": "The mutation of protein can lead to human disease. The mutated amino acid can change biological functions and three-dimensional structures that can change the binding affinity. However, no SOTA models have yet incorporated the concept of mutational alteration effects on protein sequence for modeling DTA (Supplementary Tables S3 and S4; Supplementary Figure S8). For future research, it is necessary to develop a deep-learning model that can identify small-scale alterations in a protein sequence and apply their effects to predicting DTIs and DTAs. ", "sentences": [], "annotations": [], "relations": []}, {"offset": 28536, "infons": {"section_type": "DISCUSS", "type": "paragraph"}, "text": "Recently, deep-learning models that predict protein structures based only on amino acid sequences have been developed. With such methods, the binding pockets of proteins can be captured, and interactions can be modeled for drug target affinity prediction. We believe that such approaches will soon allow us to achieve higher performance, and leave the exploration using interaction sites with binding pockets in a data-driven manner to future work.", "sentences": [], "annotations": [], "relations": []}, {"offset": 28985, "infons": {"section_type": "DISCUSS", "type": "footnote"}, "text": "Disclaimer/Publisher\u2019s Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods, instructions or products referred to in the content.", "sentences": [], "annotations": [], "relations": []}, {"offset": 29357, "infons": {"section_type": "SUPPL", "type": "title"}, "text": "Supplementary Materials", "sentences": [], "annotations": [], "relations": []}, {"offset": 29381, "infons": {"section_type": "SUPPL", "type": "paragraph"}, "text": "The following supporting information can be downloaded at: , Table S1: Davis and BindingDB test dataset statistics; Table S2: Results of 5-fold cross-validation; Figure S1: MSE during 5-fold cross-validation progress on Davis dataset. (a) GCN (b) GAT (c) GIN (d) MPNN (e) DMPNN; Figure S2: The ratio of negative DTA for each compound; Figure S3: Performance comparison of GraphATT-DTA and baseline models of each scaffold (a) Concordance Index (CI) (b) Mean Squared Error (MSE); Figure S4: Prediction from GraphATT-DTA model for BindingDB dataset; Figure S5: Visualization with Case Studies. (a) 3C4C (b) 3EFL; Figure S6: Top 5000 similar compounds with Canertinib; Figure S7: The substructure of Canertinib and 57721266 with high attention score; Table S3: Flt3 contingency table (odd ratio: 1.3); Table S4: EGFR contingency table (odd ratio: 2.5); Figure S8: Performance comparisons of GraphATT-DTA and baseline models on the difference between the affinity of wild and mutant proteins. (a) FLT3 (b) EGFR.", "sentences": [], "annotations": [], "relations": []}, {"offset": 30389, "infons": {"section_type": "AUTH_CONT", "type": "title"}, "text": "Author Contributions", "sentences": [], "annotations": [], "relations": []}, {"offset": 30410, "infons": {"section_type": "AUTH_CONT", "type": "paragraph"}, "text": "Conceptualization, H.B. and H.N.; methodology, H.B. and H.N.; writing\u2014original draft preparation, H.B.; writing\u2014review and editing, H.B. and H.N. All authors have read and agreed to the published version of the manuscript.", "sentences": [], "annotations": [], "relations": []}, {"offset": 30637, "infons": {"section_type": "AUTH_CONT", "type": "title"}, "text": "Institutional Review Board Statement", "sentences": [], "annotations": [], "relations": []}, {"offset": 30674, "infons": {"section_type": "AUTH_CONT", "type": "paragraph"}, "text": "Not applicable.", "sentences": [], "annotations": [], "relations": []}, {"offset": 30690, "infons": {"section_type": "AUTH_CONT", "type": "title"}, "text": "Informed Consent Statement", "sentences": [], "annotations": [], "relations": []}, {"offset": 30717, "infons": {"section_type": "AUTH_CONT", "type": "paragraph"}, "text": "Not applicable.", "sentences": [], "annotations": [], "relations": []}, {"offset": 30733, "infons": {"section_type": "SUPPL", "type": "title"}, "text": "Data Availability Statement", "sentences": [], "annotations": [], "relations": []}, {"offset": 30761, "infons": {"section_type": "SUPPL", "type": "paragraph"}, "text": "Not applicable.", "sentences": [], "annotations": [], "relations": []}, {"offset": 30777, "infons": {"section_type": "COMP_INT", "type": "title"}, "text": "Conflicts of Interest", "sentences": [], "annotations": [], "relations": []}, {"offset": 30799, "infons": {"section_type": "COMP_INT", "type": "paragraph"}, "text": "The authors declare no conflict of interest.", "sentences": [], "annotations": [], "relations": []}, {"offset": 30844, "infons": {"section_type": "REF", "type": "title"}, "text": "References", "sentences": [], "annotations": [], "relations": []}, {"offset": 30855, "infons": {"fpage": "203", "lpage": "214", "name_0": "surname:Paul;given-names:S.M.", "name_1": "surname:Mytelka;given-names:D.S.", "name_2": "surname:Dunwiddie;given-names:C.T.", "name_3": "surname:Persinger;given-names:C.C.", "name_4": "surname:Munos;given-names:B.H.", "name_5": "surname:Lindborg;given-names:S.R.", "name_6": "surname:Schacht;given-names:A.L.", "pub-id_pmid": "20168317", "section_type": "REF", "source": "Nat. Rev. Drug Discov.", "type": "ref", "volume": "9", "year": "2010"}, "text": "How to improve R&D productivity: The pharmaceutical industry's grand challenge", "sentences": [], "annotations": [], "relations": []}, {"offset": 30934, "infons": {"fpage": "247", "lpage": "269", "name_0": "surname:Bagherian;given-names:M.", "name_1": "surname:Sabeti;given-names:E.", "name_2": "surname:Wang;given-names:K.", "name_3": "surname:Sartor;given-names:M.A.", "name_4": "surname:Nikolovska-Coleska;given-names:Z.", "name_5": "surname:Najarian;given-names:K.", "pub-id_doi": "10.1093/bib/bbz157", "pub-id_pmid": "31950972", "section_type": "REF", "source": "Brief. Bioinform.", "type": "ref", "volume": "22", "year": "2021"}, "text": "Machine learning approaches and databases for prediction of drug\u2013target interaction: A survey paper", "sentences": [], "annotations": [], "relations": []}, {"offset": 31036, "infons": {"elocation-id": "2208", "name_0": "surname:Chen;given-names:R.", "name_1": "surname:Liu;given-names:X.", "name_2": "surname:Jin;given-names:S.", "name_3": "surname:Lin;given-names:J.", "name_4": "surname:Liu;given-names:J.", "pub-id_doi": "10.3390/molecules23092208", "pub-id_pmid": "30200333", "section_type": "REF", "source": "Molecules", "type": "ref", "volume": "23", "year": "2018"}, "text": "Machine learning for drug-target interaction prediction", "sentences": [], "annotations": [], "relations": []}, {"offset": 31092, "infons": {"fpage": "916", "lpage": "932", "name_0": "surname:Wallach;given-names:I.", "name_1": "surname:Heifets;given-names:A.", "pub-id_doi": "10.1021/acs.jcim.7b00403", "pub-id_pmid": "29698607", "section_type": "REF", "source": "J. Chem. Inf. Model.", "type": "ref", "volume": "58", "year": "2018"}, "text": "Most ligand-based classification benchmarks reward memorization rather than generalization", "sentences": [], "annotations": [], "relations": []}, {"offset": 31183, "infons": {"fpage": "320", "lpage": "328", "name_0": "surname:Li;given-names:J.", "name_1": "surname:Fu;given-names:A.", "name_2": "surname:Zhang;given-names:L.", "pub-id_doi": "10.1007/s12539-019-00327-w", "section_type": "REF", "source": "Interdiscip. Sci. Comput. Life Sci.", "type": "ref", "volume": "11", "year": "2019"}, "text": "An overview of scoring functions used for protein\u2013ligand interactions in molecular docking", "sentences": [], "annotations": [], "relations": []}, {"offset": 31276, "infons": {"fpage": "262", "lpage": "275", "name_0": "surname:Bredel;given-names:M.", "name_1": "surname:Jacoby;given-names:E.", "pub-id_doi": "10.1038/nrg1317", "pub-id_pmid": "15131650", "section_type": "REF", "source": "Nat. Rev. Genet.", "type": "ref", "volume": "5", "year": "2004"}, "text": "Chemogenomics: An emerging strategy for rapid target and drug discovery", "sentences": [], "annotations": [], "relations": []}, {"offset": 31348, "infons": {"fpage": "10520", "lpage": "10594", "name_0": "surname:Yang;given-names:X.", "name_1": "surname:Wang;given-names:Y.", "name_2": "surname:Byrne;given-names:R.", "name_3": "surname:Schneider;given-names:G.", "name_4": "surname:Yang;given-names:S.", "pub-id_doi": "10.1021/acs.chemrev.8b00728", "pub-id_pmid": "31294972", "section_type": "REF", "source": "Chem. Rev.", "type": "ref", "volume": "119", "year": "2019"}, "text": "Concepts of artificial intelligence for computer-assisted drug discovery", "sentences": [], "annotations": [], "relations": []}, {"offset": 31421, "infons": {"fpage": "463", "lpage": "477", "name_0": "surname:Vamathevan;given-names:J.", "name_1": "surname:Clark;given-names:D.", "name_2": "surname:Czodrowski;given-names:P.", "name_3": "surname:Dunham;given-names:I.", "name_4": "surname:Ferran;given-names:E.", "name_5": "surname:Lee;given-names:G.", "name_6": "surname:Li;given-names:B.", "name_7": "surname:Madabhushi;given-names:A.", "name_8": "surname:Shah;given-names:P.", "name_9": "surname:Spitzer;given-names:M.", "pub-id_doi": "10.1038/s41573-019-0024-5", "pub-id_pmid": "30976107", "section_type": "REF", "source": "Nat. Rev. Drug Discov.", "type": "ref", "volume": "18", "year": "2019"}, "text": "Applications of machine learning in drug discovery and development", "sentences": [], "annotations": [], "relations": []}, {"offset": 31488, "infons": {"fpage": "742", "lpage": "754", "name_0": "surname:Rogers;given-names:D.", "name_1": "surname:Hahn;given-names:M.", "pub-id_doi": "10.1021/ci100050t", "pub-id_pmid": "20426451", "section_type": "REF", "source": "J. Chem. Inf. Model.", "type": "ref", "volume": "50", "year": "2010"}, "text": "Extended-connectivity fingerprints", "sentences": [], "annotations": [], "relations": []}, {"offset": 31523, "infons": {"fpage": "1273", "lpage": "1280", "name_0": "surname:Durant;given-names:J.L.", "name_1": "surname:Leland;given-names:B.A.", "name_2": "surname:Henry;given-names:D.R.", "name_3": "surname:Nourse;given-names:J.G.", "pub-id_doi": "10.1021/ci010132r", "pub-id_pmid": "12444722", "section_type": "REF", "source": "J. Chem. Inf. Comput. Sci.", "type": "ref", "volume": "42", "year": "2002"}, "text": "Reoptimization of MDL keys for use in drug discovery", "sentences": [], "annotations": [], "relations": []}, {"offset": 31576, "infons": {"fpage": "1401", "lpage": "1409", "name_0": "surname:Wen;given-names:M.", "name_1": "surname:Zhang;given-names:Z.", "name_2": "surname:Niu;given-names:S.", "name_3": "surname:Sha;given-names:H.", "name_4": "surname:Yang;given-names:R.", "name_5": "surname:Yun;given-names:Y.", "name_6": "surname:Lu;given-names:H.", "pub-id_doi": "10.1021/acs.jproteome.6b00618", "pub-id_pmid": "28264154", "section_type": "REF", "source": "J. Proteome Res.", "type": "ref", "volume": "16", "year": "2017"}, "text": "Deep-learning-based drug\u2013target interaction prediction", "sentences": [], "annotations": [], "relations": []}, {"offset": 31633, "infons": {"fpage": "i509", "lpage": "i518", "name_0": "surname:Cichonska;given-names:A.", "name_1": "surname:Pahikkala;given-names:T.", "name_2": "surname:Szedmak;given-names:S.", "name_3": "surname:Julkunen;given-names:H.", "name_4": "surname:Airola;given-names:A.", "name_5": "surname:Heinonen;given-names:M.", "name_6": "surname:Aittokallio;given-names:T.", "name_7": "surname:Rousu;given-names:J.", "pub-id_doi": "10.1093/bioinformatics/bty277", "pub-id_pmid": "29949975", "section_type": "REF", "source": "Bioinformatics", "type": "ref", "volume": "34", "year": "2018"}, "text": "Learning with multiple pairwise kernels for drug bioactivity prediction", "sentences": [], "annotations": [], "relations": []}, {"offset": 31705, "infons": {"elocation-id": "e1005678", "name_0": "surname:Cichonska;given-names:A.", "name_1": "surname:Ravikumar;given-names:B.", "name_2": "surname:Parri;given-names:E.", "name_3": "surname:Timonen;given-names:S.", "name_4": "surname:Pahikkala;given-names:T.", "name_5": "surname:Airola;given-names:A.", "name_6": "surname:Wennerberg;given-names:K.", "name_7": "surname:Rousu;given-names:J.", "name_8": "surname:Aittokallio;given-names:T.", "pub-id_doi": "10.1371/journal.pcbi.1005678", "pub-id_pmid": "28787438", "section_type": "REF", "source": "PLoS Comput. Biol.", "type": "ref", "volume": "13", "year": "2017"}, "text": "Computational-experimental approach to drug-target interaction mapping: A case study on kinase inhibitors", "sentences": [], "annotations": [], "relations": []}, {"offset": 31811, "infons": {"fpage": "325", "lpage": "337", "name_0": "surname:Pahikkala;given-names:T.", "name_1": "surname:Airola;given-names:A.", "name_2": "surname:Pietil\u00e4;given-names:S.", "name_3": "surname:Shakyawar;given-names:S.", "name_4": "surname:Szwajda;given-names:A.", "name_5": "surname:Tang;given-names:J.", "name_6": "surname:Aittokallio;given-names:T.", "pub-id_doi": "10.1093/bib/bbu010", "pub-id_pmid": "24723570", "section_type": "REF", "source": "Brief. Bioinform.", "type": "ref", "volume": "16", "year": "2015"}, "text": "Toward more realistic drug\u2013target interaction predictions", "sentences": [], "annotations": [], "relations": []}, {"offset": 31871, "infons": {"fpage": "1", "lpage": "14", "name_0": "surname:He;given-names:T.", "name_1": "surname:Heidemeyer;given-names:M.", "name_2": "surname:Ban;given-names:F.", "name_3": "surname:Cherkasov;given-names:A.", "name_4": "surname:Ester;given-names:M.", "pub-id_doi": "10.1186/s13321-017-0209-z", "pub-id_pmid": "28316652", "section_type": "REF", "source": "J. Cheminform.", "type": "ref", "volume": "9", "year": "2017"}, "text": "SimBoost: A read-across approach for predicting drug\u2013target binding affinities using gradient boosting machines", "sentences": [], "annotations": [], "relations": []}, {"offset": 31985, "infons": {"fpage": "i821", "lpage": "i829", "name_0": "surname:\u00d6zt\u00fcrk;given-names:H.", "name_1": "surname:\u00d6zg\u00fcr;given-names:A.", "name_2": "surname:Ozkirimli;given-names:E.", "pub-id_doi": "10.1093/bioinformatics/bty593", "pub-id_pmid": "30423097", "section_type": "REF", "source": "Bioinformatics", "type": "ref", "volume": "34", "year": "2018"}, "text": "DeepDTA: Deep drug\u2013target binding affinity prediction", "sentences": [], "annotations": [], "relations": []}, {"offset": 32041, "infons": {"fpage": "1140", "lpage": "1147", "name_0": "surname:Nguyen;given-names:T.", "name_1": "surname:Le;given-names:H.", "name_2": "surname:Quinn;given-names:T.P.", "name_3": "surname:Nguyen;given-names:T.", "name_4": "surname:Le;given-names:T.D.", "name_5": "surname:Venkatesh;given-names:S.", "pub-id_doi": "10.1093/bioinformatics/btaa921", "pub-id_pmid": "33119053", "section_type": "REF", "source": "Bioinformatics", "type": "ref", "volume": "37", "year": "2021"}, "text": "GraphDTA: Predicting drug\u2013target binding affinity with graph neural networks", "sentences": [], "annotations": [], "relations": []}, {"offset": 32120, "infons": {"fpage": "20701", "lpage": "20712", "name_0": "surname:Jiang;given-names:M.", "name_1": "surname:Li;given-names:Z.", "name_2": "surname:Zhang;given-names:S.", "name_3": "surname:Wang;given-names:S.", "name_4": "surname:Wang;given-names:X.", "name_5": "surname:Yuan;given-names:Q.", "name_6": "surname:Wei;given-names:Z.", "pub-id_doi": "10.1039/D0RA02297G", "pub-id_pmid": "35517730", "section_type": "REF", "source": "RSC Adv.", "type": "ref", "volume": "10", "year": "2020"}, "text": "Drug\u2013target affinity prediction using graph neural network and contact maps", "sentences": [], "annotations": [], "relations": []}, {"offset": 32198, "infons": {"fpage": "717", "lpage": "722", "name_0": "surname:Quan;given-names:Z.", "name_1": "surname:Guo;given-names:Y.", "name_2": "surname:Lin;given-names:X.", "name_3": "surname:Wang;given-names:Z.-J.", "name_4": "surname:Zeng;given-names:X.", "section_type": "REF", "source": "Proceedings of the 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)", "type": "ref"}, "text": "Graphcpi: Graph neural representation learning for compound-protein interaction", "sentences": [], "annotations": [], "relations": []}, {"offset": 32278, "infons": {"fpage": "3329", "lpage": "3338", "name_0": "surname:Karimi;given-names:M.", "name_1": "surname:Wu;given-names:D.", "name_2": "surname:Wang;given-names:Z.", "name_3": "surname:Shen;given-names:Y.", "pub-id_doi": "10.1093/bioinformatics/btz111", "pub-id_pmid": "30768156", "section_type": "REF", "source": "Bioinformatics", "type": "ref", "volume": "35", "year": "2019"}, "text": "DeepAffinity: Interpretable deep learning of compound\u2013protein affinity through unified recurrent and convolutional neural networks", "sentences": [], "annotations": [], "relations": []}, {"offset": 32411, "infons": {"fpage": "4247", "lpage": "4261", "name_0": "surname:Yang;given-names:Z.", "name_1": "surname:Zhong;given-names:W.", "name_2": "surname:Zhao;given-names:L.", "name_3": "surname:Chen;given-names:C.Y.-C.", "pub-id_doi": "10.1021/acs.jpclett.1c00867", "pub-id_pmid": "33904745", "section_type": "REF", "source": "J. Phys. Chem. Lett.", "type": "ref", "volume": "12", "year": "2021"}, "text": "ML-DTI: Mutual learning mechanism for interpretable drug\u2013target interaction prediction", "sentences": [], "annotations": [], "relations": []}, {"offset": 32500, "infons": {"fpage": "bbab117", "name_0": "surname:Zeng;given-names:Y.", "name_1": "surname:Chen;given-names:X.", "name_2": "surname:Luo;given-names:Y.", "name_3": "surname:Li;given-names:X.", "name_4": "surname:Peng;given-names:D.", "pub-id_doi": "10.1093/bib/bbab117", "pub-id_pmid": "33866349", "section_type": "REF", "source": "Brief. Bioinform.", "type": "ref", "volume": "22", "year": "2021"}, "text": "Deep drug-target binding affinity prediction with multiple attention blocks", "sentences": [], "annotations": [], "relations": []}, {"offset": 32576, "infons": {"fpage": "655", "lpage": "662", "name_0": "surname:Zhao;given-names:Q.", "name_1": "surname:Zhao;given-names:H.", "name_2": "surname:Zheng;given-names:K.", "name_3": "surname:Wang;given-names:J.", "pub-id_doi": "10.1093/bioinformatics/btab715", "pub-id_pmid": "34664614", "section_type": "REF", "source": "Bioinformatics", "type": "ref", "volume": "38", "year": "2022"}, "text": "HyperAttentionDTI: Improving drug\u2013protein interaction prediction by sequence-based deep learning with attention mechanism", "sentences": [], "annotations": [], "relations": []}, {"offset": 32700, "infons": {"fpage": "bbab506", "name_0": "surname:Yuan;given-names:W.", "name_1": "surname:Chen;given-names:G.", "name_2": "surname:Chen;given-names:C.Y.-C.", "pub-id_doi": "10.1093/bib/bbab506", "pub-id_pmid": "34929738", "section_type": "REF", "source": "Brief. Bioinform.", "type": "ref", "volume": "23", "year": "2022"}, "text": "FusionDTA: Attention-based feature polymerizer and knowledge distillation for drug-target binding affinity prediction", "sentences": [], "annotations": [], "relations": []}, {"offset": 32818, "infons": {"fpage": "1046", "lpage": "1051", "name_0": "surname:Davis;given-names:M.I.", "name_1": "surname:Hunt;given-names:J.P.", "name_2": "surname:Herrgard;given-names:S.", "name_3": "surname:Ciceri;given-names:P.", "name_4": "surname:Wodicka;given-names:L.M.", "name_5": "surname:Pallares;given-names:G.", "name_6": "surname:Hocker;given-names:M.", "name_7": "surname:Treiber;given-names:D.K.", "name_8": "surname:Zarrinkar;given-names:P.P.", "pub-id_doi": "10.1038/nbt.1990", "pub-id_pmid": "22037378", "section_type": "REF", "source": "Nat. Biotechnol.", "type": "ref", "volume": "29", "year": "2011"}, "text": "Comprehensive analysis of kinase inhibitor selectivity", "sentences": [], "annotations": [], "relations": []}, {"offset": 32873, "infons": {"fpage": "D198", "lpage": "D201", "name_0": "surname:Liu;given-names:T.", "name_1": "surname:Lin;given-names:Y.", "name_2": "surname:Wen;given-names:X.", "name_3": "surname:Jorissen;given-names:R.N.", "name_4": "surname:Gilson;given-names:M.K.", "pub-id_doi": "10.1093/nar/gkl999", "pub-id_pmid": "17145705", "section_type": "REF", "source": "Nucleic Acids Res.", "type": "ref", "volume": "35", "year": "2007"}, "text": "BindingDB: A web-accessible database of experimentally determined protein\u2013ligand binding affinities", "sentences": [], "annotations": [], "relations": []}, {"offset": 32975, "infons": {"name_0": "surname:Wang;given-names:M.", "name_1": "surname:Zheng;given-names:D.", "name_2": "surname:Ye;given-names:Z.", "name_3": "surname:Gan;given-names:Q.", "name_4": "surname:Li;given-names:M.", "name_5": "surname:Song;given-names:X.", "name_6": "surname:Zhou;given-names:J.", "name_7": "surname:Ma;given-names:C.", "name_8": "surname:Yu;given-names:L.", "name_9": "surname:Gai;given-names:Y.", "pub-id_arxiv": "1909.01315", "section_type": "REF", "source": "arXiv Prepr.", "type": "ref", "year": "2019"}, "text": "Deep graph library: A graph-centric, highly-performant package for graph neural networks", "sentences": [], "annotations": [], "relations": []}, {"offset": 33064, "infons": {"fpage": "27233", "lpage": "27238", "name_0": "surname:Li;given-names:M.", "name_1": "surname:Zhou;given-names:J.", "name_2": "surname:Hu;given-names:J.", "name_3": "surname:Fan;given-names:W.", "name_4": "surname:Zhang;given-names:Y.", "name_5": "surname:Gu;given-names:Y.", "name_6": "surname:Karypis;given-names:G.", "pub-id_doi": "10.1021/acsomega.1c04017", "pub-id_pmid": "34693143", "section_type": "REF", "source": "ACS Omega", "type": "ref", "volume": "6", "year": "2021"}, "text": "Dgl-lifesci: An open-source toolkit for deep learning on graphs in life science", "sentences": [], "annotations": [], "relations": []}, {"offset": 33144, "infons": {"comment": "Available online: https://rdkit.org", "name_0": "surname:Landrum;given-names:G.", "section_type": "REF", "type": "ref"}, "text": "RDKit: Open-Source Cheminformatics", "sentences": [], "annotations": [], "relations": []}, {"offset": 33179, "infons": {"name_0": "surname:Kipf;given-names:T.", "name_1": "surname:Welling;given-names:M.", "pub-id_arxiv": "1609.02907", "section_type": "REF", "source": "arXiv", "type": "ref", "year": "2017"}, "text": "Semi-Supervised Classification with Graph Convolutional Networks", "sentences": [], "annotations": [], "relations": []}, {"offset": 33244, "infons": {"name_0": "surname:Velickovic;given-names:P.", "name_1": "surname:Cucurull;given-names:G.", "name_2": "surname:Casanova;given-names:A.", "name_3": "surname:Romero;given-names:A.", "name_4": "surname:Lio;given-names:P.", "name_5": "surname:Bengio;given-names:Y.J.A.", "pub-id_arxiv": "1710.10903", "section_type": "REF", "source": "arXiv", "type": "ref", "year": "2018"}, "text": "Graph Attention Networks", "sentences": [], "annotations": [], "relations": []}, {"offset": 33269, "infons": {"name_0": "surname:Xu;given-names:K.", "name_1": "surname:Hu;given-names:W.", "name_2": "surname:Leskovec;given-names:J.", "name_3": "surname:Jegelka;given-names:S.", "pub-id_arxiv": "1810.00826", "section_type": "REF", "source": "ArXiv", "type": "ref", "year": "2019"}, "text": "How Powerful are Graph Neural Networks?", "sentences": [], "annotations": [], "relations": []}, {"offset": 33309, "infons": {"name_0": "surname:Gilmer;given-names:J.", "name_1": "surname:Schoenholz;given-names:S.", "name_2": "surname:Riley;given-names:P.F.", "name_3": "surname:Vinyals;given-names:O.", "name_4": "surname:Dahl;given-names:G.E.", "pub-id_arxiv": "1704.01212", "section_type": "REF", "source": "ArXiv", "type": "ref", "year": "2017"}, "text": "Neural Message Passing for Quantum Chemistry", "sentences": [], "annotations": [], "relations": []}, {"offset": 33354, "infons": {"fpage": "3370", "lpage": "3388", "name_0": "surname:Yang;given-names:K.F.", "name_1": "surname:Swanson;given-names:K.", "name_2": "surname:Jin;given-names:W.", "name_3": "surname:Coley;given-names:C.W.", "name_4": "surname:Eiden;given-names:P.", "name_5": "surname:Gao;given-names:H.", "name_6": "surname:Guzman-Perez;given-names:A.", "name_7": "surname:Hopper;given-names:T.", "name_8": "surname:Kelley;given-names:B.", "name_9": "surname:Mathea;given-names:M.", "pub-id_doi": "10.1021/acs.jcim.9b00237", "pub-id_pmid": "31361484", "section_type": "REF", "source": "J. Chem. Inf. Model.", "type": "ref", "volume": "59", "year": "2019"}, "text": "Analyzing Learned Molecular Representations for Property Prediction", "sentences": [], "annotations": [], "relations": []}, {"offset": 33422, "infons": {"fpage": "32", "name_0": "surname:Paszke;given-names:A.", "name_1": "surname:Gross;given-names:S.", "name_2": "surname:Massa;given-names:F.", "name_3": "surname:Lerer;given-names:A.", "name_4": "surname:Bradbury;given-names:J.", "name_5": "surname:Chanan;given-names:G.", "name_6": "surname:Killeen;given-names:T.", "name_7": "surname:Lin;given-names:Z.", "name_8": "surname:Gimelshein;given-names:N.", "name_9": "surname:Antiga;given-names:L.", "section_type": "REF", "source": "NeurIPS\u201919: Proceedings of the 33rd International Conference on Neural Information Processing Systems", "type": "ref"}, "text": "Pytorch: An imperative style, high-performance deep learning library", "sentences": [], "annotations": [], "relations": []}, {"offset": 33491, "infons": {"fpage": "2887", "lpage": "2893", "name_0": "surname:Bemis;given-names:G.W.", "name_1": "surname:Murcko;given-names:M.A.", "pub-id_doi": "10.1021/jm9602928", "pub-id_pmid": "8709122", "section_type": "REF", "source": "J. Med. Chem.", "type": "ref", "volume": "39", "year": "1996"}, "text": "The properties of known drugs. 1. Molecular frameworks", "sentences": [], "annotations": [], "relations": []}, {"offset": 33546, "infons": {"fpage": "127", "lpage": "132", "name_0": "surname:Karaman;given-names:M.W.", "name_1": "surname:Herrgard;given-names:S.", "name_2": "surname:Treiber;given-names:D.K.", "name_3": "surname:Gallant;given-names:P.", "name_4": "surname:Atteridge;given-names:C.E.", "name_5": "surname:Campbell;given-names:B.T.", "name_6": "surname:Chan;given-names:K.W.", "name_7": "surname:Ciceri;given-names:P.", "name_8": "surname:Davis;given-names:M.I.", "name_9": "surname:Edeen;given-names:P.T.", "pub-id_doi": "10.1038/nbt1358", "pub-id_pmid": "18183025", "section_type": "REF", "source": "Nat. Biotechnol.", "type": "ref", "volume": "26", "year": "2008"}, "text": "A quantitative analysis of kinase inhibitor selectivity", "sentences": [], "annotations": [], "relations": []}, {"offset": 33602, "infons": {"fpage": "583", "lpage": "589", "name_0": "surname:Jumper;given-names:J.", "name_1": "surname:Evans;given-names:R.", "name_2": "surname:Pritzel;given-names:A.", "name_3": "surname:Green;given-names:T.", "name_4": "surname:Figurnov;given-names:M.", "name_5": "surname:Ronneberger;given-names:O.", "name_6": "surname:Tunyasuvunakool;given-names:K.", "name_7": "surname:Bates;given-names:R.", "name_8": "surname:\u017d\u00eddek;given-names:A.", "name_9": "surname:Potapenko;given-names:A.", "pub-id_doi": "10.1038/s41586-021-03819-2", "pub-id_pmid": "34265844", "section_type": "REF", "source": "Nature", "type": "ref", "volume": "596", "year": "2021"}, "text": "Highly accurate protein structure prediction with AlphaFold", "sentences": [], "annotations": [], "relations": []}, {"offset": 33662, "infons": {"fpage": "871", "lpage": "876", "name_0": "surname:Baek;given-names:M.", "name_1": "surname:DiMaio;given-names:F.", "name_2": "surname:Anishchenko;given-names:I.", "name_3": "surname:Dauparas;given-names:J.", "name_4": "surname:Ovchinnikov;given-names:S.", "name_5": "surname:Lee;given-names:G.R.", "name_6": "surname:Wang;given-names:J.", "name_7": "surname:Cong;given-names:Q.", "name_8": "surname:Kinch;given-names:L.N.", "name_9": "surname:Schaeffer;given-names:R.D.", "pub-id_doi": "10.1126/science.abj8754", "pub-id_pmid": "34282049", "section_type": "REF", "source": "Science", "type": "ref", "volume": "373", "year": "2021"}, "text": "Accurate prediction of protein structures and interactions using a three-track neural network", "sentences": [], "annotations": [], "relations": []}, {"offset": 33756, "infons": {"file": "biomedicines-11-00067-g001.jpg", "id": "biomedicines-11-00067-f001", "section_type": "FIG", "type": "fig_caption"}, "text": "GraphATT-DTA architecture. Molecule graph and protein amino acid sequences are taken as input, and the predicted binding affinity of drug-target pair is the output. The attention-based novel representation is learned by molecule encoding with a graph neural network, sequence encoding using convolutional neural networks, and interaction modeling. The local-to-global relationships between drug substructures and protein sub-sequences are learned via interaction modeling using an attention mechanism. CNN, convolutional neural network; GNN, graph neural network; D, drug embedding matrix; S, protein embedding matrix; R, relation matrix; a, atom-wise softmax of relation matrix; s, subseq-wise softmax of relation matrix.", "sentences": [], "annotations": [], "relations": []}, {"offset": 34479, "infons": {"file": "biomedicines-11-00067-g002.jpg", "id": "biomedicines-11-00067-f002", "section_type": "FIG", "type": "fig_caption"}, "text": "Binding affinity prediction results on the Davis test dataset. (a) Mean Squared Error (MSE); (b) Concordance Index (CI). We compared five GNN variants: the graph convolutional neural network (GCN), graph attention network (GAT), graph isomorphism network (GIN), message-passing neural network (MPNN), and direct message-passing neural network (DMPNN). The bars are the mean of ten models and the grey lines are error bars indicating the standard deviation.", "sentences": [], "annotations": [], "relations": []}, {"offset": 34936, "infons": {"file": "biomedicines-11-00067-g003.jpg", "id": "biomedicines-11-00067-f003", "section_type": "FIG", "type": "fig_caption"}, "text": "Prediction from the GraphATT-DTA model on the Davis testing data. The scatterplot shows the trend of the predicted affinity values vs. actual affinity values (pKd). The black line represents y = x. CI, concordance index; MSE, mean-squared error; Pearson, Pearson correlation; R2, r squared.", "sentences": [], "annotations": [], "relations": []}, {"offset": 35227, "infons": {"file": "biomedicines-11-00067-g004.jpg", "id": "biomedicines-11-00067-f004", "section_type": "FIG", "type": "fig_caption"}, "text": "Ablation study on the Davis dataset.", "sentences": [], "annotations": [], "relations": []}, {"offset": 35264, "infons": {"file": "biomedicines-11-00067-g005.jpg", "id": "biomedicines-11-00067-f005", "section_type": "FIG", "type": "fig_caption"}, "text": "Visualization of drug-target binding affinities with significant regions: (a) complex compound Lapatinib and gene EGFR (PDB ID: 1XKK), where the ligand is colored green, true binding sites are yellow, the hydrogen bond is red; (b) complex 1XKK and visualization of substructure significance, where the high attention of drug is orange, high attention of protein is light blue; (c) visualization of sub-sequence significance.", "sentences": [], "annotations": [], "relations": []}, {"offset": 35689, "infons": {"file": "biomedicines-11-00067-t001.xml", "id": "biomedicines-11-00067-t001", "section_type": "TABLE", "type": "table_caption"}, "text": "Datasets used for model training, validation, and testing.", "sentences": [], "annotations": [], "relations": []}, {"offset": 35748, "infons": {"file": "biomedicines-11-00067-t001.xml", "id": "biomedicines-11-00067-t001", "section_type": "TABLE", "type": "table", "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<table frame=\"hsides\" rules=\"groups\"><thead><tr><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Dataset</th><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Davis</th><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">BindingDB</th></tr></thead><tbody><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Proteins</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">442</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">509</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Compounds</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">68</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">4,076</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Interactions</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">30,056</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">14,505</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Training</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">25,046</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">\u2014</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Testing</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">5010</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">14,505</td></tr></tbody></table>\n"}, "text": "Dataset\tDavis\tBindingDB\t \tProteins\t442\t509\t \tCompounds\t68\t4,076\t \tInteractions\t30,056\t14,505\t \tTraining\t25,046\t\u2014\t \tTesting\t5010\t14,505\t \t", "sentences": [], "annotations": [], "relations": []}, {"offset": 35888, "infons": {"file": "biomedicines-11-00067-t002.xml", "id": "biomedicines-11-00067-t002", "section_type": "TABLE", "type": "table_caption"}, "text": "Input data representations: Compound atom features.", "sentences": [], "annotations": [], "relations": []}, {"offset": 35940, "infons": {"file": "biomedicines-11-00067-t002.xml", "id": "biomedicines-11-00067-t002", "section_type": "TABLE", "type": "table", "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<table frame=\"hsides\" rules=\"groups\"><thead><tr><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Feature</th><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Dimension</th></tr></thead><tbody><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">One hot encoding of the atom element</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">44</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">One hot encoding of the degree of the atom in the molecule</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">11</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">One hot encoding of the total number of H bonds to the atom</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">11</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">One hot encoding of the number of implicit H bonds to the atom</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">11</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Whether the atom is aromatic</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">All</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">78</td></tr></tbody></table>\n"}, "text": "Feature\tDimension\t \tOne hot encoding of the atom element\t44\t \tOne hot encoding of the degree of the atom in the molecule\t11\t \tOne hot encoding of the total number of H bonds to the atom\t11\t \tOne hot encoding of the number of implicit H bonds to the atom\t11\t \tWhether the atom is aromatic\t1\t \tAll\t78\t \t", "sentences": [], "annotations": [], "relations": []}, {"offset": 36242, "infons": {"file": "biomedicines-11-00067-t003.xml", "id": "biomedicines-11-00067-t003", "section_type": "TABLE", "type": "table_caption"}, "text": "Input data representations: Compound bond features.", "sentences": [], "annotations": [], "relations": []}, {"offset": 36294, "infons": {"file": "biomedicines-11-00067-t003.xml", "id": "biomedicines-11-00067-t003", "section_type": "TABLE", "type": "table", "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<table frame=\"hsides\" rules=\"groups\"><thead><tr><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Feature</th><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Dimension</th></tr></thead><tbody><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">One hot encoding of bond type</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">4</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">One hot encoding of bond conjugating</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">2</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">One hot encoding of whether the bond is part of a ring</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">2</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">One hot encoding of the stereo</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">6</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">All</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">14</td></tr></tbody></table>\n"}, "text": "Feature\tDimension\t \tOne hot encoding of bond type\t4\t \tOne hot encoding of bond conjugating\t2\t \tOne hot encoding of whether the bond is part of a ring\t2\t \tOne hot encoding of the stereo\t6\t \tAll\t14\t \t", "sentences": [], "annotations": [], "relations": []}, {"offset": 36493, "infons": {"file": "biomedicines-11-00067-t004.xml", "id": "biomedicines-11-00067-t004", "section_type": "TABLE", "type": "table_caption"}, "text": "Graph neural network variants used for drug embedding matrix generation.", "sentences": [], "annotations": [], "relations": []}, {"offset": 36566, "infons": {"file": "biomedicines-11-00067-t004.xml", "id": "biomedicines-11-00067-t004", "section_type": "TABLE", "type": "table", "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<table xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" frame=\"hsides\" rules=\"groups\"><thead><tr><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Model</th><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Message Passing Function</th><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Update Function</th></tr></thead><tbody><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">GCN</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\"><inline-formula><mml:math id=\"mm73\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>m</mml:mi></mml:mstyle><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>v</mml:mi></mml:mstyle><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>t</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munder><mml:mstyle mathsize=\"80%\" displaystyle=\"true\"><mml:mo>\u2211</mml:mo></mml:mstyle><mml:mrow><mml:mi mathvariant=\"normal\">w</mml:mi><mml:mo>\u2208</mml:mo><mml:mi mathvariant=\"normal\">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=\"normal\">v</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mstyle mathsize=\"80%\" displaystyle=\"true\"><mml:mo>\u222a</mml:mo></mml:mstyle><mml:mo>\u00a0</mml:mo></mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:mi mathvariant=\"normal\">v</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi mathvariant=\"normal\">c</mml:mi><mml:mrow><mml:mi>wv</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msubsup><mml:mi mathvariant=\"normal\">h</mml:mi><mml:mi mathvariant=\"normal\">w</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=\"normal\">t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>\u00a0<break/><inline-formula><mml:math id=\"mm74\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant=\"normal\">c</mml:mi><mml:mrow><mml:mi>wv</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi mathvariant=\"normal\">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=\"normal\">v</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi mathvariant=\"normal\">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=\"normal\">w</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula></td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n<inline-formula>\n<mml:math id=\"mm75\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>h</mml:mi></mml:mstyle><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>v</mml:mi></mml:mstyle><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>t</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi mathvariant=\"sans-serif\">\u03c3</mml:mi><mml:mrow><mml:mo stretchy=\"false\">(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant=\"normal\">m</mml:mi><mml:mi mathvariant=\"normal\">v</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant=\"normal\">t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:msup><mml:mi mathvariant=\"normal\">W</mml:mi><mml:mi mathvariant=\"normal\">t</mml:mi></mml:msup></mml:mrow><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math>\n</inline-formula>\n</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">GAT</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\"><inline-formula><mml:math id=\"mm76\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>m</mml:mi></mml:mstyle><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>v</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>t</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi mathvariant=\"sans-serif\">\u03c3</mml:mi><mml:mrow><mml:mo stretchy=\"false\">(</mml:mo><mml:mrow><mml:munder><mml:mstyle mathsize=\"80%\" displaystyle=\"true\"><mml:mo>\u2211</mml:mo></mml:mstyle><mml:mrow><mml:mi mathvariant=\"normal\">w</mml:mi><mml:mo>\u2208</mml:mo><mml:mi mathvariant=\"normal\">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=\"normal\">v</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mstyle mathsize=\"80%\" displaystyle=\"true\"><mml:mo>\u222a</mml:mo></mml:mstyle><mml:mo>\u00a0</mml:mo></mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:mi mathvariant=\"normal\">v</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:msub><mml:mi mathvariant=\"sans-serif\">\u03b1</mml:mi><mml:mrow><mml:mi>vw</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi mathvariant=\"normal\">W</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=\"normal\">t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msubsup><mml:mi mathvariant=\"normal\">h</mml:mi><mml:mi mathvariant=\"normal\">w</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=\"normal\">t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, <break/><inline-formula><mml:math id=\"mm77\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant=\"sans-serif\">\u03b1</mml:mi><mml:mrow><mml:mi>vw</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>\u00a0</mml:mo><mml:mi>softmax</mml:mi></mml:mrow></mml:mrow><mml:mi mathvariant=\"normal\">v</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant=\"normal\">e</mml:mi><mml:mrow><mml:mi>vw</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, <break/><inline-formula><mml:math id=\"mm78\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant=\"normal\">e</mml:mi><mml:mrow><mml:mi>vw</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>LeakyReLU</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Wh</mml:mi></mml:mrow><mml:mi mathvariant=\"normal\">v</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Wh</mml:mi></mml:mrow><mml:mi mathvariant=\"normal\">w</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\"><inline-formula><mml:math id=\"mm79\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>h</mml:mi></mml:mstyle><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>v</mml:mi></mml:mstyle><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>t</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mo stretchy=\"false\">\u2016</mml:mo><mml:mrow><mml:mi mathvariant=\"normal\">k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant=\"normal\">K</mml:mi></mml:msubsup><mml:msubsup><mml:mi mathvariant=\"normal\">m</mml:mi><mml:mi mathvariant=\"normal\">v</mml:mi><mml:mrow><mml:mi mathvariant=\"normal\">t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>,<break/>where \u2016 is concatenation.</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">GIN</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\"><inline-formula><mml:math id=\"mm80\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>m</mml:mi></mml:mstyle><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>v</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>t</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> = <inline-formula><mml:math id=\"mm81\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:munder><mml:mstyle mathsize=\"80%\" displaystyle=\"true\"><mml:mo>\u2211</mml:mo></mml:mstyle><mml:mrow><mml:mi mathvariant=\"normal\">w</mml:mi><mml:mo>\u2208</mml:mo><mml:mi mathvariant=\"normal\">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=\"normal\">v</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:mi>MLP</mml:mi><mml:mrow><mml:mo stretchy=\"false\">(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant=\"normal\">h</mml:mi><mml:mi mathvariant=\"normal\">w</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=\"normal\">t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n<inline-formula>\n<mml:math id=\"mm82\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>h</mml:mi></mml:mstyle><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>v</mml:mi></mml:mstyle><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>t</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>MLP</mml:mi><mml:mrow><mml:mo stretchy=\"false\">(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant=\"normal\">h</mml:mi><mml:mi mathvariant=\"normal\">v</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=\"normal\">t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi mathvariant=\"normal\">m</mml:mi><mml:mi mathvariant=\"normal\">v</mml:mi><mml:mrow><mml:mi mathvariant=\"normal\">t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy=\"false\">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math>\n</inline-formula>\n</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">MPNN</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\"><inline-formula><mml:math id=\"mm83\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>m</mml:mi></mml:mstyle><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>v</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>t</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> = <inline-formula><mml:math id=\"mm84\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:munder><mml:mstyle mathsize=\"80%\" displaystyle=\"true\"><mml:mo>\u2211</mml:mo></mml:mstyle><mml:mrow><mml:mi mathvariant=\"normal\">w</mml:mi><mml:mo>\u2208</mml:mo><mml:mi mathvariant=\"normal\">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=\"normal\">v</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:mi mathvariant=\"normal\">A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant=\"normal\">e</mml:mi><mml:mrow><mml:mi>vw</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mo>\u00a0</mml:mo><mml:mi mathvariant=\"normal\">h</mml:mi></mml:mrow></mml:mrow><mml:mi mathvariant=\"normal\">w</mml:mi><mml:mi mathvariant=\"normal\">t</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>\n</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n<inline-formula>\n<mml:math id=\"mm85\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>h</mml:mi></mml:mstyle><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>v</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>t</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>GRU</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant=\"normal\">h</mml:mi><mml:mi mathvariant=\"normal\">v</mml:mi><mml:mi mathvariant=\"normal\">t</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi mathvariant=\"normal\">m</mml:mi><mml:mi mathvariant=\"normal\">v</mml:mi><mml:mrow><mml:mi mathvariant=\"normal\">t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math>\n</inline-formula>\n</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">DMPNN</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\"><inline-formula><mml:math id=\"mm86\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>m</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>v</mml:mi><mml:mi>w</mml:mi></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>t</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> = <inline-formula><mml:math id=\"mm87\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:munder><mml:mstyle mathsize=\"80%\" displaystyle=\"true\"><mml:mo>\u2211</mml:mo></mml:mstyle><mml:mrow><mml:mi mathvariant=\"normal\">k</mml:mi><mml:mo>\u2208</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi mathvariant=\"normal\">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=\"normal\">v</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>\u2216</mml:mo><mml:mi mathvariant=\"normal\">w</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:msubsup><mml:mi mathvariant=\"normal\">h</mml:mi><mml:mrow><mml:mi>kv</mml:mi></mml:mrow><mml:mi mathvariant=\"normal\">t</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>\n</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">\n<inline-formula>\n<mml:math id=\"mm88\" overflow=\"scroll\"><mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>h</mml:mi></mml:mstyle><mml:mrow><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>v</mml:mi><mml:mi>w</mml:mi></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle mathvariant=\"bold\" mathsize=\"normal\"><mml:mi>t</mml:mi></mml:mstyle><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo>\u00a0</mml:mo><mml:mi mathvariant=\"sans-serif\">\u03c4</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant=\"normal\">h</mml:mi><mml:mrow><mml:mi>vw</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant=\"normal\">W</mml:mi><mml:mi mathvariant=\"normal\">m</mml:mi></mml:msub><mml:msubsup><mml:mi mathvariant=\"normal\">m</mml:mi><mml:mrow><mml:mi>vw</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=\"normal\">t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math>\n</inline-formula>\n</td></tr></tbody></table>\n"}, "text": "Model\tMessage Passing Function\tUpdate Function\t \tGCN\t\u00a0\t\t \tGAT\t, , \t,where \u2016 is concatenation.\t \tGIN\t = \t\t \tMPNN\t = \t\t \tDMPNN\t = \t\t \t", "sentences": [], "annotations": [], "relations": []}, {"offset": 36702, "infons": {"file": "biomedicines-11-00067-t004.xml", "id": "biomedicines-11-00067-t004", "section_type": "TABLE", "type": "table_footnote"}, "text": "Notes: DMPNN, directed message-passing neural network; GAT, graph attention network; GCN, graph convolutional neural network; GIN, graph isomorphism network; MPNN, message-passing neural network.", "sentences": [], "annotations": [], "relations": []}, {"offset": 36898, "infons": {"file": "biomedicines-11-00067-t005.xml", "id": "biomedicines-11-00067-t005", "section_type": "TABLE", "type": "table_caption"}, "text": "Hyperparameters for the GraphATT-DTA model.", "sentences": [], "annotations": [], "relations": []}, {"offset": 36942, "infons": {"file": "biomedicines-11-00067-t005.xml", "id": "biomedicines-11-00067-t005", "section_type": "TABLE", "type": "table", "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<table frame=\"hsides\" rules=\"groups\"><thead><tr><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Hyperparameter</th><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Setting</th></tr></thead><tbody><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Graph neural network layers</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">2 or 3 or 5</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">K size</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">8</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Epoch</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1000</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Batch size</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">32</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Learning rate</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.0005</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Optimizer</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Adam</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Weight decay</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.00001</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Embedding size of a feature</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">128</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Fully connected layers</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">(1024, 512, 1)</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Dropout</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.1 or 0.2</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Early stopping</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">30</td></tr></tbody></table>\n"}, "text": "Hyperparameter\tSetting\t \tGraph neural network layers\t2 or 3 or 5\t \tK size\t8\t \tEpoch\t1000\t \tBatch size\t32\t \tLearning rate\t0.0005\t \tOptimizer\tAdam\t \tWeight decay\t0.00001\t \tEmbedding size of a feature\t128\t \tFully connected layers\t(1024, 512, 1)\t \tDropout\t0.1 or 0.2\t \tEarly stopping\t30\t \t", "sentences": [], "annotations": [], "relations": []}, {"offset": 37228, "infons": {"file": "biomedicines-11-00067-t006.xml", "id": "biomedicines-11-00067-t006", "section_type": "TABLE", "type": "table_caption"}, "text": "GraphATT-DTA prediction performance on the Davis testing dataset vs. baseline models.", "sentences": [], "annotations": [], "relations": []}, {"offset": 37314, "infons": {"file": "biomedicines-11-00067-t006.xml", "id": "biomedicines-11-00067-t006", "section_type": "TABLE", "type": "table", "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<table frame=\"hsides\" rules=\"groups\"><thead><tr><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Models</th><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Protein</th><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Compound</th><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Interaction</th><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Davis MSE</th><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Davis CI</th></tr></thead><tbody><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">DeepDTA</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1D CNN</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1D CNN</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Concat</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.245</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.886</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">GraphDTA</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1D CNN</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">GIN</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Concat</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.229</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.890</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">DeepAffinity</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">RNN\u2013CNN</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">RNN\u2013CNN</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Joint attention</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.302</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.870</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">ML-DTI</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1D CNN</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1D CNN</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Mutual learning</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.222</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.891</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">HyperAttentionDTI</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1D CNN</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1D CNN</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Hyperattention</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.233</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.876</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">FusionDTA</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">BI-LSTM</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">BI-LSTM</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Fusion layer</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.203</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.911</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">GraphATT-DTA</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">1D CNN</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">MPNN</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Interaction learning</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">0.204</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">0.904</td></tr></tbody></table>\n"}, "text": "Models\tProtein\tCompound\tInteraction\tDavis MSE\tDavis CI\t \tDeepDTA\t1D CNN\t1D CNN\tConcat\t0.245\t0.886\t \tGraphDTA\t1D CNN\tGIN\tConcat\t0.229\t0.890\t \tDeepAffinity\tRNN\u2013CNN\tRNN\u2013CNN\tJoint attention\t0.302\t0.870\t \tML-DTI\t1D CNN\t1D CNN\tMutual learning\t0.222\t0.891\t \tHyperAttentionDTI\t1D CNN\t1D CNN\tHyperattention\t0.233\t0.876\t \tFusionDTA\tBI-LSTM\tBI-LSTM\tFusion layer\t0.203\t0.911\t \tGraphATT-DTA\t1D CNN\tMPNN\tInteraction learning\t0.204\t0.904\t \t", "sentences": [], "annotations": [], "relations": []}, {"offset": 37744, "infons": {"file": "biomedicines-11-00067-t006.xml", "id": "biomedicines-11-00067-t006", "section_type": "TABLE", "type": "table_footnote"}, "text": "Notes: BI-LSTM, bidirectional long short-term memory; CI, concordance index; CNN, convolutional neural network; GCN, graph convolutional neural network; GIN, graph isomorphism network; MSE, mean squared error; RNN, recurrent neural network.", "sentences": [], "annotations": [], "relations": []}, {"offset": 37985, "infons": {"file": "biomedicines-11-00067-t007.xml", "id": "biomedicines-11-00067-t007", "section_type": "TABLE", "type": "table_caption"}, "text": "Prediction performance over the BindingDB external test set of GraphATT-DTA and baseline models.", "sentences": [], "annotations": [], "relations": []}, {"offset": 38082, "infons": {"file": "biomedicines-11-00067-t007.xml", "id": "biomedicines-11-00067-t007", "section_type": "TABLE", "type": "table", "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<table frame=\"hsides\" rules=\"groups\"><thead><tr><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Models</th><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Interaction</th><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Early Stopping</th><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">BindingDB MSE</th><th align=\"center\" valign=\"middle\" style=\"border-top:solid thin;border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">BindingDB CI</th></tr></thead><tbody><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">DeepDTA</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Concat</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">O</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1.618</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.646</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">GraphDTA</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Concat</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">X</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">2.13</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.62</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">DeepAffinity</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Joint attention</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">X</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">2.188</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.574</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">ML-DTI</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Mutual learning</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">O</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1.580</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.704</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">HyperAttentionDTI</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Hyperattention </td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">O</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1.514</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.656</td></tr><tr><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">FusionDTA</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">Fusion layer</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">X</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">1.970</td><td align=\"center\" valign=\"middle\" rowspan=\"1\" colspan=\"1\">0.567</td></tr><tr><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">GraphATT-DTA</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">Interaction learning </td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">O</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">1.582</td><td align=\"center\" valign=\"middle\" style=\"border-bottom:solid thin\" rowspan=\"1\" colspan=\"1\">0.651</td></tr></tbody></table>\n"}, "text": "Models\tInteraction\tEarly Stopping\tBindingDB MSE\tBindingDB CI\t \tDeepDTA\tConcat\tO\t1.618\t0.646\t \tGraphDTA\tConcat\tX\t2.13\t0.62\t \tDeepAffinity\tJoint attention\tX\t2.188\t0.574\t \tML-DTI\tMutual learning\tO\t1.580\t0.704\t \tHyperAttentionDTI\tHyperattention \tO\t1.514\t0.656\t \tFusionDTA\tFusion layer\tX\t1.970\t0.567\t \tGraphATT-DTA\tInteraction learning \tO\t1.582\t0.651\t \t", "sentences": [], "annotations": [], "relations": []}, {"offset": 38431, "infons": {"file": "biomedicines-11-00067-t007.xml", "id": "biomedicines-11-00067-t007", "section_type": "TABLE", "type": "table_footnote"}, "text": "Notes: CI, concordance index; MSE, mean-squared error.", "sentences": [], "annotations": [], "relations": []}], "annotations": [], "relations": []}]}]