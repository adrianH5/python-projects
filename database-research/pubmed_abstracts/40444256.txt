Fréchet Inception Distance (FID) is a widely used metric for assessing synthetic image quality.
It relies on an ImageNet-based feature extractor, making its applicability to medical imaging unclear.
A recent trend is to adapt FID to medical imaging through feature extractors trained on medical images.
Our study challenges this practice by demonstrating that ImageNet-based extractors are more consistent and aligned with human judgment than their RadImageNet counterparts.
We evaluated sixteen StyleGAN2 networks across four medical imaging modalities and four data augmentation techniques with Fréchet distances (FDs) computed using eleven ImageNet or RadImageNet-trained feature extractors.
Comparison with human judgment via visual Turing tests revealed that ImageNet-based extractors produced rankings consistent with human judgment, with the FD derived from the ImageNet-trained SwAV extractor significantly correlating with expert evaluations.
In contrast, RadImageNet-based rankings were volatile and inconsistent with human judgment.
Our findings challenge prevailing assumptions, providing novel evidence that medical image-trained feature extractors do not inherently improve FDs and can even compromise their reliability.
Our code is available at https://github.com/mckellwoodland/fid-med-eval.
