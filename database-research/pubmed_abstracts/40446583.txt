The automatic screening of thyroid nodules using computer-aided diagnosis holds great promise in reducing missed and misdiagnosed cases in clinical practice.
However, most current research focuses on single-modal images and does not fully leverage the comprehensive information from multimodal medical images, limiting model performance.
To enhance screening accuracy, this study uses a deep learning framework that integrates high-dimensional convolutions of B-mode ultrasound (BMUS) and strain elastography (SE) images to predict the malignancy of TI-RADS 4 thyroid nodules with high-risk features.
First, we extract nodule regions from the images and expand the boundary areas.
Then, adaptive particle swarm optimization (APSO) and contrast limited adaptive histogram equalization (CLAHE) algorithms are applied to enhance ultrasound image contrast.
Finally, deep learning techniques are used to extract and fuse high-dimensional features from both ultrasound modalities to classify benign and malignant thyroid nodules.
The proposed model achieved an AUC of 0.937 (95 % CI 0.917-0.949) and 0.927 (95 % CI 0.907-0.948) in the test and external validation sets, respectively, demonstrating strong generalization ability.
When compared with the diagnostic performance of three groups of radiologists, the model outperformed them significantly.
Meanwhile, with the model's assistance, all three radiologist groups showed improved diagnostic performance.
Furthermore, heatmaps generated by the model show a high alignment with radiologists' expertise, further confirming its credibility.
The results indicate that our model can assist in clinical thyroid nodule diagnosis, reducing the risk of missed and misdiagnosed diagnoses, particularly for high-risk populations, and holds significant clinical value.
